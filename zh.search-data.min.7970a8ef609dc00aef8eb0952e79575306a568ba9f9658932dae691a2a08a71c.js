'use strict';(function(){const indexCfg={encode:false,tokenize:function(str){return str.replace(/[\x00-\x7F]/g,'').split('');}};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/references/filters/echo/','title':"echo",'section':"在线过滤器",'content':"echo #  描述 #  echo 过滤器是一个用于在返回结果里面输出指定字符信息的过滤器，常用于调试。\n功能演示 #    配置示例 #  一个简单的示例如下：\nflow: - name: hello_world filter: - echo: message: \u0026quot;hello infini\\n\u0026quot; echo 过滤器可以设置重复输出相同的字符的次数，示例如下：\n... - echo: message: \u0026quot;hello gateway\\n\u0026quot; repeat: 3 ... 参数说明 #     名称 类型 说明     message string 需要输出的字符内容   repeat int 重复次数   stdout bool 是否在终端也打印输出，默认为 false    "});index.add({'id':1,'href':'/docs/overview/','title':"产品概述",'section':"Docs",'content':"概述 #  介绍 #  极限网关（INFINI Gateway）是一个面向 Elasticsearch 的高性能应用网关，它包含丰富的特性，使用起来也非常简单。极限网关工作的方式和普通的反向代理一样，我们一般是将网关部署在 Elasticsearch 集群前面， 将以往直接发送给 Elasticsearch 的请求都发送给网关，再由网关转发给请求到后端的 Elasticsearch 集群。因为网关位于在用户端和后端 Elasticsearch 之间，所以网关在中间可以做非常多的事情， 比如可以实现索引级别的限速限流、常见查询的缓存加速、查询请求的审计、查询结果的动态修改等等。\n特性 #  极限网关 最懂 Elasticsearch，其在设计的时候就综合考虑了很多和 Elasticsearch 相关的业务场景及特点，基于此打造了很多完美契合 Elasticsearch 的众多非常实用的功能。\n轻量级 极限网关使用 Golang 编写，安装包很小，只有 10MB 左右，没有任何外部环境依赖，部署安装都非常简单，只需要下载对应平台的二进制可执行文件，启动网关程序的二进制程序文件执行即可。  极致性能 极限网关在编写每一行代码的时候，都会考虑如何让其运行在最佳状态，经测试，极限网关比同类主流网关类产品速度快 25% 以上，且针对 Elasticsearch 做了非常细致的优化，能成倍提升写入和查询的速度。   跨版本支持 极限网关针对不同的 Elasticsearch 版本做了兼容和针对性处理，能够让业务代码无缝的进行适配，后端 Elasticsearch 集群版本升级能够做到无缝过渡，降低版本升级和数据迁移的复杂度。  可观测性 极限网关可以动态对 Elasticsearch 运行过程中产生的任何请求进行截获和分析，通过指标和日志来了解整个集群的运行情况，用于提升性能和优化业务。还可以用于审计和慢查询分析。   高可用 极限网关内置多种高可用解决方案，前端请求入口支持基于虚拟 IP 的双机热备，后端集群支持集群拓扑的自动感知，节点上下线能自动发现，自动处理后端故障，自动进行请求的重试和迁移。  灵活可扩展 极限网关的每个模块都可以独立扩展，可灵活对每个请求进行干预和路由，支持路由的智能学习，内置丰富的过滤器，通过配置动态修改每个请求的处理逻辑，也支持通过插件来进行扩展。   无缝集成 #  极限网关对外提供的接口完全兼容 Elasticsearch 原生的接口，集成起来非常简单，只需将原本指向 Elasticsearch 的配置修改成网关的地址即可。\n为什么需要极限网关？ #  嗯，上面的集成交互图基本上看明白了，可我现在 Elasticsearch 用的好好的，我为什么需要在前面加上一个网关呢？\n好吧，如果您是一个稍微上了规模的 Elasticsearch 集群，不如试着想想下面的几个场景：\nWAF 与安全 #  相信您存储在 Elasticsearch 中的每一份数据都是很宝贵的，随着 Elasticsearch 的流行，它也正日益成为黑客们攻击的主要目标，WAF（Web Application Firewall）的需求应运而生。 不管是跨站脚本攻击还是跨站脚本注入，又或是弱密码、暴力破解，还是程序员不合理的查询参数滥用，极限网关都能对这些来自不同 Web 应用程序客户端的各类请求进行内容检测和验证， 通过执行一系列针对 Elasticsearch 的安全策略来确保其安全性与合法性，对非法的请求予以实时阻断，从而对后端 Elasticsearch 进行有效防护。\n集群升级 #  没错，相信您也知道 Elasticsearch 版本迭代的速度是非常快的，可能经常需要处理集群版本升级的事宜，而集群升级势必要考虑到以下几点：\n 保证最小的停机时间，业务的数据写入和查询不能因为集群的升级而中止，数据要能持续的进行写入，还不能因为后端重启节点而丢失数据 集群流量的切换，新旧集群在什么时候以及如何进行切换，是修改业务代码或者配置文件呢，以及如何回滚恢复呢，是不是需要重新发布一个新的部署包  借助极限网关，您的业务代码完全不用关心后端 Elasticsearch 集群是什么状况，只需要访问网关固定的地址即可，剩下的交给网关就都搞定了。\n索引重建 #  修改了 Mapping 需要重建索引，修改了分词词典需要重建索引，重建过程中还不能停止数据的写入，重建完成之后还要确保数据是一致的，有新增的数据和修改的数据也必须一一处理，自己处理起来貌似还挺麻烦。 而极限网关，可以做到一键索引重建，重建过程中的任何文档修改操作都会被自动记录，新旧索引在重建完成之后会自动无缝的进行切换，对于前端应用来说完全无感知。\n限流限速 #  有没有遇到过突发流量把集群打爆的情况，有没有遇到过个别大索引特别热闹把整个集群都连累的窘迫，其实您需要对异常的流量进行管理，这样才能保护整个 Elasticsearch 集群不会被异常的流量影响甚至是被恶意的攻击。 极限网关可以做到灵活的流量控制，可以做到索引级别的限速规则设置，一千个索引就有一千个哈姆雷特，完全没问题。\n查询太慢 #  极限网关内置缓存功能，能够将最常见的查询进行缓存，还可指定周期性的查询计划来预热特定的查询，保证前端的业务每次都能命中查询，从而提升查询速度，改进业务查询用户体验；\n索引太慢 #  极限网关可以将来自不同客户端的众多小批量的 Elasticsearch 索引请求合并成一个大的批次请求，通过精准的分片级别的路由，将索引请求合并封装直接投递到指定分片的指定节点上， 避免后端 Elasticsearch 再次进行请求转发，节省 Elasticsearch 资源和带宽，从而提升整体集群的吞吐和性能。\n请求干预 #  代码上线之后才发现查询语句写错了？有了极限网关，完全不用担心，可以在线对指定业务的指定查询进行改写，将查询语句动态修复，无需重新发布应用，方便灵活。或者您对 Elasticsearch 查询返回的 JSON 结果不满意， 也没关系，借助极限网关，您能够动态的替换查询结果为新的内容，甚至可以聚合来自其他数据源的数据，如 Hbase、MySQL 等等，融合成您需要的 JSON 数据再返回给客户端。\n请求分析 #  只知道有人抱怨 Elasticsearch 很慢，可您知道是 Elasticsearch 里面的哪些索引慢么？又是哪些查询造成的呢？ 又是哪些用户造成的呢？极限网关帮您全程跟踪，从集群到索引，从索引到查询，从应用到用户，让您对于 Elasticsearch 集群内的那点事情一清二楚。\n所以，用上极限网关之后您再用 Elasticsearch 将会变成是一件很爽的事情。\n架构 #  极限网关的核心模块见下面的架构图：\n负载外部请求代理的模块由四个主要部分组成，即：Entry、Router、Flow 和 Filter。一个 Entry 需要配置一个 Router，一个 Router 可以路由到多个 Flow，一个 Flow 由多个 Filter 组成。\nEntry #  Entry 模块主要定义网关的请求入口，极限网关支持 HTTP 和 HTTPS 两种模式，HTTPS 可以自动生成证书。\nRouter #  Router 模块主要定义请求的路由规则，根据 Method 和请求地址来进行路由到指定的 Flow 处理流程里面去。\nFlow #  Flow 模块主要定义数据的处理逻辑，每个请求会经过一系列的 Filter 操作，Flow 用来将这些 Filter 组织起来。\nFilter #  Filter 模块由若干个不同的 Filter 组件构成，每个 Filter 在设计的时候只处理一件事情，通过多个 Filter 组成变成一个 Flow。\nPipeline #  Pipeline 模块由若干个不同的 Processor 组件构成，通过多个 Processor 组成一个 Pipeline，Pipeline 和 Flow 相比，更侧重离线任务的处理。\nQueue #  Queue 模块是一个抽象的消息队列，如基于本地磁盘的可靠性消息持久化以及 Redis 和 Kafka 等适配器，根据不同的场景可以设置队列的不同后端适配器。\n此外，INFINI Gateway 使用的框架底层还有一些公共的模块，如：API 用来提供对外的编程入口，Elastic 模块用于处理不同版本的 Elasticsearch API 封装等等。\n接下来 #   查看 下载安装  "});index.add({'id':2,'href':'/docs/tutorial/online_query_rewrite/','title':"在线查询修复的实现",'section':"动手教程",'content':"在线查询修复的实现 #  在某些情况下，您可能会碰到业务代码生成的 QueryDSL 存在不合理的情况，一般做法是需要修改业务代码并发布上线， 如果上线新版本需要很长的时间，比如没有到投产窗口，或者封网，又或者需要和其他的代码提交一起上线，往往意味着需要大量的测试， 而生产环境的故障要立马解决，客户不能等啊，怎么办？\n别着急，您可以使用极限网关来对查询进行动态修复。\n举个例子 #  比如下面的这个查询：\nGET _search { \u0026quot;size\u0026quot;: 1000000 , \u0026quot;explain\u0026quot;: true } 参数 size 设置的太大了，刚开始没有发现问题，随着数据越来越多，返回的数据太多势必会造成性能的急剧下降， 另外参数 explain 的开启也会造成不必要的性能开销，一般只在开发调试的时候才会用到这个功能。\n通过在网关里面增加一个 request_body_json_set 过滤器，可以动态替换指定请求体 JSON PATH 的值，上面的例子对应的配置如下：\nflow: - name: rewrite_query filter: - request_body_json_set: path: - explain -\u0026gt; false - size -\u0026gt; 10 - dump_request_body: - elasticsearch: elasticsearch: dev 通过重新设置 explain 和 size 参数，现在我们查询发给 Elasticsearch 前会被改写成如下格式：\n{ \u0026quot;size\u0026quot;: 10, \u0026quot;explain\u0026quot;: false } 成功修复线上问题。\n再举个例子 #  看下面的这个查询，编写代码的程序员写错了需要查询的字段名，应该是 name，但是写成了 name1，参数 size 也设置的特别大，如下：\nGET medcl/_search { \u0026quot;aggs\u0026quot;: { \u0026quot;total_num\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;name1\u0026quot;, \u0026quot;size\u0026quot;: 1000000 } } } } 然后，系统居然上线了，这不查询就出问题了嘛。 哎，别着急，在网关请求流程里面增加如下过滤器配置就行了：\nflow: - name: rewrite_query filter: - request_body_json_set: path: - aggs.total_num.terms.field -\u0026gt; \u0026quot;name\u0026quot; - aggs.total_num.terms.size -\u0026gt; 10 - size -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 上面的配置，我们通过请求体 JSON 的路径直接替换了其数据，并且新增了一个参数来不返回查询文档，因为只需要聚合结果就行了。\n再举个例子 #  用户的查询为：\n{ \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;should\u0026quot;:[{\u0026quot;term\u0026quot;:{\u0026quot;isDel\u0026quot;:0}},{\u0026quot;match\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;order\u0026quot;}}] }\t} } 现在希望将其中的 term 查询换成等价的 range 查询，即如下：\n{ \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;should\u0026quot;:[{ \u0026quot;range\u0026quot;: { \u0026quot;isDel\u0026quot;: {\u0026quot;gte\u0026quot;: 0,\u0026quot;lte\u0026quot;: 0 }}},{\u0026quot;match\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;order\u0026quot;}}] }\t} } 使用下面的配置即可：\nflow: - name: rewrite_query filter: - request_body_json_del: path: - query.bool.should.[0] - request_body_json_set: path: - query.bool.should.[1].range.isDel.gte -\u0026gt; 0 - query.bool.should.[1].range.isDel.lte -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 上面的配置，首先使用了一个 request_body_json_del 来删除查询 should 里面的第一个元素，也就是要替换掉的 Term 子查询， 然后现在只剩一个 Match 查询了，现在增加一个 Should 的子查询，新增下标的注意应该为 1，分别设置 Range 查询的各个属性即可。\n进一步完善 #  上面的例子都是直接替换查询，不过一般情况下，你可能还需要进行一个判断来决定是否进行替换，比如当 _ctx.request.body_json.query.bool.should.[0].term.isDel JSON 字段存在才进行替换，网关的 条件判断非常灵活如下，配置如下：\nflow: - name: cache_first filter: - if: and: - has_fields: ['_ctx.request.body_json.query.bool.should.[0].term.isDel'] then: - request_body_json_del: path: - query.bool.should.[0] - request_body_json_set: path: - query.bool.should.[1].range.isDel.gte -\u0026gt; 0 - query.bool.should.[1].range.isDel.lte -\u0026gt; 0 - dump_request_body: - elasticsearch: elasticsearch: dev 完美！\n"});index.add({'id':3,'href':'/docs/getting-started/install/','title':"安装网关",'section':"入门指南",'content':"安装网关 #  极限网关支持主流的操作系统和平台，程序包很小，没有任何额外的外部依赖，安装起来应该是很快的 ：）\n安装演示 #    下载安装 #  根据您所在的操作系统和平台选择下面相应的下载地址：\n http://release.elasticsearch.cn/gateway/stable/\n最新快照的下载地址访问：这里  容器部署 #  极限网关也支持 Docker 容器方式部署。\n了解更多  验证安装 #  极限网关下载解压之后，我们可以执行这个命令来验证安装包是否有效，如下：\n✗ ./bin/gateway -v gateway 1.0.0_SNAPSHOT 2021-01-03 22:45:28 6a54bb2 如果能够正常看到上面的版本信息，说明网关程序本身一切正常。\n启动网关 #  以管理员身份直接运行网关程序即可启动极限网关了，如下：\n➜ sudo ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, 4daf6e9, Mon Jan 11 11:40:44 2021 +0800, medcl, add response_header_filter [01-11 16:43:31] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [01-11 16:43:31] [INF] [api.go:255] api server listen at: http://0.0.0.0:2900 [01-11 16:43:31] [INF] [runner.go:59] pipeline: primary started with 1 instances [01-11 16:43:31] [INF] [runner.go:59] pipeline: nodes_index started with 1 instances [01-11 16:43:31] [INF] [entry.go:262] entry [es_gateway] listen at: https://0.0.0.0:8000 [01-11 16:43:32] [INF] [floating_ip.go:170] floating_ip listen at: 192.168.3.234, echo port: 61111 [01-11 16:43:32] [INF] [app.go:254] gateway now started. 看到上面的启动信息，说明网关已经成功运行了，并且监听了响应的端口。\n访问网关 #  使用浏览器或者其它客户端即可正常访问由网关代理的后端 Elasticsearch 服务了，如下：\n停止网关 #  如果需要停止网关，按 Ctrl+C 即可停止极限网关，如下：\n^C [GATEWAY] got signal: interrupt, start shutting down [01-11 16:44:41] [INF] [app.go:303] gateway now terminated. [GATEWAY] 1.0.0_SNAPSHOT, uptime: 1m10.550336s Thanks for using GATEWAY, have a good day! 后台运行 #  如果希望将极限网关以后台任务的方式运行，如下：\n➜ sudo ./bin/gateway -daemon -pidfile=/tmp/gateway.pid ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, aa6f614, Mon Jan 11 14:48:17 2021 +0800, medcl, add request_client_ip_filter [GATEWAY] started in background, pid: 16474 通过 PID 可以方便的停止极限网关，如下：\nsudo kill `cat /tmp/gateway.pid` 系统服务 #  如果希望将极限网关当做一个系统服务来管理，可以将网关程序拷贝到 /opt/gateway/bin/gateway 位置，将配置文件拷贝到 /etc/gateway/gateway.yml 位置， 然后新增一个系统服务，编辑 /usr/lib/systemd/system/gateway.service 内容如下：\n[Unit] Description=infini-gateway After=network.target [Service] Type=forking WorkingDirectory=/opt/gateway ExecStart=/opt/gateway/bin/gateway -daemon -pidfile /var/run/gateway.pid -config /etc/gateway/gateway.yml ExecStop=/bin/kill `cat /var/run/gateway.pid` PrivateTmp=true User=root Group=root LimitNOFILE=16384:163840 [Install] WantedBy=multi-user.target 重新加载服务\nsystemctl daemon-reload 启动网关服务\nsystemctl start gateway 查看网关服务\nsystemctl status gateway 停止网关服务\nsystemctl stop gateway 查看服务日志\njournalctl -fu gateway 设置开机自启\nsystemctl enable gateway 取消开机自启\nsystemctl disable gateway 到这里极限网关就已经安装好了，下一步我们来看如何配置极限网关。\n下一步  "});index.add({'id':4,'href':'/docs/references/entry/','title':"服务入口",'section':"功能手册",'content':"服务入口 #  定义入口 #  每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: false 通过参数 network.binding 可以指定服务监听的 IP 和地址，极限网关支持端口重用，也就是多个极限网关共享一个相同的 IP 和端口，这样可以充分利用服务器的资源， 也能做到不同网关进程的动态配置修改（通过开启多个进程，修改配置之后，依次重启各个进程）而不会中断客户端的正常请求。\n每个发送到 entry 的请求都会通过 router 来进行流量的路由处理，router 在单独的地方定义规则，以方便在不同的 entry 间复用，entry 只需要通过 router 参数指定要使用的 router 规则即可，这里定义的是 default。\nTLS 配置 #  极限网关支持无缝开启 TLS 传输加密，只需要将 tls.enabled 设置成 true，即可直接切换为 HTTPS 的通信模式，极限网关能自动生成自签证书。\n极限网关也支持自定义证书路径，配置方式如下：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: true cert_file: /etc/ssl.crt key_file: /etc/ssl.key skip_insecure_verify: false 多个服务 #  极限网关支持一个网关监听多个不同的服务入口，各个服务入口的监听地址、协议和路由都可以分别定义，用来满足不同的业务需求，配置示例如下：\nentry: - name: es_ingest enabled: true router: ingest_router network: binding: 0.0.0.0:8000 - name: es_search enabled: true router: search_router network: binding: 0.0.0.0:9000 上面的例子，定义了一个名为 es_ingest 的服务入口，监听的地址是 0.0.0.0:8000，所有请求都通过 ingest_router 来进行处理。 另外一个 es_search 服务，监听端口是 9000，使用 search_router 来进行请求处理，可以实现业务的读写分离。 另外，对于不同的后端 Elasticsearch 集群也可以定义不同的服务入口，通过网关来进行请求的代理转发。\n参数说明 #     名称 类型 说明     name string 服务入口名称   enabled bool 是否启用该入口   max_concurrency int 最大的并发连接数，默认 10000   router string 路由名称   network object 网络的相关配置   tls object TLS 安全传输相关配置   network.host string 服务监听的网络地址，如：192.168.3.10   network.port string 服务监听的端口地址，如：8000   network.binding string 服务监听的网络绑定地址，如：0.0.0.0:8000   network.publish string 服务监听的对外访问地址，如：192.168.3.10:8000   network.reuse_port bool 是否重用网络端口，用于多进程端口共享   network.skip_occupied_port bool 是否自动跳过已占用端口   tls.enabled bool 是否启用 TLS 安全传输   tls.cert_file string TLS 安全证书公钥路径   tls.key_file string TLS 安全证书秘钥路径   tls.skip_insecure_verify bool 是否忽略 TLS 的证书校验    "});index.add({'id':5,'href':'/docs/tutorial/request-logging/','title':"查询请求流量日志分析",'section':"动手教程",'content':"查询请求流量日志分析 #  极限网关能够跟踪记录经过网关的所有请求，可用来分析发送给 Elasticsearch 的请求情况，用于分析请求性能和了解业务运行情况。\n设置网关路由 #  如果需要开启极限网关的查询日志分析，需要在路由上面配置 tracing_flow 参数，设置一个流程来记录请求日志。\nrouter: - name: default tracing_flow: request_logging default_flow: cache_first 上面的配置定义了一个名为 default 的路由，默认的请求流程为 cache_first，用于日志记录的流程为 request_logging。\n定义日志流程 #  日志处理流程配置 request_logging 的定义如下：\nflow: - name: request_logging filter: - request_path_filter: must_not: # any match will be filtered prefix: - /favicon.ico - request_header_filter: exclude: - app: kibana # in order to filter kibana's access log, config `elasticsearch.customHeaders: { \u0026quot;app\u0026quot;: \u0026quot;kibana\u0026quot; }` to your kibana's config `/config/kibana.yml` - logging: queue_name: request_logging 上面的流程里面使用了若干个过滤器：\n request_path_filter 过滤了无用的 /favicon.ico 请求 request_header_filter，过滤了来自 Kibana 的请求 request_logging，将请求日志记录到本地磁盘队列 request_logging，供后续管道来消费并创建索引  定义日志管道 #  极限网关使用管道任务来异步消费这些日志，并创建索引，具体的定义配置如下：\npipelines: - name: request_logging_index processors: - json_indexing: index_name: \u0026quot;gateway_requests\u0026quot; elasticsearch: \u0026quot;dev\u0026quot; input_queue: \u0026quot;request_logging\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 #in MB 上面的配置里面，定义了一个名为 request_logging_index 的处理管道，设置了消费的磁盘队列名称 request_logging 和索引的目标集群 dev 和索引名 gateway_requests，使用了一个工作线程，批次提交大小为 10MB。\n然后还定义了一个名为 primary 的管道运行器，程序启动，该运行器就会监听并运行管道里面定义的处理，也就是消费查询日志并创建索引。\n定义索引集群 #  接下来配置索引集群，如下：\nelasticsearch: - name: dev enabled: true endpoint: https://192.168.3.98:9200 # if your elasticsearch is using https, your gateway should be listen on as https as well basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: elastic password: pass discovery: # auto discovery elasticsearch cluster nodes enabled: true refresh: enabled: true 上面的配置定义了一个名为 dev 的 Elasticsearch 集群，并且开启 Elastic 模块来处理集群的自动配置。\n配置索引模板 #  然后就可以配置 Elasticsearch 集群的索引模板了，在 dev 集群上执行下面的命令创建日志索引的模板。\n 展开查看 Elasticsearch 的模板定义 ...  PUT _template/.infini-gateway-default { \u0026quot;order\u0026quot;: 1, \u0026quot;index_patterns\u0026quot;: [ \u0026quot;gateway_requests\u0026quot; ], \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;max_result_window\u0026quot;: \u0026quot;10000000\u0026quot;, \u0026quot;number_of_shards\u0026quot;: \u0026quot;1\u0026quot; } }, \u0026quot;mappings\u0026quot;: { \u0026quot;dynamic_templates\u0026quot;: [ { \u0026quot;strings\u0026quot;: { \u0026quot;mapping\u0026quot;: { \u0026quot;ignore_above\u0026quot;: 256, \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot;: \u0026quot;string\u0026quot; } } ], \u0026quot;properties\u0026quot;: { \u0026quot;request\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } }, \u0026quot;response\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;body\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot; } } } } }, \u0026quot;aliases\u0026quot;: {} }     配置索引生命周期 #   展开查看索引生命周期的定义 ...  PUT _ilm/policy/30days-retention { \u0026quot;policy\u0026quot;: { \u0026quot;phases\u0026quot;: { \u0026quot;hot\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;0ms\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;rollover\u0026quot;: { \u0026quot;max_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;max_size\u0026quot;: \u0026quot;50gb\u0026quot; }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 100 } } }, \u0026quot;warm\u0026quot;: { \u0026quot;actions\u0026quot;: { \u0026quot;forcemerge\u0026quot;: { \u0026quot;max_num_segments\u0026quot;: 1 }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 50 } } }, \u0026quot;cold\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;3d\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;allocate\u0026quot;: { \u0026quot;number_of_replicas\u0026quot;: 1, \u0026quot;include\u0026quot;: {}, \u0026quot;exclude\u0026quot;: {}, \u0026quot;require\u0026quot;: { \u0026quot;box_type\u0026quot;: \u0026quot;warm\u0026quot; } }, \u0026quot;set_priority\u0026quot;: { \u0026quot;priority\u0026quot;: 0 } } }, \u0026quot;delete\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;delete\u0026quot;: { \u0026quot;delete_searchable_snapshot\u0026quot;: true } } } } } } PUT _template/gateway_requests-rollover { \u0026quot;order\u0026quot; : 0, \u0026quot;index_patterns\u0026quot; : [ \u0026quot;gateway_requests-*\u0026quot; ], \u0026quot;settings\u0026quot; : { \u0026quot;index\u0026quot; : { \u0026quot;format\u0026quot; : \u0026quot;7\u0026quot;, \u0026quot;lifecycle\u0026quot; : { \u0026quot;name\u0026quot; : \u0026quot;30days-retention\u0026quot;, \u0026quot;rollover_alias\u0026quot; : \u0026quot;gateway_requests\u0026quot; }, \u0026quot;codec\u0026quot; : \u0026quot;best_compression\u0026quot;, \u0026quot;routing\u0026quot; : { \u0026quot;allocation\u0026quot; : { \u0026quot;require\u0026quot; : { \u0026quot;box_type\u0026quot; : \u0026quot;hot\u0026quot; }, \u0026quot;total_shards_per_node\u0026quot; : \u0026quot;1\u0026quot; } }, \u0026quot;number_of_shards\u0026quot; : \u0026quot;1\u0026quot; } }, \u0026quot;mappings\u0026quot; : { \u0026quot;dynamic_templates\u0026quot; : [ { \u0026quot;strings\u0026quot; : { \u0026quot;mapping\u0026quot; : { \u0026quot;ignore_above\u0026quot; : 256, \u0026quot;type\u0026quot; : \u0026quot;keyword\u0026quot; }, \u0026quot;match_mapping_type\u0026quot; : \u0026quot;string\u0026quot; } } ] }, \u0026quot;aliases\u0026quot; : { } } DELETE gateway_requests-00001 PUT gateway_requests-00001 { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.rollover_alias\u0026quot;:\u0026quot;gateway_requests\u0026quot; , \u0026quot;refresh_interval\u0026quot;: \u0026quot;5s\u0026quot; }, \u0026quot;aliases\u0026quot;:{ \u0026quot;gateway_requests\u0026quot;:{ \u0026quot;is_write_index\u0026quot;:true } } }     导入仪表板 #  下载面向 Kibana 7.9 的最新的仪表板 INFINI-Gateway-7.9.2-2021-01-15.ndjson.zip，在 dev 集群的 Kibana 里面导入，如下：\n启动网关 #  接下来，就可以启动网关，。\n➜ ./bin/gateway ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, a17be4c, Wed Feb 3 00:12:02 2021 +0800, medcl, add extra retry for bulk_indexing [02-03 13:51:35] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [02-03 13:51:35] [INF] [api.go:255] api server listen at: http://0.0.0.0:2900 [02-03 13:51:35] [INF] [runner.go:59] pipeline: primary started with 1 instances [02-03 13:51:35] [INF] [runner.go:59] pipeline: nodes_index started with 2 instances [02-03 13:51:35] [INF] [entry.go:267] entry [es_gateway] listen at: http://0.0.0.0:8000 [02-03 13:51:35] [INF] [app.go:297] gateway now started. 修改应用配置 #  将之前指向 Elasticsearch 地址的应用（如 Beats、Logstash、Kibana 等）换成网关的地址。 假设网关 IP 是 192.168.3.98，则修改 Kibana 配置如下：\n# The Kibana server's name. This is used for display purposes. #server.name: \u0026quot;your-hostname\u0026quot; # The URLs of the Elasticsearch instances to use for all your queries. elasticsearch.hosts: [\u0026quot;https://192.168.3.98:8000\u0026quot;] elasticsearch.customHeaders: { \u0026quot;app\u0026quot;: \u0026quot;kibana\u0026quot; } # When this setting's value is true Kibana uses the hostname specified in the server.host # setting. When the value of this setting is false, Kibana uses the hostname of the host # that connects to this Kibana instance. #elasticsearch.preserveHost: true # Kibana uses an index in Elasticsearch to store saved searches, visualizations and # dashboards. Kibana creates a new index if the index doesn't already exist. #kibana.index: \u0026quot;.kibana\u0026quot; # The default application to load. #kibana.defaultAppId: \u0026quot;home\u0026quot; 保存配置并重启 Kibana。\n查看效果 #  现在任何通过网关访问 Elasticsearch 的请求都能被监控到了。\n"});index.add({'id':6,'href':'/docs/references/modules/floating_ip/','title':"浮动 IP",'section':"功能组件",'content':"浮动 IP #  极限网关内置浮动 IP 功能，可以实现双机热备、故障转移的能力，极限网关天然提供四层网络流量的高可用，无需再额外考虑增加额外的软件和设备来保障因为停机、网络故障等造成的代理服务中断。\n注意:\n 该特性目前仅支持 Mac OS、Linux 操作系统。且需要网关以 root 身份运行。 此特性依赖目标系统的 ping 和 ifconfig 命令，请确保相关包默认已安装。 一组启用浮动 IP 的网关所在网卡地址应该在一个子网，且内网广播互通（网关实际 IP 和浮动 IP 要求只最后一位地址不一样，如：192.168.3.x）。   功能演示 #    Youtube  Bilibili  什么是浮动 IP #  极限网关基于浮动 IP 来实现高可用，浮动 IP 也叫虚拟 IP 或者动态 IP，我们知道每台服务器之间都必须要有 IP 才能进行通信，一台服务器的 IP 一般是固定的并且一般要提前分配好， 如果这台服务器因为故障挂了的话，这个 IP 以及上面部署的业务也就不能访问了。 而一个浮动 IP 通常是一个公开的、可以路由到的 IP 地址，并且不会自动分配给实体设备。项目管理者临时分配这个动态IP到一个或者多个实体设备。 这个实体设备有自动分配的静态 IP 用于内部网间设备的通讯。这个内部网使用私有地址，这些私有地址不能被路由到。通过浮动 IP 内网实体的服务才能被外网识别和访问。\n为什么需要浮动 IP #  在一个配置好浮动 IP 的典型切换场景是，当出现当前绑定浮动 IP 的机器出现故障的时候，浮动 IP 地址会飘到网络中的另一台设备。新设备无延迟的接替当掉的设备，并对外提供服务。 从而实现网络服务的高可用，对应业务的消费方来说，只需要指定浮动 IP 就可以了。 浮动 IP 非常有用，在某些特定的场景，比如客户端或者 SDK 只允许配置一个服务 IP 地址，所以这个 IP 一定要是高可用的，而极限网关正好解决了这个问题。 使用两个独立的极限网关服务器，最好部署在独立的物理服务器上，两台极限网关构成一组双机热备的状态，任意网关出现故障都能保障前端业务的正常访问。\n如何开启浮动 IP #  极限网关开启浮动 IP 的操作非常简单，通过修改配置文件 gateway.yml，增加如下配置：\nfloating_ip: enabled: true 极限网关能够自动检测网络网卡设备信息，自动绑定虚拟 IP 到内网通信的端口，非常智能，对于使用起来非常简单，默认监听的 IP 为当前机器所在网段的 *.*.*.234。 假设你当前机器所在的物理 IP 是 192.168.3.35，那么默认的浮动 IP 是 192.168.3.234，这个默认处理只是为了方便配置和快速启动，如果你需要使用自定义的浮动 IP 的话，也可以通过补充完整的参数来设置。\n相关参数设置 #  有关浮动 IP 更多完整的配置参数样例如下：\nfloating_ip: enabled: true ip: 192.168.3.234 netmask: 255.255.255.0 interface: en1 各参数说明如下：\n   名称 类型 说明     enabled bool 是否开启浮动 IP，默认是 false   interface string 网卡设备名称，如果不指定，会选择第一个监听非本机地址的设备名称，如果服务器有多张网卡，建议手动设置   ip string 监听的浮动 IP 地址，默认是当前物理网卡所在网段的 *.*.*.234地址，建议手动设置浮动 IP 地址，浮动 IP 地址不能和已有 IP 冲突   netmask string 浮动 IP 的子网掩码，默认是网卡所在子网掩码，或者 255.255.255.0    "});index.add({'id':7,'href':'/docs/references/router/','title':"服务路由",'section':"功能手册",'content':"服务路由 #  极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：\nrouter: - name: my_router default_flow: default_flow tracing_flow: request_logging rules: - method: - PUT - POST pattern: - \u0026quot;/_bulk\u0026quot; - \u0026quot;/{index_name}/_bulk\u0026quot; flow: - bulk_process_flow 路由有几个非常重要的概念：\n flow：请求的处理流程，一个路由里面有三个地方定义 flow default_flow: 默认的处理流，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行 tracing_flow：用于追踪请求状态的流，不受 default_flow 的影响，用于记录请求日志、统计等 rules：根据匹配规则将请求分发到特定的处理流中去，支持请求的 Method、Path 的正则匹配  参数说明 #     名称 类型 说明     name string 路由名称   default_flow string 默认的请求的处理流程名称   tracing_flow string 用于追踪请求的处理流程名称   rules array 路由规则列表，按照数组的先后顺序依次应用   rules.method string 请求的 Method 类型，支持 GET、HEAD、POST、PUT、PATCH、DELETE、CONNECT、OPTIONS、TRACE， * 表示任意类型   rules.pattern string 请求的 URL Path 匹配规则，支持通配符，不允许有重叠匹配   rules.flow string 规则匹配之后执行的处理流程，支持多个 flow 组合，依次顺序执行    Pattern 语法 #     语法 说明 示例     {变量名} 带名称的变量 /{name}   {变量名:regexp} 通过正则来限制变量的匹配规则 /{name:[a-zA-Z]}   {变量名:*} 匹配之后的任意路径，只允许应用在 Pattern 末尾 /{any:*}    更多示例：\nPattern: /user/{user} /user/gordon match /user/you match /user/gordon/profile no match /user/ no match Pattern with suffix: /user/{user}_admin /user/gordon_admin match /user/you_admin match /user/you no match /user/gordon/profile no match /user/gordon_admin/profile no match /user/ no match Pattern: /src/{filepath:*} /src/ match /src/somefile.go match /src/subdir/somefile.go match 其他注意事项：\n Pattern 必须是 / 开头 任意匹配只能作为最后的一个规则  "});index.add({'id':8,'href':'/docs/user-cases/stories/indexing_speedup_for_big_index_rebuild/','title':"某保险业务索引速度百倍提升",'section':"用户案例",'content':"某保险集团业务的索引速度百倍提升之旅 #  业务挑战 #  某大型保险集团的保单查询业务，通过将数据库的常用字段放到 Elasticsearch 里面，用来提升查询性能，集群部署在 14 台物理机上面，每个物理机上面部署了 4 个 Elasticsearch 实例， 整个集群约有 90 多亿条数据，索引主分片存储接近 5 TB，每天的增量更新数据大概在 6 亿条左右，由于业务上的特殊性，全国的所有的业务数据都存放在一个索引里面， 造成了单个索引达到了 210 个分片，批量重建的任务采用 Spark 任务来并行执行，平均的写入速度在 2000~3000 条/s 左右，一次增量重建时间可能需要 2~3 天， 业务数据的更新延迟较大，长时间的重建也会影响正常时间段的业务访问。该技术团队也尝试过直接对 Elasticsearch 层面和 Spark 写入端多轮的测试和调优，发现对整体的写入速度没有太大的提升。\n应用场景 #  通过分析，集群性能应该没有问题，不过由于单个批次写入请求到达 Elasticsearch 之后需要重新再次按照主分片所在节点进行封装转发，而某保的业务索引分片个数太多，每个数据节点最终拿到的请求文档数太小， 客户端一次批次写入要拆分成几百次的小批次请求，并且由于短板原理，最慢的节点处理速度会拖慢整个批次写入的速度，从而造成集群总体吞吐的低下。\n通过评估极限网关，发现极限网关具备提前拆分请求和合并请求的能力，通过提前拆分合并请求到以节点为单位的本地队列，然后通过队列消费程序写入到目标 Elasticsearch 集群，将随机的批次请求转换为顺序的精准投放，如下图：\n极限网关在收到 Spark 请求之后先落地到本地磁盘确保数据不丢失，同时极限网关能够本地计算每个文档与目标数据节点的对应关系，新的数据写入架构如下图所示：\n通过采用极限网关来接收 Spark 的写入请求，整个集群的写入吞吐显著提升，Spark 写数据只花了不到 15 分钟即任务运行结束，网关从收到请求到写完 Elasticsearch 也只花了 20 分钟，服务器的 CPU 资源也充分利用起来了， 各个节点的 CPU 利用率均达到 100%。\n用户收益 #   索引速度提升 20000%\n 通过采用极限网关来作为中间加速层，该集团保单业务的索引重建速度由原来的 2-3 天都重建不完缩减到 20 分钟左右，每日增量 6 亿条数据的全部重建终于也可以快速完成， 索引写入 QPS 峰值也达到了 30 万+，大大缩短了索引重建周期，降低了数据延迟，增强了线上数据的一致性，确保了查询业务的正常使用。\n"});index.add({'id':9,'href':'/docs/tutorial/index_diff/','title':"索引文档级别差异对比",'section':"动手教程",'content':"索引差异对比 #  通过极限网关可以进行索引的文档差异对比，可以对同集群或者跨集群的两个不同的索引进行 diff 比较，对于使用应用双写、CCR 或者其他数据复制方案的场景，可以进行定期 diff 比较来确保数据是否真的一致。\n功能演示 #    如何配置 #  设置目标集群 #  修改配置文件 gateway.yml，设置两个集群资源 source 和 target，增加如下配置：\nelasticsearch: - name: source enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest - name: target enabled: true endpoint: http://localhost:9201 basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: test password: testtest 配置对比任务 #  增加一个服务管道配置，用来处理两个集群的索引文档拉取和对比，如下：\npipelines: - name: index_diff_service processors: - dag: parallel: - dump_hash: #dump es1's doc indices: \u0026quot;medcl-test\u0026quot; scroll_time: \u0026quot;10m\u0026quot; elasticsearch: \u0026quot;source\u0026quot; output_queue: \u0026quot;source_docs\u0026quot; batch_size: 10000 slice_size: 5 - dump_hash: #dump es2's doc indices: \u0026quot;medcl-test\u0026quot; scroll_time: \u0026quot;10m\u0026quot; batch_size: 10000 slice_size: 5 elasticsearch: \u0026quot;target\u0026quot; output_queue: \u0026quot;target_docs\u0026quot; end: - index_diff: diff_queue: \u0026quot;diff_result\u0026quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 上面的配置中，并行使用了 dump_hash 来拉取集群 source 的 medcl-a 索引和取集群 target 的 medcl-b 索引，并以文本结果的方式输出到终端。\n输出结果到 Elasticsearch #  如果 diff 结果比较多，可以选择保存到 Elasticsearch 集群，将上面的 index_diff 处理单元的参数 text_report 设置为 false，并增加如下配置：\npipelines: - name: diff_result_ingest processors: - json_indexing: index_name: \u0026quot;diff_result\u0026quot; elasticsearch: \u0026quot;source\u0026quot; input_queue: \u0026quot;diff_result\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 #in MB 最后导入 仪表板 到 Kibana 即可看到如下效果：\n"});index.add({'id':10,'href':'/docs/references/modules/force_merge/','title':"索引段合并",'section':"功能组件",'content':"主动合并索引分段 #  极限网关内置一个索引分段合并服务，可以主动对索引段文件进行合并，从而提升查询速度，段合并服务支持多个索引的依次顺序处理，并对合并任务状态进行了跟踪处理，避免大量段合并任务并行操作拖慢集群。\n如何开启 #  修改配置文件 gateway.yml，增加如下配置：\nforce_merge: enabled: false elasticsearch: dev min_num_segments: 20 max_num_segments: 1 indices: - index_name 各参数说明如下：\n   名称 类型 说明     enabled bool 是否启用该模块，默认是 false   elasticsearch string 操作的 Elasticsearch 集群 ID   min_num_segments int 超过多少分片的索引才会执行主动分片合并，以索引为单位的统计数目   max_num_segments int 将分片下的段文件合并之后，最多生成的段文件个数   indices array 需要进行分片合并的索引列表   discovery object 自动发现索引的相关设置   discovery.min_idle_time string 满足段合并条件的最小时间跨度，默认 1d   discovery.interval string 重新检测需要进行段合并的时间间隔   discovery.rules array 自动进行索引检测的索引匹配规则   discovery.rules.index_pattern string 要进行索引段文件合并的索引通配符   discovery.rules.timestamp_fields array 代表索引时间戳的字段列表    "});index.add({'id':11,'href':'/docs/user-cases/stories/a_cross_region_cluster_access_locality/','title':"跨云集群的就近本地访问",'section':"用户案例",'content':"跨云集群的就近本地访问 #  业务需求 #  作业帮为了确保某个业务 Elasticsearch 集群的高可用，在百度云和华为云上面采取了双云部署，即将单个 Elasticsearch 集群跨云进行部署，并且要求业务请求优先访问本地云。\nElasticsearch 单集群双云实现 #  Elasticsearch 集群采用 Master 与 Data 节点分离的架构。 目前主力云放 2 个 Master，另外一个云放一个 Master。 主要考虑就是基础设施故障中，专线故障问题是大多数，某个云厂商整体挂的情况基本没有。 所以设置了主力云，当专线故障时，主力云的 Elasticsearch 是可以读写的，业务把流量切到主力云就行了。\n具体配置方式如下。\n首先，在 Master 节点上设置：\ncluster.routing.allocation.awareness.attributes: zone_id cluster.routing.allocation.awareness.force.zone_id.values: zone_baidu,zone_huawei 然后分别在百度云上数据节点上设置：\nnode.attr.zone_id: zone_baidu 和华为云上数据节点上设置：\nnode.attr.zone_id: zone_huawei 创建索引采用 1 副本，可以保证百度云与华为云上都有一份相同的数据。\n业务访问方式如下图：\n 百度云业务 -\u0026gt; 百度 lb -\u0026gt; INFINI Gateway (百度) -\u0026gt; Elasticsearch （百度云 data 节点） 华为云业务 -\u0026gt; 华为 lb -\u0026gt; INFINI Gateway (华为) -\u0026gt; Elasticsearch （华为云 data 节点）  极限网关配置 #  Elasticsearch 支持一个 Preference 参数来设置请求的优先访问，通过在两个云内部的极限网关分别设置各自请求默认的 Preference 参数，让各个云内部的请求优先发往本云内的数据节点，即可实现请求的就近访问。\n具体的百度云的 INFINI Gateway 配置如下（华为云大体相同，就不重复贴了）：\npath.data: data path.logs: log entry: - name: es-test enabled: true router: default network: binding: 0.0.0.0:9200 reuse_port: true router: - name: default default_flow: es-test flow: - name: es-test filter: - set_request_query_args: args: - preference -\u0026gt; _prefer_nodes:data-baidu01,data-baidu02 #通过配置preference的_prefer_nodes为所有的百度data节点，来实现百度云的业务优先访问百度云的节点，最大程度避免跨云访问，对业务更友好。 when: contains: _ctx.request.path: /_search - elasticsearch: elasticsearch: default refresh: enabled: true interval: 10s roles: include: - data #配置为data，请求只发送到data节点 tags: include: - zone_id: zone_baidu #只转发给百度云里面的节点 elasticsearch: - name: default enabled: true endpoint: http://10.10.10.10:9200 discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: elastic 总结与收益 #  引入极限网关前故障回顾 #  百度云业务访问 Elasticsearch 集群，拉取每天的增量数据同步到 Hive 集群，其中有几个任务失败后，又重新同步。结果是部分数据从华为云的 Elasticsearch 节点拉取到百度云的 Hive 集群中，数据量巨大导致跨云专线流量监控告警。由于线上业务、MySQL、Redis、Elasticsearch 等使用同一根专线， 此次故障影响面较大。临时解决方案是业务修改语句加入 Preference 参数来实现业务只拉取本地云数据，减少对专线的占用。但是一方面业务改造及维护成本较高；另一方面作为 DBA 会担心业务改造有疏漏、新增业务遗忘 Preference 参数、以及后期调整成本较高，这始终是一个风险点。\n引入极限网关的收益 #  在原有架构上加入极限网关，可以在业务不修改代码的情况下做到优先访问本地云，提升访问速度的同时，最大限度减少对专线的压力。\n 作者：赵青，前网易 DBA，工作主要涉及 Oracle、MySQL、Redis、Elasticsearch、Tidb、OB 等组件的运维以及运维自动化、平台化、智能化等工作。现就职于作业帮。\n "});index.add({'id':12,'href':'/docs/getting-started/configuration/','title':"配置网关",'section':"入门指南",'content':"配置 #  极限网关支持多种方式来修改配置。\n命令行参数 #  极限网关提供了命令行参数如下：\n✗ ./bin/gateway --help Usage of ./bin/gateway: -config string the location of config file, default: gateway.yml (default \u0026quot;gateway.yml\u0026quot;) -cpu int the number of CPUs to use (default -1) -cpuprofile string write cpu profile to this file -daemon run in background as daemon -debug run in debug mode, gateway will quit with panic error -log string the log level,options:trace,debug,info,warn,error (default \u0026quot;info\u0026quot;) -memprofile string write memory profile to this file -pidfile string pidfile path (only for daemon mode) -pprof string enable and setup pprof/expvar service, eg: localhost:6060 , the endpoint will be: http://localhost:6060/debug/pprof/ and http://localhost:6060/debug/vars -v version 常用的说明如下：\n config，指定配置文件名，默认的配置文件名为当前执行命令所在目录的 gateway.yml，如果你的配置文件放置在其他地方，可以通过指定参数来进行选择。 daemon，将网关切换到后台执行，一般还需要结合 pidfile 来保存进程号，方便后续的进程操作。  配置文件 #  极限网关的大部分配置都可以通过 gateway.yml 来进行配置，配置修改完成之后，需要重启网关程序才能生效。\n定义入口 #  每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：\nentry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 这里定义了一个名为 es_gateway 的服务入口，监听的地址是 0.0.0.0:8000，使用了一个名为 default 的路由来处理请求。\n定义路由 #  极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：\nrouter: - name: default default_flow: cache_first 这里定义了一个名为 default 的路由，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行。\n定义流程 #  一个请求流程定义了一系列请求处理的工作单元，是一个典型的管道式工作方式，一个典型的配置示例如下：\nflow: - name: cache_first filter: - get_cache: - elasticsearch: elasticsearch: prod - set_cache: 上面的配置定义了一个名为 cache_first 的处理流，使用了三个不同的 filter，分别是 get_cache、elasticsearch 和 set_cache，这些 filter 会依据配置的先后顺序依次执行，注意每个 filter 名称后面要带上一个 :。 各个 filter 的处理结果分别如下：\n get_cache，这个 filter 主要用来从缓存里面拿数据，如果之前发生过相同的请求，并且缓存还存在且有效的情况下，这个 filter 可以直接拿到缓存然后立即返回，不用继续往下处理； elasticsearch，这个 filter 主要用来将请求转发给后端的 Elasticsearch 集群，并且将 Elasticsearch 返回的响应内容继续往下传递； set_cache，这个 filter 会将执行结果缓存到本地内存，有一些参数限制，比如状态码，请求大小等，并设置一定的过期时间，以方便下次重复请求可以直接使用缓存，一般要和 get_cache 组合使用。  定义资源 #  这里的资源主要是指 Elasticsearch 后端服务器资源，极限网关支持多个 Elasticsearch 集群，可以实现将请求转发到多个不同集群，也可以支持请求的蓝绿发布、灰度切换等，定义一个 Elasticsearch 后端资源的方式示例如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 通过参数 endpoint 来设置 Elasticsearch 的访问地址，如果 Elasticsearch 开启了身份认证，可以通过 basic_auth 来指定用户名和密码信息，该用户需要有能够获取集群状态信息的权限。 通过参数 discover 可以开启自动的后端节点的自动发现，用于自动检测后端节点的情况，能够自动识别新增和离线的节点。\n通过这些基本的配置，我们就可以正常的代理 Elasticsearch 的请求了，关于每个组件更详细完整的参数，请参考 功能手册。\n"});index.add({'id':13,'href':'/docs/getting-started/docker/','title':"容器部署",'section':"入门指南",'content':"容器部署 #  极限网关支持容器方式部署，可以运行在 K8s 集群环境。\n安装演示 #    下载镜像 #  极限网关的镜像发布在 Docker 的官方仓库，地址如下：\n https://hub.docker.com/r/infinilabs/gateway\n使用下面的命令即可获取最新的容器镜像：\ndocker pull infinilabs/gateway:latest 验证镜像 #  将镜像下载到本地之后，可以看到极限网关的容器镜像非常小，只有不到 25MB，所以下载的速度应该是非常快的。\n✗ docker images REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/gateway latest fdae74b64e1a 47 minutes ago 23.5MB 创建配置 #  现在需要创建一个配置文件 gateway.yml，来进行基本的配置，如下：\npath.data: data path.logs: log entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 200000 network: binding: 0.0.0.0:8000 - name: my_es_entry1 enabled: true router: my_router max_concurrency: 200000 network: binding: 0.0.0.0:8001 tls: enabled: true flow: - name: simple_flow filter: #comment out any filter sections, like you don't need cache or rate-limiter - elasticsearch: elasticsearch: dev #elasticsearch configure reference name router: - name: my_router default_flow: simple_flow elasticsearch: - name: dev enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest Note: 上面配置里面的 Elasticsearch 的相关配置，请改成实际的服务器连接地址和认证信息：\n启动网关 #  使用如下命令启动极限网关容器：\ndocker run -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:latest 验证网关 #  如果都运行正常的话，应该可以看到如下的信息：\n➜ /tmp docker run -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:latest ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. [GATEWAY] 1.0.0_SNAPSHOT, b61758c, Mon Dec 28 14:32:02 2020 +0800, medcl, no panic by default [12-30 05:26:41] [INF] [instance.go:24] workspace: data/gateway/nodes/0 [12-30 05:26:41] [INF] [runner.go:59] pipeline: primary started with 1 instances [12-30 05:26:41] [INF] [entry.go:257] entry [es_gateway] listen at: http://0.0.0.0:8000 [12-30 05:26:41] [INF] [app.go:247] gateway now started. [12-30 05:26:45] [INF] [reverseproxy.go:196] elasticsearch [prod] endpoints: [] =\u0026gt; [192.168.3.201:9200] 如果希望容器运行在后台，加上 -d 参数，如下：\ndocker run -d -p 2900:2900 -p 8000:8000 -v=`pwd`/gateway.yml:/gateway.yml infinilabs/gateway:latest 使用命令行或者浏览器访问地址： http://localhost:8000/ 应该就能正常访问 Elasticsearch 了，如下：\n➜ /tmp curl -v http://localhost:8000/ * Trying ::1... * TCP_NODELAY set * Connected to localhost (::1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Wed, 30 Dec 2020 05:12:39 GMT \u0026lt; Content-Type: application/json; charset=UTF-8 \u0026lt; Content-Length: 480 \u0026lt; UPSTREAM: 192.168.3.201:9200 \u0026lt; { \u0026quot;name\u0026quot; : \u0026quot;node1\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;pi\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;Z_HcN_6ESKWicV-eLsyU4g\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;6.4.2\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;04711c2\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2018-09-26T13:34:09.098244Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;7.4.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;5.6.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;5.0.0\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } * Connection #0 to host localhost left intact * Closing connection 0 Docker Compose #  还可以使用 docker compose 来管理容器实例，新建一个 docker-compose.yml 文件如下：\nversion: \u0026quot;3.5\u0026quot; services: infini-gateway: image: infinilabs/gateway:latest ports: - 2900:2900 - 8000:8000 container_name: \u0026quot;infini-gateway\u0026quot; volumes: - ../gateway.yml:/gateway.yml volumes: dist: 在配置文件所在目录，执行如下命令即可启动，如下：\n➜ docker-compose up Starting infini-gateway ... done Attaching to infini-gateway infini-gateway | ___ _ _____ __ __ __ _ infini-gateway | / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ infini-gateway | / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _/ infini-gateway | / /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\ infini-gateway | \\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/ infini-gateway | infini-gateway | [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway. infini-gateway | [GATEWAY] 1.0.0_SNAPSHOT, b61758c, Mon Dec 28 14:32:02 2020 +0800, medcl, no panic by default infini-gateway | [12-30 13:24:16] [INF] [instance.go:24] workspace: data/gateway/nodes/0 infini-gateway | [12-30 13:24:16] [INF] [api.go:244] api server listen at: http://0.0.0.0:2900 infini-gateway | [12-30 13:24:16] [INF] [runner.go:59] pipeline: primary started with 1 instances infini-gateway | [12-30 13:24:16] [INF] [entry.go:257] entry [es_gateway] listen at: http://0.0.0.0:8000 infini-gateway | [12-30 13:24:16] [INF] [app.go:247] gateway now started. "});index.add({'id':14,'href':'/docs/user-cases/','title':"用户案例",'section':"Docs",'content':"用户案例 #  谁在用? #  如果您正在使用 极限网关 并且您觉得还不错愿意告诉大家您也在用的话，请在这个 Github Discussion里留言告诉我们，感谢您的支持和鼓励。\n国内用户 #                              "});index.add({'id':15,'href':'/docs/getting-started/optimization/','title':"系统调优",'section':"入门指南",'content':"系统调优 #  要保证极限网关运行在最佳状态，其所在服务器的操作系统也需要进行相应的调优，以 Linux 为例。\n系统参数 #  vi /etc/security/limits.conf\n* soft nofile 1024000 * hard nofile 1024000 * soft memlock unlimited * hard memlock unlimited root soft nofile 1024000 root hard nofile 1024000 root soft memlock unlimited 内核调优 #  vi /etc/sysctl.conf\nnet.ipv4.ip_forward = 1 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.ip_nonlocal_bind=1 net.ipv4.tcp_tw_reuse=1 net.ipv4.tcp_timestamps=1 net.ipv4.tcp_syncookies=1 net.ipv4.tcp_max_syn_backlog=65535 net.ipv4.tcp_synack_retries=0 net.core.somaxconn=32768 net.core.netdev_max_backlog=65535 net.core.rmem_max=4194304 net.core.wmem_max=4194304 fs.file-max=10485760 vm.max_map_count=262144 执行下面的命令验证配置参数是否合法。\nsysctl -p 最后重启操作系统让配置生效。\n"});index.add({'id':16,'href':'/docs/references/flow/','title':"处理流程",'section':"功能手册",'content':"处理流程 #  流程定义 #  每一个网关接收到的请求都会通过一系列的流程处理，最后才返回给客户端，流程的定义在极限网关里面叫做 flow，以下面的这个例子为例：\nflow: - name: hello_world filter: - echo: str: \u0026quot;hello gateway\\n\u0026quot; repeat: 1 - name: not_found filter: - echo: str: '404 not found\\n' repeat: 1 上面的例子定义了两个 flow hello_world 和 not_found， 每个 flow 都使用了一个名为 echo 的过滤器，用来输出一段字符串，每个 flow 下面可以定义一系列 filter，他们按照定义的顺序依次执行。\n语法说明 #  极限网关采用约定的格式来定义流程，并且支持灵活的条件参数来进行逻辑判断，具体的格式定义如下：\nflow: - name: \u0026lt;flow_name\u0026gt; filter: - \u0026lt;filter_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; ... 上面的 filter_name 代表具体的某个过滤器名称，用来执行特定的任务，when 下面的 condition 用来定义特定的满足执行该任务的条件参数，不满足条件的情况下会跳过该过滤器任务的执行，parameters 里面设置的该过滤器相关的参数，如果多个参数依次换行即可。\n条件判断 #  极限网关的流程定义支持复杂的逻辑判断，可以让特定的过滤器只有在满足某种条件下才会执行，举例如下：\nfilter: - if: \u0026lt;condition\u0026gt; then: \u0026lt;1\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; ... else: \u0026lt;2\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;filter_name\u0026gt;: \u0026lt;parameters\u0026gt; ... 参数说明 #     名称 类型 说明     then array 表示满足 condition 条件定义后才会执行的一系列过滤器定义   else array 不满足条件才会执行的一系列过滤器定义，可不设置    使用 if 可以对多个 filter 来进行条件判断进行逻辑选择，使用 when 来对单个过滤器进行判断是否执行。\n条件类型 #  在流程里面定义的各种 condition 条件可以使用当前 请求上下文 来判断是否满足特定条件，从而实现逻辑处理，支持布尔表达式（AND、NOT、OR）来进行组合，完整的条件类型如下：\n equals contains regexp range network has_fields in queue_has_lag cluster_available or and not  equals #  使用 equals 条件来判断字段的内容是否为指定的值，用于字符和数字类型的精确匹配。\n如下面的例子判断是否请求的方法是否为 GET 类型，_ctx 是访问请求上下文的特定关键字：\nequals: _ctx.request.method: GET contains #  使用 contains 条件来判断字段的内容是否包含特定的字符值，仅支持字符字段类型。\n如下面的例子为判断返回的请求体里面是否包含错误关键字：\ncontains: _ctx.response.body: \u0026quot;error\u0026quot; regexp #  使用 regexp 条件可以用来判断某个字段的内容是否满足正则表达式的匹配规则，仅支持字符字段类型。\n如下面的例子判断请求的 uri 是否为查询请求：\nregexp: _ctx.request.uri: \u0026quot;.*/_search\u0026quot; range #  使用 range 条件用来判断字段的值是否满足特定的范围，支持 lt、lte、gt 和 gte 几种类型，仅支持数字字段类型。\n如下面判断状态码范围的例子：\nrange: _ctx.response.code: gte: 400 以及如下组合来判断响应字节大小范围的例子：\nrange: _ctx.request.body_length.gte: 100 _ctx.request.body_length.lt: 5000 network #  如果某个字段的值为 IP 字段类型，可以使用 network 条件可以判断该字段是否满足某个特定的网络范围，支持标准的 IPv4 和 IPv6，支持 CIDR 的表达方式，或者是以下范围别名：\n   名称 说明     loopback 匹配本地回环网络地址，范围：127.0.0.0/8 或者 ::1/128。   unicast 匹配 RFC 1122、RFC 4632 和 RFC 4291 中定义的全球单播地址，但 IPv4 广播地址 (255.255.255.255) 除外。包括私有地址范围。   multicast 匹配广播地址。   interface_local_multicast 匹配 IPv6 接口本地组播地址。   link_local_unicast 匹配链路本地单播地址。   link_local_multicast 匹配链路本地广播地址。   private 匹配 RFC 1918 (IPv4) 和 RFC 4193 (IPv6) 中定义的私有地址范围。   public 匹配除了本机、未指定、IPv4 广播、链路本地单播、链路本地多播、接口本地多播或私有地址以外的公网地址。   unspecified 匹配未指定的地址（IPv4 地址 0.0.0.0 或 IPv6 地址 :: ）。    如下面的例子匹配本机网络地址：\nnetwork: _ctx.request.client_ip: private 或者指定一个子网：\nnetwork: _ctx.request.client_ip: '192.168.3.0/24' 支持数组，任意满足即可：\nnetwork: _ctx.request.client_ip: ['192.168.3.0/24', '10.1.0.0/8', loopback] has_fields #  如果要判断某个字段是否存在，可以使用 has_fields，支持一个或者多个字符字段，如下：\nhas_fields: ['_ctx.request.user'] in #  如果要判断某个字段是否存在指定数组的任意值，可以使用 in，支持单个字段的判断，仅支持字符和数值类型。\n如下判断返回状态码：\nin: _ctx.response.status: [ 403,404,200,201 ] queue_has_lag #  使用 queue_has_lag 可以来判断某个或多个本地磁盘队列是否存在堆积的情况，如下：\nqueue_has_lag: [ \u0026quot;prod\u0026quot;, \u0026quot;prod-500\u0026quot; ] 如果希望设置队列大于指定深度可以在队列的名称后面加上 \u0026gt;队列深度，如：\nqueue_has_lag: [ \u0026quot;prod\u0026gt;10\u0026quot;, \u0026quot;prod-500\u0026gt;10\u0026quot; ] 上面的例子表示，只有当队列深度超过 10 的情况下才满足条件。\ncluster_available #  使用 cluster_available 可以判断某个或多个 Elasticsearch 集群的服务可用性，如下：\ncluster_available: [\u0026quot;prod\u0026quot;] or #  使用 or 来组合多个任意可选条件，格式如下：\nor: - \u0026lt;condition1\u0026gt; - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; ... 举例如下：\nor: - equals: _ctx.response.code: 304 - equals: _ctx.response.code: 404 and #  使用 and 来组合多个必要条件，格式如下：\nand: - \u0026lt;condition1\u0026gt; - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; ... 举例如下：\nand: - equals: _ctx.response.code: 200 - equals: _ctx.status: OK 还可以对 and 和 or 条件进行灵活组合，如下：\nor: - \u0026lt;condition1\u0026gt; - and: - \u0026lt;condition2\u0026gt; - \u0026lt;condition3\u0026gt; not #  如果要对某个条件取反，使用 not 即可，格式如下：\nnot: \u0026lt;condition\u0026gt; 举例如下：\nnot: equals: _ctx.status: OK "});index.add({'id':17,'href':'/docs/references/elasticsearch/','title':"Elasticsearch",'section':"功能手册",'content':"Elasticsearch #  定义资源 #  极限网关支持多集群的访问，支持不同的版本，每个集群作为一个 Elasticsearch 后端资源，可以后续被极限网关的多个地方使用，以下面的这个例子为例：\nelasticsearch: - name: local enabled: true endpoint: https://127.0.0.1:9200 - name: dev enabled: true endpoint: https://192.168.3.98:9200 basic_auth: username: elastic password: pass - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: pass 上面的例子定义了一个名为 local 的本地开发测试集群，和一个名为 dev 的开发集群。开发集群开启了身份验证，这里也定义了相应的用户名和密码。 最后还定义了一个名为 prod 的生产集群，并且通过参数 discovery 开启了集群的节点拓扑自动发现和更新。\n参数说明 #     名称 类型 说明     name string Elasticsearch 集群名称   enabled bool 是否启用   endpoint string Elasticsearch 访问地址，如: http://localhost:9200   endpoints array Elasticsearch 访问地址列表，支持多个入口地址，用于冗余   schema string 协议类型，http 或者 https   host string Elasticsearch 主机，格式：localhost:9200，host 和 endpoint 任意选择一种配置方式即可   hosts array Elasticsearch 主机列表，支持多个入口地址，用于冗余   basic_auth object 身份认证信息   basic_auth.username string 用户名   basic_auth.password string 密码   discovery object 集群发现设置   discovery.enabled bool 是否启用集群拓扑发现   discovery.refresh object 集群拓扑更新设置   discovery.refresh.enabled bool 是否启用集群拓扑自动更新   discovery.refresh.interval string 集群拓扑自动更新时间间隔   traffic_control object 集群按节点级别的总体流量控制   traffic_control.max_bytes_per_node int 最大允许的每秒请求字节数   traffic_control.max_qps_per_node int 最大允许的每秒请求次数，不区分读写    "});index.add({'id':18,'href':'/docs/references/context/','title':"请求上下文",'section':"功能手册",'content':"请求上下文 #  什么是上下文 #  上下文是极限网关用来访问当前运行环境下相关信息的入口，如请求的来源和配置信息等等，使用关键字 _ctx 即可访问相应的字段，如：_ctx.request.uri 表示请求的 URL 地址。\n内置请求上下文 #  HTTP 请求内置的 _ctx 上下文对象主要包括如下：\n   名称 类型 说明     id uint64 请求的唯一 ID   tls bool 表示请求是否 TLS   remote_addr string 客户端来源 IP   local_addr string 网关本地 IP   elapsed int64 请求已执行时间（毫秒）   request.* object 描述请求信息   response.* object 描述响应信息    request #  request 对象包含以下属性：\n   名称 类型 说明     host string 访问的目标主机名/域名   method string 请求类型   uri string 请求完整地址   path string 请求路径   query_args map Url 请求参数   user string 发起请求的用户名   header map Header 参数   body string 请求体   body_json object JSON 请求体对象   body_length int 请求体长度    如果客户端提交的请求体数据类型是 JSON 格式，可以通过 body_json 来直接访问，举例如下：\ncurl -u tesla:password -XGET \u0026quot;http://localhost:8000/medcl/_search?pretty\u0026quot; -H 'Content-Type: application/json' -d' { \u0026quot;query\u0026quot;:{ \u0026quot;bool\u0026quot;:{ \u0026quot;must\u0026quot;:[{\u0026quot;match\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;A\u0026quot;}},{\u0026quot;match\u0026quot;:{\u0026quot;age\u0026quot;:18}}] }\t}, \u0026quot;size\u0026quot;:900, \u0026quot;aggs\u0026quot;: { \u0026quot;total_num\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;name1\u0026quot;, \u0026quot;size\u0026quot;: 1000000 } } } }' 在 JSON 里面通过 . 来标识路径，如果是数组则使用 [下标] 来访问指定的元素，比如可以使用一个 dump 过滤器来进行调试，如下：\n - name: cache_first filter: - dump: context: - _ctx.request.body_json.size - _ctx.request.body_json.aggs.total_num.terms.field - _ctx.request.body_json.query.bool.must.[1].match.age 输出结果如下：\n_ctx.request.body_json.size : 900 _ctx.request.body_json.aggs.total_num.terms.field : name1 _ctx.request.body_json.query.bool.must.[1].match.age : 18 response #  response 对象包含以下属性：\n   名称 类型 说明     status int 请求状态码   header map Header 参数   content_type string 响应请求体类型   body string 响应体   body_length int 响应体长度    "});index.add({'id':19,'href':'/docs/troubleshooting/','title':"常见问题",'section':"Docs",'content':"常见问题及故障处理 #  这里主要收集极限网关使用过程中遇到的常见问题及处理办法，欢迎反馈提交到 这里。 故\n常见问题 #  写入速度没有提升 #  问题描述：为什么我用了极限网关的 bulk_reshuffle，写入速度没有提升呢？\n问题解答：如果你的集群节点总数太少，比如低于 10 个数据节点或者索引吞吐低于 15w/s，你可能没有必要使用这个功能或者关注点不应该在写入性能上面， 因为集群规模太小，Elasticsearch 因为转发性能和请求分发造成的影响不是特别明显，走不走网关理论上性能不会差距很大。 当然使用 bulk_reshuffle 还有其他好处，比如数据先落地网关队列可以解耦后端 Elasticsearch 故障的影响。\n常见故障 #  端口重用不支持的问题 #  错误提示：The OS doesn\u0026rsquo;t support SO_REUSEPORT: cannot enable SO_REUSEPORT: protocol not available\n问题描述：极限网关默认开启端口重用，用于多进程共享端口，在旧版本的 Linux 内核中需要打补丁才能使用。\n解决方案：可以通过修改监听网络的配置，将 reuse_port 改成 false，关闭端口重用：\n**. network: binding: 0.0.0.0:xx reuse_port: false Elasticsearch 用户权限不够 #  错误提示：[03-10 14:57:43] [ERR] [app.go:325] shutdown: json: cannot unmarshal object into Go value of type []adapter.CatIndexResponse\n问题描述：极限网关 Elasticsearch 配置开启 discovery 的情况下，如果用户权限给的不够，会提示这个错误，因为需要访问相关的 Elasticsearch API 来获取集群的信息。\n解决方案：给相关的 Elasticsearch 用户赋予所有索引的 monitor 和 view_index_metadata 权限即可。\n"});index.add({'id':20,'href':'/docs/getting-started/benchmark/','title':"性能测试",'section':"入门指南",'content':"性能测试 #  推荐使用 Elasticsearch 专属压测工具 Loadgen 来对网关进行性能压测。\nLoadgen 的特点：\n 性能强劲 轻量级无依赖 支持模板化参数随机 支持高并发 支持压测端均衡流量控制   下载地址： http://release.elasticsearch.cn/loadgen/\n Loadgen #  Loadgen 使用非常简单，下载解压之后会得到两个文件，一个可执行程序和一个配置文件 loadgen.yml，配置文件样例如下：\nvariables: - name: ip type: file path: test/ip.txt - name: user type: file path: test/user.txt - name: id type: sequence - name: uuid type: uuid - name: now_local type: now_local - name: now_utc type: now_utc - name: now_unix type: now_unix requests: - request: has_variable: true method: GET basic_auth: username: elastic password: pass url: http://localhost:8000/medcl/_search body: '{ \u0026quot;query\u0026quot;: {\u0026quot;match\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;$[[user]]\u0026quot; }}}' 变量的使用 #  上面的配置中，variables 用来定义变量参数，根据 name 来设置变量标识，在构造请求的使用 $[[变量名]] 即可访问该变量的值，变量目前支持的类型有：\n   类型 说明     file 文件型外部变量参数   sequence 自增数字类型的变量   uuid UUID 字符类型的变量   now_local 当前时间、本地时区   now_utc 当前时间、UTC 时区   now_unix 当前时间、Unix 时间戳    file 类型变量参数加载自外部文本文件，每行一个变量参数，访问该变量时每次随机取其中一个，变量里面的定义格式举例如下：\n➜ loadgen git:(master) ✗ cat test/user.txt medcl elastic 请求的定义 #  配置节点 requests 用来设置 Loadgen 将依次执行的请求，支持固定参数的请求，通过设置 has_variable 为 true 也可支持模板变量参数化构造请求，以下是一个普通的查询请求：\nrequests: - request: has_variable: true method: GET basic_auth: username: elastic password: pass url: http://localhost:8000/medcl/_search?q=name:$[[user]] 上面的查询对 medcl 索引进行了查询，并对 name 字段执行一个查询，每次请求的值来自随机变量 user。\n命令行参数 #  Loadgen 会循环执行配置文件里面定义的请求，默认 Loadgen 只会运行 5s 就自动退出了，如果希望延长运行时间或者加大并发可以通过启动的时候设置参数来控制，通过查看帮助命令如下：\n➜ loadgen git:(master) ✗ ./bin/loadgen --help Usage of ./bin/loadgen: -c int Number of concurrent threads (default 1) -compress Compress requests with gzip -config string the location of config file, default: loadgen.yml (default \u0026quot;loadgen.yml\u0026quot;) -cpu int the number of CPUs to use (default -1) -cpuprofile string write cpu profile to this file -d int Duration of tests in seconds (default 5) -daemon run in background as daemon -debug run in debug mode, loadgen will quit with panic error -l int Limit total requests (default -1) -log string the log level,options:trace,debug,info,warn,error (default \u0026quot;info\u0026quot;) -memprofile string write memory profile to this file -pidfile string pidfile path (only for daemon mode) -pprof string enable and setup pprof/expvar service, eg: localhost:6060 , the endpoint will be: http://localhost:6060/debug/pprof/ and http://localhost:6060/debug/vars -r int Max requests per second (fixed QPS) (default -1) -v\tversion 执行压测 #  执行 Loadgen 程序即可执行压测，如下:\n➜ loadgen git:(master) ✗ ./bin/loadgen -d 30 -c 100 -compress __ ___ _ ___ ___ __ __ / / /___\\/_\\ / \\/ _ \\ /__\\/\\ \\ \\ / / // ///_\\\\ / /\\ / /_\\//_\\ / \\/ / / /__/ \\_// _ \\/ /_// /_\\\\//__/ /\\ / \\____|___/\\_/ \\_/___,'\\____/\\__/\\_\\ \\/ [LOADGEN] A http load generator and testing suit. [LOADGEN] 1.0.0_SNAPSHOT, 83f2cb9, Sun Jul 4 13:52:42 2021 +0800, medcl, support single item in dict files [07-19 16:15:00] [INF] [instance.go:24] workspace: data/loadgen/nodes/0 [07-19 16:15:00] [INF] [loader.go:312] warmup started [07-19 16:15:00] [INF] [app.go:306] loadgen now started. [07-19 16:15:00] [INF] [loader.go:316] [GET] http://localhost:8000/medcl/_search [07-19 16:15:00] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:1,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}} [07-19 16:15:00] [INF] [loader.go:316] [GET] http://localhost:8000/medcl/_search?q=name:medcl [07-19 16:15:00] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:1,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:{\u0026quot;value\u0026quot;:0,\u0026quot;relation\u0026quot;:\u0026quot;eq\u0026quot;},\u0026quot;max_score\u0026quot;:null,\u0026quot;hits\u0026quot;:[]}} [07-19 16:15:01] [INF] [loader.go:316] [POST] http://localhost:8000/_bulk [07-19 16:15:01] [INF] [loader.go:317] status: 200,\u0026lt;nil\u0026gt;,{\u0026quot;took\u0026quot;:120,\u0026quot;errors\u0026quot;:false,\u0026quot;items\u0026quot;:[{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;medcl-y4\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c3qj9123r0okahraiej0\u0026quot;,\u0026quot;_version\u0026quot;:1,\u0026quot;result\u0026quot;:\u0026quot;created\u0026quot;,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:2,\u0026quot;successful\u0026quot;:1,\u0026quot;failed\u0026quot;:0},\u0026quot;_seq_no\u0026quot;:5735852,\u0026quot;_primary_term\u0026quot;:3,\u0026quot;status\u0026quot;:201}}]} [07-19 16:15:01] [INF] [loader.go:325] warmup finished 5253 requests in 32.756483336s, 524.61KB sent, 2.49MB received [Loadgen Client Metrics] Requests/sec:\t175.10 Request Traffic/sec:\t17.49KB Total Transfer/sec:\t102.34KB Avg Req Time:\t5.711022ms Fastest Request:\t440.448µs Slowest Request:\t3.624302658s Number of Errors:\t0 Number of Invalid:\t0 Status 200:\t5253 [Estimated Server Metrics] Requests/sec:\t160.37 Transfer/sec:\t93.73KB Avg Req Time:\t623.576686ms Loadgen 在正式压测之前会将所有的请求执行一次来进行预热，如果出现错误会提示是否继续，预热的请求结果也会输出到终端，执行完成之后会输出执行的摘要信息。\n 因为 Loadgen 最后的结果是所有请求全部执行完成之后的累计统计，可能存在不准的问题，建议通过打开 Kibana 的监控仪表板来实时查看 Elasticsearch 的各项运行指标。\n 模拟批量写入 #  使用 Loadgen 来模拟 bulk 批量写入也非常简单，在请求体里面配置一条索引操作，然后使用 body_repeat_times 参数来随机参数化复制若干条请求即可完成一批请求的准备，如下：\n - request: method: POST has_variable: true basic_auth: username: test password: testtest url: http://localhost:8000/_bulk body_repeat_times: 1000 body: \u0026quot;{ \\\u0026quot;index\\\u0026quot; : { \\\u0026quot;_index\\\u0026quot; : \\\u0026quot;medcl-y4\\\u0026quot;,\\\u0026quot;_type\\\u0026quot;:\\\u0026quot;doc\\\u0026quot;, \\\u0026quot;_id\\\u0026quot; : \\\u0026quot;$[[uuid]]\\\u0026quot; } }\\n{ \\\u0026quot;id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot;,\\\u0026quot;field1\\\u0026quot; : \\\u0026quot;$[[user]]\\\u0026quot;,\\\u0026quot;ip\\\u0026quot; : \\\u0026quot;$[[ip]]\\\u0026quot;,\\\u0026quot;now_local\\\u0026quot; : \\\u0026quot;$[[now_local]]\\\u0026quot;,\\\u0026quot;now_unix\\\u0026quot; : \\\u0026quot;$[[now_unix]]\\\u0026quot; }\\n\u0026quot; 限制客户端压力 #  使用 Loadgen 并设置命令行参数 -r 可以限制客户端发送的每秒请求数，从而评估固定压力下 Elasticsearch 的响应时间和负载情况，如下：\n➜ loadgen git:(master) ✗ ./bin/loadgen -d 30 -c 100 -r 100  注意，在大量并发下，此客户端吞吐限制可能不完全准确。\n 限制请求的总条数 #  通过设置参数 -l 可以控制客户端发送的请求总数，从而制造固定的文档，修改配置如下：\nrequests: - request: method: POST has_variable: true basic_auth: username: test password: testtest url: http://localhost:8000/medcl-test/doc2/_bulk body_repeat_times: 1 body: \u0026quot;{ \\\u0026quot;index\\\u0026quot; : { \\\u0026quot;_index\\\u0026quot; : \\\u0026quot;medcl-test\\\u0026quot;, \\\u0026quot;_id\\\u0026quot; : \\\u0026quot;$[[uuid]]\\\u0026quot; } }\\n{ \\\u0026quot;id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot;,\\\u0026quot;field1\\\u0026quot; : \\\u0026quot;$[[user]]\\\u0026quot;,\\\u0026quot;ip\\\u0026quot; : \\\u0026quot;$[[ip]]\\\u0026quot; }\\n\u0026quot; 每次请求只有一个文档，然后执行 loadgen\n./bin/loadgen -config loadgen-gw.yml -d 600 -c 100 -l 50000 执行完成之后，Elasticsearch 的索引 medcl-test 将增加 50000 条记录。\n使用自增 ID 来确保文档的顺序性 #  如果希望生成的文档编号自增有规律，方便进行对比，可以使用 sequence 类型的自增 ID 来作为主键，内容也不要用随机数，如下：\nrequests: - request: method: POST has_variable: true basic_auth: username: test password: testtest url: http://localhost:8000/medcl-test/doc2/_bulk body_repeat_times: 1 body: \u0026quot;{ \\\u0026quot;index\\\u0026quot; : { \\\u0026quot;_index\\\u0026quot; : \\\u0026quot;medcl-test\\\u0026quot;, \\\u0026quot;_id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot; } }\\n{ \\\u0026quot;id\\\u0026quot; : \\\u0026quot;$[[id]]\\\u0026quot; }\\n\u0026quot; "});index.add({'id':21,'href':'/docs/references/filters/','title':"在线过滤器",'section':"功能手册",'content':"请求过滤器 #  什么是过滤器 #  过滤器是网关接收到请求之后，在流程里面定义的一系列处理单元，每个过滤器处理一件任务，可以灵活组合，过滤器是请求的在线处理。\n过滤器列表 #  请求过滤 #    request_method_filter  request_header_filter  request_path_filter  request_user_filter  request_host_filter  request_client_ip_filter  request_api_key_filter  response_status_filter  response_header_filter  请求转发 #    ratio  clone  switch  flow  请求干预 #    sample  request_body_json_del  request_body_json_set  request_body_regex_replace  response_body_regex_replace  response_header_format  set_basic_auth  set_hostname  set_request_header  set_request_query_args  set_response_header  set_response  限速限流 #    request_path_limiter  request_host_limiter  request_user_limiter  request_api_key_limiter  request_client_ip_limiter  retry_limiter  sleep  日志监控 #    logging  Elasticsearch #    date_range_precision_tuning  bulk_reshuffle  elasticsearch_health_check  bulk_response_validate  身份认证 #    ldap_auth  Output #    queue  elasticsearch  cache  translog  redis_pubsub  drop  调试开发 #    echo  dump  "});index.add({'id':22,'href':'/docs/release-notes/','title':"版本历史",'section':"Docs",'content':"版本发布日志 #  这里是极限网关历史版本发布的相关说明。\n1.4.0 #  Breaking changes #   Rename flow config filter_v2 to filter, only support new syntax Rename pipeline config pipelines_v2 to pipelines, only support new syntax Rename filter request_logging to logging Merge dump filters to dump filter Response headers renamed, dashboard may broken Remove filter request_body_truncate and response_body_truncate  Features #   Add option to disable file logging output   Bug fix #   Fix invalid host header setting in elasticsearch reverse proxy Fix cluster available health check  Improvements #   Support string type in in condition  1.3.0 #  Breaking changes #   Switch to use pipelines_v2 syntax only Rename filter disk_enqueue to queue Rename processor disk_queue_consumer to queue_consumer Rename filter redis to redis_pubsub  Features #   Refactoring pipeline framework, support DAG based task schedule Add dump_hash and index_diffs processor Add redis output and redis queue adapter Add set_request_query_args filter Add ldap_auth filter Add retry_limiter filter Add request_body_json_set and request_body_json_del filter Add stats filter  Bug fix #   Fix data race issue in bulk_reshuffle Fix fix_null_id always executed in bulk_reshuffle Auto handle big sized documents in bulk requests  Improvements #   Refactoring flow runner to service pipeline Optimize CPU and Memory usage Optimize index diff service, speedup and cross version compatibility Set the default max file size of queue files to 1 GB Proper handle elasticsearch failure during startup Support custom depth check to queue_has_lag condition Support multi hosts for elasticsearch configuration Add parameter auto_start to prevent pipeline running on start Add keep_running parameter to pipeline config Safety shutdown pipeline and entry service Support more complex routing pattern rules  1.2.0 #  Features #   Support alias in bulk_reshuffle filter. Support truncate in request_logging filter. Handle 429 retry in json_indexing service. Add forcemerge service. Add response_body_regex_replace filter. Add request_body_regex_replace filter. Add sleep filter. Add option to log slow requests only. Add cluster and bulk status to request logging. Add filter_v2 and support _ctx to access request context. Add dump_context filter. Add translog filter, support rotation and compression. Add set_response filter. Add set_request_header filter. Add set_hostname filter. Add set_basic_auth filter. Add set_response_header filter. Add elasticsearch_health_check filter. Add drop filter.  Bug fix #   Fix truncate body filter, correctly resize the body bytes. Fix cache filter. Fix floating_ip module. Fix dirty write in diskqueue. Fix compression enabled requests. Fix date_range_precision_tuning filter. Fix invalid indices status on closed indices #23. Fix document hash for elasticsearch 6.x. Fix floating_ip feature run with daemon mode. Fix async bulk to work with beats.  Improvements #   Optimize memory usage, fix memory leak.  Acknowledgement #  Thanks to the following enterprises and teams #   China Everbright Bank, China Citic Bank, BSG, Yogoo  Thanks to the following individual contributors #   MaQianghua, YangFan, Tanzi, FangLi  1.1.0 #   Request Logging and Dashboard. Support ARM Platform [armv5\\v6\\v7\\v8(arm64)]. Fix Elasticsearch Nodes Auto Discovery. Add Request Header Filter. Add Request Method Filter. Add Sample Filter. Request Logging Performance Optimized (100x speedup). Add Request Path Filter. Add Debug Filter. Add User Info to Logging Message. Support Routing Partial Traffic to Specify Processing Flow (by Ratio). Support Traffic Clone, Support Dual-Write or 1:N Write. Elasticsearch topology auto discovery, support filter by nodes,tags,roles. Backend failure auto detection, auto retry and select another available endpoint. Floating IP feature ready to use. Add bulk_reshuffle filter.  1.0.0 #   Rewritten for performance Index level request throttle Request caching Kibana MAGIC speedup Upstream auto discovery Weighted upstream selections Max connection limit per upstream  "});index.add({'id':23,'href':'/docs/references/processors/','title':"离线处理器",'section':"功能手册",'content':"服务管道 #  什么是服务管道 #  服务管道是用于离线处理任务的功能组合，和在线请求的过滤器一样使用管道设计模式。\n什么是管道处理器 #  管道处理器是服务管道的基础单位，每个处理组件一般专注做一件事情，根据需要灵活组装，灵活插拔。\n处理器列表 #  任务调度 #    dag  索引写入 #    bulk_indexing  json_indexing  queue_consumer  索引对比 #    dump_hash  index_diff  请求处理 #    flow_runner  "});index.add({'id':24,'href':'/docs/tutorial/es-hadoop_integration/','title':"与 Elasticsearch-Hadoop 集成",'section':"动手教程",'content':"与 Elasticsearch-Hadoop 集成 #  Elasticsearch-Hadoop 默认会通过某个种子节点拿到后端的所有 Elasticsearch 节点，可能存在热点和请求分配不合理的情况， 为了提高后端 Elasticsearch 节点的资源利用率，可以通过极限网关来实现后端 Elasticsearch 节点访问的精准路由。\n写入加速 #  如果是通过 Elasticsearch-Hadoop 来进行数据导入，可以通过修改 Elasticsearch-Hadoop 程序的以下参数来访问极限网关来提升写入吞吐，如下：\n   名称 类型 说明     es.nodes string 设置访问网关的地址列表，如：localhost:8000,localhost:8001   es.nodes.discovery bool 设置为 false，不采用 sniff 模式，只访问配置的后端节点列表   es.nodes.wan.only bool 设置为 true，代理模式，强制走网关地址   es.batch.size.entries int 适当调大批次文档数，提升吞吐，如 5000   es.batch.size.bytes string 适当调大批次传输大小，提升吞吐，如 20mb   es.batch.write.refresh bool 设置为 false，避免主动刷新，提升吞吐    相关链接 #    Elasticsearch-Hadoop 配置参数文档  "});index.add({'id':25,'href':'/docs/resources/','title':"其它资源",'section':"Docs",'content':"其它资源 #  这里是一些和极限网关有关的外部有用资源。\n文章 #    极限网关 INFINI Gateway 初体验  INFINI Gateway 的使用方法和使用心得分享  性能爆表！INFINI Gateway 性能与压力测试结果  四倍索引速度提升, 有点东西  "});index.add({'id':26,'href':'/docs/references/config/','title':"其它配置",'section':"功能手册",'content':"其它配置 #  系统配置 #  系统配置主要用来设置极限网关的基础属性：\n   名称 类型 说明     path.data string 数据目录，默认为 data   path.logs string 日志目录，默认为 log   log.level string 日志级别，默认为 info   log.debug bool 是否开启调试模式，当开启的时候，一旦出现异常程序直接退出，打印完整堆栈，仅用于调试定位故障点，默认为 false，生产环境不要开启，可能丢数据   log.disable_file_output bool 是否关闭本地文件的日志输出，默认为 false，容器环境不希望本地日志输出的可以开启本参数   allow_multi_instance bool 是否运行单个机器上面启动多个网关实例，默认为 true   max_num_of_instances int 网关实例的最大个数，默认为 5    "});index.add({'id':27,'href':'/docs/references/processors/bulk_indexing/','title':"bulk_indexing",'section':"离线处理器",'content':"bulk_indexing #  描述 #  bulk_indexing 处理器用来异步消费队列里面的 bulk 请求。\n配置示例 #  一个简单的示例如下：\npipelines: - name: bulk_request_ingest auto_start: true keep_running: true processors: - bulk_indexing: elasticsearch: \u0026quot;dev\u0026quot; compress: true worker_size: 1 bulk_size_in_mb: 1 retry_delay_in_seconds: 5 参数说明 #     名称 类型 说明     input_queue string 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 1   max_connection_per_host int 目标主机允许的最大连接数，默认 5，单位秒   bulk_size_in_kb int 批次请求的单位大小，单位 KB   bulk_size_in_mb int 批次请求的单位大小，单位 MB   elasticsearch string 保存到目标集群的名称   failure_queue string 故障请求的保存队列名称，默认为 %集群名%-failure   process_failure_queue bool 是否主动不断重试处理故障队列里面的请求数据   queues array 手动指定的一组需要消费的队列名称   index array 设置一组索引名称，单独开启的索引分片级别的消费队列   shards array 设置分片级别允许请求通过的分片 ID，其余的丢弃    "});index.add({'id':28,'href':'/docs/references/filters/bulk_reshuffle/','title':"bulk_reshuffle",'section':"在线过滤器",'content':"bulk_reshuffle #  描述 #  极限网关具有本地计算每个索引文档对应后端 Elasticsearch 集群的目标存放位置的能力，从而能够精准的进行请求定位，在一批 bulk 请求中，可能存在多个后端节点的数据，bulk_reshuffle 过滤器用来将正常的 bulk 请求打散，按照目标节点或者分片进行拆分重新组装，避免 Elasticsearch 节点收到请求之后再次进行请求分发， 从而降低 Elasticsearch 集群间的流量和负载，也能避免单个节点成为热点瓶颈，确保各个数据节点的处理均衡，从而提升集群总体的索引吞吐能力。\n配置示例 #  一个简单的示例如下：\nflow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: node mode: sync - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 以上配置表示会将 bulk 请求拆分，按照索引文档所对应的目标节点，重新拆组装，然后分别同步提交到目标 Elasticsearch 节点。\n节点级别的异步提交 #  默认的同步提交方式可能受目标 Elasticsearch 服务的性能影响，极限网关支持异步的提交方式，将数据线落地到本地磁盘队列，然后通过单独的任务来消费提交。\n当极限网关处于开启异步模式的情况下，就算后端 Elasticsearch 集群出现故障也不会影响索引操作的正常进行，因为请求都是存放在网关本地的磁盘队列，从而解耦了前端索引和后端集群的依赖。因此就算后端 Elasticsearch 集群出现故障、进行重启、或是版本升级都不会影响正常的索引操作。  配置流程 #  首先定义一个异步的请求处理流程。\nflow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: node mode: async - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 极限网关会以目标节点为单位来将请求存放到本地磁盘。\n配置管道 #  然后配置一个消费队列的管道，如下：\npipelines: - name: bulk_request_ingest auto_start: true processors: - bulk_indexing: elasticsearch: \u0026quot;prod\u0026quot; compress: true worker_size: 10 bulk_size_in_mb: 10 #in MB retry_delay_in_seconds: 5 process_failure_queue: true #process failed bulk messages 这里使用了一个名为 bulk_request_ingest 的管道任务，并且设置目标的 Elasticsearch 集群为 prod，和前面的集群保持一致，也可以设置消费每个队列的 worker 大小和 bulk 提交的批次大小。 这样当极限网关收到的节点级别的请求会自动的发送到对应的 Elasticsearch 节点。\n分片级别的异步提交 #  分片级别的异步提交比较适合单个索引数据量很大，需要单独处理的场景，通过将索引拆分到分片为单位，然后让 bulk 请求以分片为单位进行提交，进一步提高后端 Elasticsearch 处理的效率。\n具体的配置如下：\n定义流程 #  flow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: shard mode: async - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 将拆装的级别设置为分片类型。\n定义管道 #  pipelines: - name: bulk_request_ingest auto_start: true processors: - bulk_indexing: elasticsearch: \u0026quot;prod\u0026quot; index: - logs-repeat-test - logs100million - medcl4 timeout: \u0026quot;60s\u0026quot; worker_size: 1 bulk_size_in_mb: 1 #in MB 相比前面节点级别的配置，这里主要新增了一个 index 参数用来监听该索引下面的所有分片磁盘队列，这里需要主动添加要处理的索引，如果索引很多的话本地磁盘的开销会比较大，建议仅针对特定要优化吞吐的索引开启该模式。 此次定义和节点级别的管道任务定义一致，重启极限网关即可实现按分片为单位进行数据的异步索引提交了。\n参数说明 #     名称 类型 说明     elasticsearch string Elasticsearch 集群实例名称   level string 请求的 shuffle 级别，默认为 node，也就是节点级别，还可以设置为 shard 级别   mode string 请求打散重新组装之后的发送模式，支持 sync 同步发送和 async 异步两种模式，如果是 async 异步模式，需要结合队列消费管道处理，默认为 sync 模式   fix_null_id bool 如果 bulk 索引请求的文档里面没有指定文档 id，是否自动生成一个随机的 UUID，适合日志类型数据，默认 true   index_stats_analysis bool 是否记录索引名称统计信息到请求日志，默认 true   action_stats_analysis bool 是否记录批次操作统计信息到请求日志，默认 true   doc_buffer_size int 设置处理文档的缓冲大小，如果单个索引文档很大，本参数需大于文档大小，默认 262144 即 256 KB   shards array 字符数组类型，如 \u0026quot;0\u0026quot;，设置哪些索引的分片将要被处理，默认所有分片，可以开启特定分片    "});index.add({'id':29,'href':'/docs/references/filters/bulk_response_validate/','title':"bulk_response_validate",'section':"在线过滤器",'content':"bulk_response_validate #  描述 #  bulk_response_validate 过滤器用来验证 Elasticsearch 的 Bulk 请求是否正确执行完成。\n配置示例 #  一个简单的示例如下：\nflow: - name: bulk_response_validate filter: - bulk_response_validate: invalid_status: 500 参数说明 #     名称 类型 说明     invalid_status int 当 Bulk 请求不成功的时候，设置请求响应的状态码。    "});index.add({'id':30,'href':'/docs/references/filters/cache/','title':"cache",'section':"在线过滤器",'content':"cache #  描述 #  cache 过滤器由 get_cache 和 set_cache 两组过滤器组成，一般需要组合使用，可用于缓存加速查询，抵挡重复请求，降低后端集群查询压力。\nget_cache 过滤器 #  过滤器 get_cache 用来从缓存里面获取之前出现的消息，直接返回给客户端，避免访问后端 Elasticsearch，用于缓存热点数据。\n配置示例如下：\nflow: - name: get_cache filter: - get_cache: pass_patterns: [\u0026quot;_cat\u0026quot;,\u0026quot;scroll\u0026quot;, \u0026quot;scroll_id\u0026quot;,\u0026quot;_refresh\u0026quot;,\u0026quot;_cluster\u0026quot;,\u0026quot;_ccr\u0026quot;,\u0026quot;_count\u0026quot;,\u0026quot;_flush\u0026quot;,\u0026quot;_ilm\u0026quot;,\u0026quot;_ingest\u0026quot;,\u0026quot;_license\u0026quot;,\u0026quot;_migration\u0026quot;,\u0026quot;_ml\u0026quot;,\u0026quot;_rollup\u0026quot;,\u0026quot;_data_stream\u0026quot;,\u0026quot;_open\u0026quot;, \u0026quot;_close\u0026quot;] 参数说明 #     名称 类型 说明     pass_patterns string 设置忽略缓存的请求规则，URL 包含其中的任意关键字将跳过缓存    set_cache 过滤器 #  过滤器 set_cache 用来将后端查询拿到的返回结果存到缓存里面，可以设置过期时间。\n配置示例如下：\nflow: - name: get_cache filter: - set_cache: min_response_size: 100 max_response_size: 1024000 cache_ttl: 30s max_cache_items: 100000 参数说明 #     名称 类型 说明     cache_type string 缓存类型，支持 ristretto，ccache 和 redis，默认 ristretto   cache_ttl string 缓存的过期时间，默认 10s   async_search_cache_ttl string 异步请求结果的缓存过期时间，默认 10m   min_response_size int 最小符合缓存要求的消息体大小，默认 -1 表示不限制   max_response_size int 最大符合缓存要求的消息体大小，默认为 int 的最大值   max_cached_item int 最大的缓存消息总数，默认 1000000，当类型为 ccache有效   max_cached_size int 最大的缓存内存开销，默认 1000000000 即 1GB，当类型为 ristretto 有效   validated_status_code array 允许被缓存的请求状态码，默认 200,201,404,403,413,400,301    其它参数 #  如果希望主动忽略缓存，可以在 URL 的参数里面传递一个 no_cache 来让网关忽略缓存。如：\ncurl http://localhost:8000/_search?no_cache=true "});index.add({'id':31,'href':'/docs/references/filters/clone/','title':"clone",'section':"在线过滤器",'content':"clone #  描述 #  clone 过滤器用来将流量克隆转发到另外的一个处理流程，可以实现双写、多写、多数据中心同步、集群升级、版本切换等需求。\n配置示例 #  一个简单的示例如下：\nflow: - name: double_write filter: - clone: flows: - write_to_region_a - write_to_region_b #last one's response will be output to client - name: write_to_region_a filter: - elasticsearch: elasticsearch: es1 - name: write_to_region_b filter: - elasticsearch: elasticsearch: es2 上面的例子可以将 Elasticsearch 的请求复制到两个不同的异地集群。\n参数说明 #     名称 类型 说明     flows array 指定多个流量处理的流程，依次同步执行，将最后一个流程处理的结果输出给客户端   continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。    "});index.add({'id':32,'href':'/docs/references/processors/dag/','title':"dag",'section':"离线处理器",'content':"dag #  描述 #  dag 处理器用来管理任务的并行调度。\n配置示例 #  下面的这个例子，定义了一个名为 racing_example 的服务，auto_start 设置为自动启动，processors 设置依次执行的每个处理单元，其中 dag 处理器支持多个任务并行执行，支持 wait_all 和 first_win 两种聚合模式，如下：\npipelines: - name: racing_example auto_start: true processors: - echo: #ready, set, go message: read,set,go - dag: mode: wait_all #first_win, wait_all parallel: - echo: #player1 message: player1 - echo: #player2 message: player2 - echo: #player3 message: player3 end: - echo: #checking score message: checking score - echo: #announce champion message: 'announce champion' - echo: #done message: racing finished 上面的 echo 处理器非常简单，用来输出一个指定的消息，这个管道模拟的是一个赛跑的场景，palyer1、2、3 并行赛跑，全部跑完之后再进行算分和宣布比赛冠军，最后输出结束信息，程序运行输出如下：\n[10-12 14:59:22] [INF] [echo.go:36] message:read,set,go [10-12 14:59:22] [INF] [echo.go:36] message:player1 [10-12 14:59:22] [INF] [echo.go:36] message:player2 [10-12 14:59:22] [INF] [echo.go:36] message:player3 [10-12 14:59:22] [INF] [echo.go:36] message:checking score [10-12 14:59:22] [INF] [echo.go:36] message:announce champion [10-12 14:59:22] [INF] [echo.go:36] message:racing finished 参数说明 #     名称 类型 说明     mode string 任务结果的聚合模式，设置 first_win 表示并行里面的任意任务执行完就继续往下执行，而设置 wait_all 表示需要等待所有任务执行完毕才继续往后执行。   parallel array 任务数组列表，依次定义多个子任务   end array 任务数组列表，并行任务之后再执行的任务    "});index.add({'id':33,'href':'/docs/references/filters/date_range_precision_tuning/','title':"date_range_precision_tuning",'section':"在线过滤器",'content':"date_range_precision_tuning #  描述 #  date_range_precision_tuning 过滤器用来重设时间范围查询的时间精度，通过调整精度，可以让短时间内邻近的重复请求更容易被缓存，对于有一些对于时间精度不那么高但是数据量非常大的场景，比如使用 Kibana 来做报表分析，通过缩减精度来缓存重复的查询请求，从而降低后端服务器压力，前端报表展现的提速非常明显。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - date_range_precision_tuning: time_precision: 4 - get_cache: - elasticsearch: elasticsearch: dev - set_cache: 精度说明 #  Kibana 默认发往 Elasticsearch 的查询，使用的是当前时间 Now，精度到毫秒，通过设置不同的精度来改写查询，以下面的查询为例：\n{\u0026quot;range\u0026quot;:{\u0026quot;@timestamp\u0026quot;:{\u0026quot;gte\u0026quot;:\u0026quot;2019-09-26T08:21:12.152Z\u0026quot;,\u0026quot;lte\u0026quot;:\u0026quot;2020-09-26T08:21:12.152Z\u0026quot;,\u0026quot;format\u0026quot;:\u0026quot;strict_date_optional_time\u0026quot;} 分别设置不同的精度，改写之后的查询结果如下：\n   精度 新的查询     0 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T00:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T23:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   1 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T00:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T09:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   2 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:00:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:59:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   3 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:20:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:29:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   4 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:00.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:59.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   5 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:10.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:19.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   6 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.000Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.999Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   7 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.100Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.199Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   8 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.150Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.159Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}   9 {\u0026ldquo;range\u0026rdquo;:{\u0026quot;@timestamp\u0026quot;:{\u0026ldquo;gte\u0026rdquo;:\u0026ldquo;2019-09-26T08:21:12.152Z\u0026rdquo;,\u0026ldquo;lte\u0026rdquo;:\u0026ldquo;2020-09-26T08:21:12.152Z\u0026rdquo;,\u0026ldquo;format\u0026rdquo;:\u0026ldquo;strict_date_optional_time\u0026rdquo;}    参数说明 #     名称 类型 说明     time_precision int 时间的精度长度，对于时间呈现长度位数，默认为 4，有效范围 0 到 9   path_keywords array 只对包含所设置关键字的请求进行时间精度重置，避免对不必要的请求进行解析，默认 _search 和 _async_search    "});index.add({'id':34,'href':'/docs/references/filters/drop/','title':"drop",'section':"在线过滤器",'content':"drop #  描述 #  drop 过滤器用来丢弃某个消息，提前结束请求的处理。\n配置示例 #  一个简单的示例如下：\nflow: - name: drop filter: - drop: "});index.add({'id':35,'href':'/docs/references/filters/dump/','title':"dump",'section':"在线过滤器",'content':"dump #  描述 #  dump 过滤器是一个用于在终端打印 Dump 输出相关请求信息的过滤器，主要用于调试。\n配置示例 #  一个简单的示例如下：\nflow: - name: hello_world filter: - dump: uri: true request_header: true request_body: true response_body: true status_code: true 参数说明 #  dump 过滤器比较简单，在需要的流程处理阶段插入 dump 过滤器，即可在终端输出相应阶段的请求信息，方便调试。\n   名称 类型 说明     request bool 是否输出全部完整的请求信息   uri bool 是否输出请求的 URI 信息   query_args bool 是否输出请求的参数信息   user bool 是否输出请求的用户信息   api_key bool 是否输出请求的 APIKey 信息   request_header bool 是否输出请求的头信息   response_header bool 是否输出响应的头信息   status_code bool 是否输出响应的状态码   context array 输出自定义的上下文信息    输出上下文 #  可以使用 context 参数来调试请求上下文信息，示例配置文件：\nflow: - name: echo filter: - set_response: status: 201 content_type: \u0026quot;text/plain; charset=utf-8\u0026quot; body: \u0026quot;hello world\u0026quot; - set_response_header: headers: - Env -\u0026gt; Dev - dump: context: - _ctx.id - _ctx.tls - _ctx.remote_addr - _ctx.local_addr - _ctx.request.host - _ctx.request.method - _ctx.request.uri - _ctx.request.path - _ctx.request.body - _ctx.request.body_length - _ctx.request.query_args.from - _ctx.request.query_args.size - _ctx.request.header.Accept - _ctx.request.user - _ctx.response.status - _ctx.response.body - _ctx.response.content_type - _ctx.response.body_length - _ctx.response.header.Env 启动网关，执行如下命令：\ncurl http://localhost:8000/medcl/_search\\?from\\=1\\\u0026amp;size\\=100 -d'{search:query123}' -v -u 'medcl:123' 网关终端输出如下信息：\n---- dumping context ---- _ctx.id : 21474836481 _ctx.tls : false _ctx.remote_addr : 127.0.0.1:50925 _ctx.local_addr : 127.0.0.1:8000 _ctx.request.host : localhost:8000 _ctx.request.method : POST _ctx.request.uri : http://localhost:8000/medcl/_search?from=1\u0026amp;size=100 _ctx.request.path : /medcl/_search _ctx.request.body : {search:query123} _ctx.request.body_length : 17 _ctx.request.query_args.from : 1 _ctx.request.query_args.size : 100 _ctx.request.header.Accept : */* _ctx.request.user : medcl _ctx.response.status : 201 _ctx.response.body : hello world _ctx.response.content_type : text/plain; charset=utf-8 _ctx.response.body_length : 11 _ctx.response.header.Env : Dev "});index.add({'id':36,'href':'/docs/references/processors/dump_hash/','title':"dump_hash",'section':"离线处理器",'content':"dump_hash #  描述 #  dump_hash 处理器用来导出集群的索引文档并计算 Hash。\n配置示例 #  一个简单的示例如下：\npipelines: - name: bulk_request_ingest auto_start: true keep_running: true processors: - dump_hash: #dump es1's doc indices: \u0026quot;medcl-dr3\u0026quot; scroll_time: \u0026quot;10m\u0026quot; elasticsearch: \u0026quot;source\u0026quot; query: \u0026quot;field1:elastic\u0026quot; fields: \u0026quot;doc_hash\u0026quot; output_queue: \u0026quot;source_docs\u0026quot; batch_size: 10000 slice_size: 5 参数说明 #     名称 类型 说明     elasticsearch string 目标集群的名称   scroll_time string Scroll 回话超时时间   batch_size int Scroll 批次大小，默认 5000   slice_size int Slice 大小，默认 1   sort_type string 文档排序类型，默认 asc   sort_field string 文档排序字段   indices string 索引   query string 查询过滤条件   fields string 要返回的字段列表   output_queue string 输出结果的名称    "});index.add({'id':37,'href':'/docs/references/filters/elasticsearch/','title':"elasticsearch",'section':"在线过滤器",'content':"elasticsearch #  描述 #  elasticsearch 过滤器是一个用于请求转发给后端 Elasticsearch 集群的过滤器。\n配置示例 #  使用 elasticsearch 过滤器之前，需要提前定义一个 Elasticsearch 的集群配置节点，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 流程的配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod 上面的例子即将请求转发给 prod 集群。\n自动更新 #  对于一个大规模的集群，可能存在很多的节点，不可能一一配置后端的所有节点，只需要先指定 Elasticsearch 模块允许自动发现后端节点，如下：\nelasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 然后过滤器这边的配置也开启刷新，即可访问后端所有节点，且节点上下线也会自动更新，示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 设置权重 #  如果后端集群很多，极限网关支持对不同的节点设置不同的访问权重，配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod max_connection: 1000 max_response_size: -1 balancer: weight refresh: enabled: true interval: 30s weights: - host: 192.168.3.201:9200 weight: 10 - host: 192.168.3.202:9200 weight: 20 - host: 192.168.3.203:9200 weight: 30 上面的例子中，发往 Elasticsearch 集群的流量，将以 3：2：1 的比例分别发给 203、202 和 201 这三个节点。\n过滤节点 #  极限网关还支持按照节点的 IP、标签、角色来进行过滤，可以用来将请求避免发送给特定的节点，如 Master、冷节点等，配置示例如下：\nflow: - name: cache_first filter: - elasticsearch: elasticsearch: prod max_connection: 1000 max_response_size: -1 balancer: weight refresh: enabled: true interval: 30s filter: hosts: exclude: - 192.168.3.201:9200 include: - 192.168.3.202:9200 - 192.168.3.203:9200 tags: exclude: - temp: cold include: - disk: ssd roles: exclude: - master include: - data - ingest 参数说明 #     名称 类型 说明     elasticsearch string Elasticsearch 集群的名称   max_connection_per_node int 限制访问 Elasticsearch 集群每个节点的最大 TCP 连接数，默认 10000   max_response_size int 限制 Elasticsearch 请求返回的最大消息体大小，默认 100*1024*1024   max_conn_wait_timeout int 限制 Elasticsearch 等待空闲链接的超时时间，默认 10s   max_idle_conn_duration int 限制 Elasticsearch 连接的空闲时间，默认 0s   max_conn_duration int 限制 Elasticsearch 连接的持续时间，默认 0s   read_timeout int 限制 Elasticsearch 请求的读取超时时间，默认 0s   write_timeout int 限制 Elasticsearch 请求的写入超时时间，默认 0s   read_buffer_size int 设置 Elasticsearch 请求的读缓存大小，默认 4096*4   write_buffer_size int 设置 Elasticsearch 请求的写缓存大小，默认 4096*4   tls_insecure_skip_verify bool 是否忽略 Elasticsearch 集群的 TLS 证书校验，默认 true   balancer string 后端 Elasticsearch 节点的负载均衡算法，目前只有 weight 基于权重的算法   refresh.enable bool 是否开启节点状态变化的自动刷新，可感知后端 Elasticsearch 拓扑的变化   refresh.interval int 节点状态刷新的间隔时间   weights array 可以设置后端节点的优先级，权重高的转发请求的比例相应提高   filter object 后端 Elasticsearch 节点的过滤规则，可以将请求转发给特定的节点   filter.hosts object 按照 Elasticsearch 的访问地址来进行过滤   filter.tags object 按照 Elasticsearch 的标签来进行过滤   filter.roles object 按照 Elasticsearch 的角色来进行过滤   filter.*.exclude array 排除特定的条件，任何匹配的节点会被拒绝执行请求的代理   filter.*.include array 允许符合条件的 Elasticsearch 节点来代理请求，在 exclude 参数没有配置的情况下，如果配置了 include 条件，则必须要满足任意一个 include 条件，否则不允许进行请求的代理    "});index.add({'id':38,'href':'/docs/references/filters/elasticsearch_health_check/','title':"elasticsearch_health_check",'section':"在线过滤器",'content':"elasticsearch_health_check #  描述 #  elasticsearch_health_check 过滤器用来以限速模式下主动探测 Elasticsearch 的健康情况， 当出现后端故障的情况下，可以触发一次主动的集群健康检查，而不用等待 Elasticsearch 默认的轮询检查结果，限速设置为最多每秒发送一次检查请求给后端 Elasticsearch。\n配置示例 #  一个简单的示例如下：\nflow: - name: elasticsearch_health_check filter: - elasticsearch_health_check: elasticsearch: dev 参数说明 #     名称 类型 说明     elasticsearch string 集群 ID   interval int 设置最少执行请求的时间间隔，单位秒，默认 1    "});index.add({'id':39,'href':'/docs/references/filters/flow/','title':"flow",'section':"在线过滤器",'content':"flow #  描述 #  flow 过滤器用来跳转或执行某个或一系列其他流程。\n配置示例 #  一个简单的示例如下：\nflow: - name: flow filter: - flow: flows: - request_logging 参数说明 #     名称 类型 说明     flows array 流程 ID，数组格式，可以指定多个，依次执行    "});index.add({'id':40,'href':'/docs/references/processors/flow_runner/','title':"flow_runner",'section':"离线处理器",'content':"flow_runner #  描述 #  flow_runner 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。\n配置示例 #  一个简单的示例如下：\npipelines: - name: bulk_request_ingest auto_start: true keep_running: true processors: - flow_runner: input_queue: \u0026quot;primary_deadletter_requests\u0026quot; flow: primary-flow-post-processing when: cluster_available: [ \u0026quot;primary\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue string 订阅的队列名称   flow string 以什么样的流程来消费队列里面的请求消息    "});index.add({'id':41,'href':'/docs/references/processors/index_diff/','title':"index_diff",'section':"离线处理器",'content':"index_diff #  描述 #  index_diff 处理器用来对两个结果集进行差异对比。\n配置示例 #  一个简单的示例如下：\npipelines: - name: bulk_request_ingest auto_start: true keep_running: true processors: - index_diff: diff_queue: \u0026quot;diff_result\u0026quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 参数说明 #     名称 类型 说明     source_queue string 来源数据的名称   target_queue string 目标数据的名称   diff_queue string 存放 diff 结果的队列   buffer_size int 内存 buffer 大小   keep_source bool diff 结果里面是否包含文档 source 信息   text_report bool 是否输出文本格式的结果    "});index.add({'id':42,'href':'/docs/references/processors/json_indexing/','title':"json_indexing",'section':"离线处理器",'content':"json_indexing #  描述 #  json_indexing 处理器用来消费队列里面的纯 JSON 文档，并保存到指定的 Elasticsearch 服务器里面。\n配置示例 #  一个简单的示例如下：\npipelines: - name: request_logging_index auto_start: true keep_running: true processors: - json_indexing: index_name: \u0026quot;gateway_requests\u0026quot; elasticsearch: \u0026quot;dev\u0026quot; input_queue: \u0026quot;request_logging\u0026quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 参数说明 #     名称 类型 说明     input_queue int 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒   bulk_size_in_kb int 批次请求的单位大小，单位 KB   bulk_size_in_mb int 批次请求的单位大小，单位 MB   elasticsearch string 保存到目标集群的名称   index_name string 保存到目标集群的索引名称   type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc    "});index.add({'id':43,'href':'/docs/references/filters/ldap_auth/','title':"ldap_auth",'section':"在线过滤器",'content':"ldap_auth #  描述 #  ldap_auth 过滤器用来设置基于 LDAP 的身份认证。\n配置示例 #  一个简单的示例如下：\nflow: - name: ldap_auth filter: - ldap_auth: host: \u0026quot;ldap.forumsys.com\u0026quot; port: 389 bind_dn: \u0026quot;cn=read-only-admin,dc=example,dc=com\u0026quot; bind_password: \u0026quot;password\u0026quot; base_dn: \u0026quot;dc=example,dc=com\u0026quot; user_filter: \u0026quot;(uid=%s)\u0026quot; 上面的配置使用的是在线的免费 LDAP 测试服务器，测试用户 tesla，密码 password。\n➜ curl http://127.0.0.1:8000/ -u tesla:password { \u0026quot;name\u0026quot; : \u0026quot;192.168.3.7\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;ZGTwWtBfSLWRpsS1VKQDiQ\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;7.8.0\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;757314695644ea9a1dc2fecd26d1a43856725e65\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2020-06-14T19:35:50.234439Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;8.5.1\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;6.8.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;6.0.0-beta1\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } ➜ curl http://127.0.0.1:8000/ -u tesla:password1 Unauthorized% 参数说明 #     名称 类型 说明     host string LDAP 服务器地址   port int LDAP 服务器端口，默认 389   tls bool LDAP 服务器是否为 TLS 安全传输协议，默认 false   bind_dn string 执行 LDAP 查询的用户信息   bind_password string 执行 LDAP 查询的密码信息   base_dn string 过滤 LDAP 用户的根域   user_filter string 过滤 LDAP 用户的查询条件，默认 (uid=%s)   uid_attribute string 用于用户 ID 的属性，默认 uid   group_attribute string 用于用户组的属性，默认 cn   attribute array 指定 LDAP 查询返回的属性列表    "});index.add({'id':44,'href':'/docs/references/filters/logging/','title':"logging",'section':"在线过滤器",'content':"logging #  描述 #  logging 过滤器用来按请求记录下来，通过异步记录到本地磁盘的方式，尽可能降低对请求的延迟影响，对于流量很大的场景，建议配合其它请求过滤器来降低日志的总量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - logging: queue_name: request_logging 记录的请求日志样例如下：\n { \u0026quot;_index\u0026quot; : \u0026quot;gateway_requests\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;EH5bG3gBsbC2s3iWFzCF\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;tls\u0026quot; : false, \u0026quot;@timestamp\u0026quot; : \u0026quot;2021-03-10T08:57:30.645Z\u0026quot;, \u0026quot;conn_time\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;flow\u0026quot; : { \u0026quot;from\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;process\u0026quot; : [ \u0026quot;request_body_regex_replace\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;date_range_precision_tuning\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;elasticsearch\u0026quot;, \u0026quot;set_cache\u0026quot;, \u0026quot;||\u0026quot;, \u0026quot;request_logging\u0026quot; ], \u0026quot;relay\u0026quot; : \u0026quot;192.168.43.101-Quartz\u0026quot;, \u0026quot;to\u0026quot; : [ \u0026quot;localhost:9200\u0026quot; ] }, \u0026quot;id\u0026quot; : 3, \u0026quot;local_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;remote_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;request\u0026quot; : { \u0026quot;body_length\u0026quot; : 53, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot; { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 100 } \u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;content-type\u0026quot; : \u0026quot;application/json\u0026quot;, \u0026quot;User-Agent\u0026quot; : \u0026quot;curl/7.54.0\u0026quot;, \u0026quot;Accept\u0026quot; : \u0026quot;*/*\u0026quot;, \u0026quot;Host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;53\u0026quot; }, \u0026quot;host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:8000\u0026quot;, \u0026quot;method\u0026quot; : \u0026quot;POST\u0026quot;, \u0026quot;path\u0026quot; : \u0026quot;/myindex/_search\u0026quot;, \u0026quot;remote_addr\u0026quot; : \u0026quot;127.0.0.1:63309\u0026quot;, \u0026quot;started\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;uri\u0026quot; : \u0026quot;http://localhost:8000/myindex/_search\u0026quot; }, \u0026quot;response\u0026quot; : { \u0026quot;body_length\u0026quot; : 441, \u0026quot;cached\u0026quot; : false, \u0026quot;elapsed\u0026quot; : 9.878, \u0026quot;status_code\u0026quot; : 200, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot;{\u0026quot;took\u0026quot;:0,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;max_score\u0026quot;:1.0,\u0026quot;hits\u0026quot;:[{\u0026quot;_index\u0026quot;:\u0026quot;myindex\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c132mhq3r0otidqkac1g\u0026quot;,\u0026quot;_score\u0026quot;:1.0,\u0026quot;_source\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;local\u0026quot;,\u0026quot;enabled\u0026quot;:true,\u0026quot;endpoint\u0026quot;:\u0026quot;http://localhost:9200\u0026quot;,\u0026quot;basic_auth\u0026quot;:{},\u0026quot;discovery\u0026quot;:{\u0026quot;refresh\u0026quot;:{}},\u0026quot;created\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;,\u0026quot;updated\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;}}]}}\u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;UPSTREAM\u0026quot; : \u0026quot;localhost:9200\u0026quot;, \u0026quot;process\u0026quot; : \u0026quot;request_body_regex_replace-\u0026gt;get_cache-\u0026gt;date_range_precision_tuning-\u0026gt;get_cache-\u0026gt;elasticsearch-\u0026gt;set_cache\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;441\u0026quot;, \u0026quot;content-type\u0026quot; : \u0026quot;application/json; charset=UTF-8\u0026quot;, \u0026quot;Server\u0026quot; : \u0026quot;INFINI\u0026quot;, \u0026quot;CLUSTER\u0026quot; : \u0026quot;dev\u0026quot; }, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:63310\u0026quot; } } } 参数说明 #     名称 类型 说明     queue_name string 将请求日志保存的本地磁盘的队列名称   format_header_keys bool 是否将 Header 标准化，都转成小写，默认 false   remove_authorization bool 是否将 Authorization 信息从 Header 里面移除，默认 true   max_request_body_size int 是否将过长的请求消息进行截断，默认 1024 ，即保留 1024 个字符   max_response_body_size int 是否将过长的返回消息进行截断，默认 1024 ，即保留 1024 个字符   min_elapsed_time_in_ms int 按照请求的响应时间进行过滤，最低超过多少 ms 的请求才会被记录下来   bulk_stats_details bool 是否记录 bulk 请求详细的按照索引的统计信息，默认 true    "});index.add({'id':45,'href':'/docs/references/filters/queue/','title':"queue",'section':"在线过滤器",'content':"queue #  描述 #  queue 过滤器用来保存请求到消息队列。\n配置示例 #  一个简单的示例如下：\nflow: - name: queue filter: - queue: queue_name: queue_name 参数说明 #     名称 类型 说明     depth_threshold int 大于队列指定深度才能存入队列，默认为 0   queue_name string 消息队列名称    "});index.add({'id':46,'href':'/docs/references/processors/queue_consumer/','title':"queue_consumer",'section':"离线处理器",'content':"queue_consumer #  描述 #  queue_consumer 处理器用来异步消费队列里面的请求到 Elasticsearch。\n配置示例 #  一个简单的示例如下：\npipelines: - name: bulk_request_ingest auto_start: true keep_running: true processors: - queue_consumer: input_queue: \u0026quot;backup\u0026quot; elasticsearch: \u0026quot;backup\u0026quot; waiting_after: [ \u0026quot;backup_failure_requests\u0026quot;] worker_size: 20 when: cluster_available: [ \u0026quot;backup\u0026quot; ] 参数说明 #     名称 类型 说明     input_queue int 订阅的队列名称   worker_size int 并行执行消费任务的线程数，默认 1   idle_timeout_in_seconds int 消费队列的超时时间，默认 1   elasticsearch string 保存到目标集群的名称   waiting_after array 需要先等待这些指定队列消费完才能开始消费    "});index.add({'id':47,'href':'/docs/references/filters/ratio/','title':"ratio",'section':"在线过滤器",'content':"ratio #  描述 #  ratio 过滤器用来将正常的流量按照比例迁移转发到另外的一个处理流程，可以实现灰度发布、流量迁移导出，或者将部分流量切换到不同版本集群用于测试的能力。\n配置示例 #  一个简单的示例如下：\nflow: - name: ratio_traffic_forward filter: - ratio: ratio: 0.1 flow: hello_world continue: true 参数说明 #     名称 类型 说明     ratio float 需要迁移的流量比例   flow string 指定新的流量处理流程   continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。    "});index.add({'id':48,'href':'/docs/references/filters/redis_pubsub/','title':"redis_pubsub",'section':"在线过滤器",'content':"redis_pubsub #  描述 #  reids 过滤器用来将收到的请求和响应结果保存到 Redis 消息队列中。\n配置示例 #  一个简单的示例如下：\nflow: - name: redis_pubsub filter: - redis_pubsub: host: 127.0.0.1 port: 6379 channel: gateway response: true 参数说明 #     名称 类型 说明     host string Reids 主机名，默认 localhost   port int Reids 端口号，默认为 6379   password string Redis 密码   db int Redis 默认选择的数据库，默认为 0   channel string Redis 消息队列名称，必填，没有默认值   response bool 是否包含响应结果，默认为 true    "});index.add({'id':49,'href':'/docs/references/filters/request_api_key_filter/','title':"request_api_key_filter",'section':"在线过滤器",'content':"request_api_key_filter #  描述 #  当 Elasticsearch 是通过 API Key 方式来进行身份认证的时候，request_api_key_filter 过滤器可用来按请求的 API ID 来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_api_key_filter: message: \u0026quot;Request filtered!\u0026quot; exclude: - VuaCfGcBCdbkQm-e5aOx 上面的例子表示，来自 VuaCfGcBCdbkQm-e5aOx 的请求会被拒绝，如下。\n➜ ~ curl localhost:8000 -H \u0026quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==\u0026quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw== \u0026gt; \u0026lt; HTTP/1.1 403 Forbidden \u0026lt; Server: INFINI \u0026lt; Date: Mon, 12 Apr 2021 15:02:37 GMT \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; content-length: 17 \u0026lt; FILTERED: true \u0026lt; process: request_api_key_filter \u0026lt; * Connection #0 to host localhost left intact {\u0026quot;error\u0026quot;:true,\u0026quot;message\u0026quot;:\u0026quot;Request filtered!\u0026quot;}% ➜ ~ 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的用户名列表   include array 允许通过的请求的用户名列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':50,'href':'/docs/references/filters/request_api_key_limiter/','title':"request_api_key_limiter",'section':"在线过滤器",'content':"request_api_key_limiter #  描述 #  request_api_key_limiter 过滤器用来按照 API Key 来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_api_key_limiter: id: - VuaCfGcBCdbkQm-e5aOx max_requests: 1 action: drop # retry or drop message: \u0026quot;your api_key reached our limit\u0026quot; 上面的配置中，对 VuaCfGcBCdbkQm-e5aOx 这个 API ID 进行限速，允许的最大 qps 为 1 每秒。\n➜ ~ curl localhost:8000 -H \u0026quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==\u0026quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: localhost:8000 \u0026gt; User-Agent: curl/7.54.0 \u0026gt; Accept: */* \u0026gt; Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw== \u0026gt; \u0026lt; HTTP/1.1 429 Too Many Requests \u0026lt; Server: INFINI \u0026lt; Date: Mon, 12 Apr 2021 15:14:52 GMT \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; content-length: 30 \u0026lt; process: request_api_key_limiter \u0026lt; * Connection #0 to host localhost left intact your api_key reached our limit% 参数说明 #     名称 类型 说明     id array 设置哪些 API ID 会参与限速，不设置表示所有 API Key 参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息    "});index.add({'id':51,'href':'/docs/references/filters/request_body_json_del/','title':"request_body_json_del",'section':"在线过滤器",'content':"request_body_json_del #  描述 #  request_body_json_del 过滤器用来删除 JSON 格式的请求体里面的部分字段。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_json_del: path: - query.bool.should.[0] - query.bool.must 参数说明 #     名称 类型 说明     path array 需要删除的 JSON PATH 键值   ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false    "});index.add({'id':52,'href':'/docs/references/filters/request_body_json_set/','title':"request_body_json_set",'section':"在线过滤器",'content':"request_body_json_set #  描述 #  request_body_json_set 过滤器用来修改 JSON 格式的请求体。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_json_set: path: - aggs.total_num.terms.field -\u0026gt; \u0026quot;name\u0026quot; - aggs.total_num.terms.size -\u0026gt; 3 - size -\u0026gt; 0 参数说明 #     名称 类型 说明     path map 使用 -\u0026gt; 作为标识符的键值对， JSON PATH 和需要替换的值   ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false    "});index.add({'id':53,'href':'/docs/references/filters/request_body_regex_replace/','title':"request_body_regex_replace",'section':"在线过滤器",'content':"request_body_regex_replace #  描述 #  request_body_regex_replace 过滤器使用正则表达式来替换请求体正文的字符串内容。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_body_regex_replace: pattern: '\u0026quot;size\u0026quot;: 10000' to: '\u0026quot;size\u0026quot;: 100' - elasticsearch: elasticsearch: prod - dump: request_body: true 上面的示例将会替换发送给 Elasticsearch 请求体里面，size 设置为 10000 的部分修改为 100，可以用来动态修复错误或者不合理的查询。\n测试如下：\ncurl -XPOST \u0026quot;http://localhost:8000/myindex/_search\u0026quot; -H 'Content-Type: application/json' -d' { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 10000 }' 实际发生的查询：\n { \u0026quot;_index\u0026quot; : \u0026quot;gateway_requests\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;EH5bG3gBsbC2s3iWFzCF\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;tls\u0026quot; : false, \u0026quot;@timestamp\u0026quot; : \u0026quot;2021-03-10T08:57:30.645Z\u0026quot;, \u0026quot;conn_time\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;flow\u0026quot; : { \u0026quot;from\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;process\u0026quot; : [ \u0026quot;request_body_regex_replace\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;date_range_precision_tuning\u0026quot;, \u0026quot;get_cache\u0026quot;, \u0026quot;elasticsearch\u0026quot;, \u0026quot;set_cache\u0026quot;, \u0026quot;||\u0026quot;, \u0026quot;request_logging\u0026quot; ], \u0026quot;relay\u0026quot; : \u0026quot;192.168.43.101-Quartz\u0026quot;, \u0026quot;to\u0026quot; : [ \u0026quot;localhost:9200\u0026quot; ] }, \u0026quot;id\u0026quot; : 3, \u0026quot;local_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;remote_ip\u0026quot; : \u0026quot;127.0.0.1\u0026quot;, \u0026quot;request\u0026quot; : { \u0026quot;body_length\u0026quot; : 53, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot; { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\u0026quot;size\u0026quot;: 100 } \u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;content-type\u0026quot; : \u0026quot;application/json\u0026quot;, \u0026quot;User-Agent\u0026quot; : \u0026quot;curl/7.54.0\u0026quot;, \u0026quot;Accept\u0026quot; : \u0026quot;*/*\u0026quot;, \u0026quot;Host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;53\u0026quot; }, \u0026quot;host\u0026quot; : \u0026quot;localhost:8000\u0026quot;, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:8000\u0026quot;, \u0026quot;method\u0026quot; : \u0026quot;POST\u0026quot;, \u0026quot;path\u0026quot; : \u0026quot;/myindex/_search\u0026quot;, \u0026quot;remote_addr\u0026quot; : \u0026quot;127.0.0.1:63309\u0026quot;, \u0026quot;started\u0026quot; : \u0026quot;2021-03-10T08:57:30.635Z\u0026quot;, \u0026quot;uri\u0026quot; : \u0026quot;http://localhost:8000/myindex/_search\u0026quot; }, \u0026quot;response\u0026quot; : { \u0026quot;body_length\u0026quot; : 441, \u0026quot;cached\u0026quot; : false, \u0026quot;elapsed\u0026quot; : 9.878, \u0026quot;status_code\u0026quot; : 200, \u0026quot;body\u0026quot; : \u0026quot;\u0026quot;\u0026quot;{\u0026quot;took\u0026quot;:0,\u0026quot;timed_out\u0026quot;:false,\u0026quot;_shards\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;successful\u0026quot;:1,\u0026quot;skipped\u0026quot;:0,\u0026quot;failed\u0026quot;:0},\u0026quot;hits\u0026quot;:{\u0026quot;total\u0026quot;:1,\u0026quot;max_score\u0026quot;:1.0,\u0026quot;hits\u0026quot;:[{\u0026quot;_index\u0026quot;:\u0026quot;myindex\u0026quot;,\u0026quot;_type\u0026quot;:\u0026quot;doc\u0026quot;,\u0026quot;_id\u0026quot;:\u0026quot;c132mhq3r0otidqkac1g\u0026quot;,\u0026quot;_score\u0026quot;:1.0,\u0026quot;_source\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;local\u0026quot;,\u0026quot;enabled\u0026quot;:true,\u0026quot;endpoint\u0026quot;:\u0026quot;http://localhost:9200\u0026quot;,\u0026quot;basic_auth\u0026quot;:{},\u0026quot;discovery\u0026quot;:{\u0026quot;refresh\u0026quot;:{}},\u0026quot;created\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;,\u0026quot;updated\u0026quot;:\u0026quot;2021-03-08T21:48:55.687557+08:00\u0026quot;}}]}}\u0026quot;\u0026quot;\u0026quot;, \u0026quot;header\u0026quot; : { \u0026quot;UPSTREAM\u0026quot; : \u0026quot;localhost:9200\u0026quot;, \u0026quot;process\u0026quot; : \u0026quot;request_body_regex_replace-\u0026gt;get_cache-\u0026gt;date_range_precision_tuning-\u0026gt;get_cache-\u0026gt;elasticsearch-\u0026gt;set_cache\u0026quot;, \u0026quot;content-length\u0026quot; : \u0026quot;441\u0026quot;, \u0026quot;content-type\u0026quot; : \u0026quot;application/json; charset=UTF-8\u0026quot;, \u0026quot;Server\u0026quot; : \u0026quot;INFINI\u0026quot;, \u0026quot;CLUSTER\u0026quot; : \u0026quot;dev\u0026quot; }, \u0026quot;local_addr\u0026quot; : \u0026quot;127.0.0.1:63310\u0026quot; } } } 参数说明 #     名称 类型 说明     pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    "});index.add({'id':54,'href':'/docs/references/filters/request_client_ip_filter/','title':"request_client_ip_filter",'section':"在线过滤器",'content':"request_client_ip_filter #  描述 #  request_client_ip_filter 过滤器用来按请求的来源用户 IP 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_client_ip_filter: exclude: - 192.168.3.67 上面的例子表示，来自 192.168.3.67 的请求不允许通过。\n路由跳转的例子:\nflow: - name: echo filter: - echo: message: hello stanger - name: default_flow filter: - request_client_ip_filter: action: redirect_flow flow: echo exclude: - 192.168.3.67 来自 192.168.3.67 会跳转到另外的 echo 流程。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 IP 数组列表   include array 允许通过的请求 IP 数组列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':55,'href':'/docs/references/filters/request_client_ip_limiter/','title':"request_client_ip_limiter",'section':"在线过滤器",'content':"request_client_ip_limiter #  描述 #  request_client_ip_limiter 过滤器用来按照请求客户端 IP 来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_client_ip_limiter: ip: #only limit for specify ips - 127.0.0.1 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;your ip reached our limit\u0026quot; 上面的配置中，对 127.0.0.1 这个 IP 进行限速，允许的最大 qps 为 256。\n参数说明 #     名称 类型 说明     ip array 设置哪些客户端 IP 会参与限速，不设置表示所有 IP 参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息    "});index.add({'id':56,'href':'/docs/references/filters/request_header_filter/','title':"request_header_filter",'section':"在线过滤器",'content':"request_header_filter #  描述 #  request_header_filter 过滤器用来按请求的 Header 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_header_filter: include: - TRACE: true 上面的例子表示，当 Header 里面包含 TRACE: true 的请求才被允许通过。\ncurl 192.168.3.4:8000 -v -H 'TRACE: true' 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 Header 信息   include array 允许通过的请求 Header 信息   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':57,'href':'/docs/references/filters/request_host_filter/','title':"request_host_filter",'section':"在线过滤器",'content':"request_host_filter #  描述 #  request_host_filter 过滤器主要用来按照指定的域名或者主机名来进行请求过滤，适合只有一个 IP 多个域名需要进行域名访问控制的场景。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_host_filter: include: - domain-test2.com:8000 上面的例子表示，只有访问的是这个域名 domain-test2.com:8000 的请求才被允许通过。\n示例如下： #  ✗ curl -k -u medcl:backsoon http://domain-test4.com:8000/ -v * Trying 192.168.3.67... * TCP_NODELAY set * Connected to domain-test4.com (192.168.3.67) port 8000 (#0) * Server auth using Basic with user 'medcl' \u0026gt; GET / HTTP/1.1 \u0026gt; Host: domain-test4.com:8000 \u0026gt; Authorization: Basic bWVkY2w6YmFja3Nvb24= \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 403 Forbidden \u0026lt; Server: INFINI \u0026lt; Date: Fri, 15 Jan 2021 13:53:01 GMT \u0026lt; Content-Length: 0 \u0026lt; FILTERED: true \u0026lt; * Connection #0 to host domain-test4.com left intact * Closing connection 0 ✗ curl -k -u medcl:backsoon http://domain-test2.com:8000/ -v * Trying 192.168.3.67... * TCP_NODELAY set * Connected to domain-test2.com (192.168.3.67) port 8000 (#0) * Server auth using Basic with user 'medcl' \u0026gt; GET / HTTP/1.1 \u0026gt; Host: domain-test2.com:8000 \u0026gt; Authorization: Basic bWVkY2w6YmFja3Nvb24= \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Fri, 15 Jan 2021 13:52:53 GMT \u0026lt; Content-Type: application/json; charset=UTF-8 \u0026lt; Content-Length: 480 \u0026lt; UPSTREAM: 192.168.3.203:9200 \u0026lt; CACHE-HASH: a2902f950b4ade804b21a062257387ef \u0026lt; { \u0026quot;name\u0026quot; : \u0026quot;node3\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;pi\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;Z_HcN_6ESKWicV-eLsyU4g\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;6.4.2\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;tar\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;04711c2\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2018-09-26T13:34:09.098244Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;7.4.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;5.6.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;5.0.0\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } * Connection #0 to host domain-test2.com left intact * Closing connection 0 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的主机列表   include array 允许通过的请求的主机列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':58,'href':'/docs/references/filters/request_host_limiter/','title':"request_host_limiter",'section':"在线过滤器",'content':"request_host_limiter #  描述 #  request_host_limiter 过滤器用来按照请求主机（域名）来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_host_limiter: host: - api.elasticsearch.cn - logging.elasticsearch.cn max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;you reached our limit\u0026quot; 上面的配置中，对 api.elasticsearch.cn 和 logging.elasticsearch.cn 这两个访问域名进行限速，允许的最大 qps 为 256 每秒。\n参数说明 #     名称 类型 说明     host array 设置哪些主机域名会参与限速，不设置表示都参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   status string 设置达到限速条件的返回状态码，默认 429   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000   failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息    "});index.add({'id':59,'href':'/docs/references/filters/request_method_filter/','title':"request_method_filter",'section':"在线过滤器",'content':"request_method_filter #  描述 #  request_method_filter 过滤器用来按请求 Method 来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_method_filter: exclude: - PUT - POST include: - GET - HEAD - DELETE 参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求 Method   include array 允许通过的请求 Method   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':60,'href':'/docs/references/filters/request_path_filter/','title':"request_path_filter",'section':"在线过滤器",'content':"request_path_filter #  描述 #  request_path_filter 过滤器用来按请求的 Path 路径来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_path_filter: must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl should: prefix: - /medcl contain: - _search - _async_search suffix: - _refresh wildcard: - /*/_refresh regex: - ^/m[\\w]+dcl 参数说明 #     名称 类型 说明     must.* object 必须都满足所设置条件的情况下才能允许通过   must_not.* object 必须都不满足所设置条件的情况下才能通过   should.* object 满足任意所设置条件的情况下即可通过   *.prefix array 判断是否由特定字符开头   *.suffix array 判断是否由特定字符结尾   *.contain array 判断是否包含特定字符   *.wildcard array 判断是否符合通配符匹配规则   *.regex array 判断是否符合正则表达式匹配规则   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    Note: 当仅设置了 should 条件的情况下，必须至少满足 should 设置的其中一种才能被允许通过。\n"});index.add({'id':61,'href':'/docs/references/filters/request_path_limiter/','title':"request_path_limiter",'section':"在线过滤器",'content':"request_path_limiter #  描述 #  request_path_limiter 过滤器用来定义请求的限速规则，可以实现索引级别的限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_path_limiter: message: \u0026quot;Hey, You just reached our request limit!\u0026quot; rules: - pattern: \u0026quot;/(?P\u0026lt;index_name\u0026gt;medcl)/_search\u0026quot; max_qps: 3 group: index_name - pattern: \u0026quot;/(?P\u0026lt;index_name\u0026gt;.*?)/_search\u0026quot; max_qps: 100 group: index_name 上面的配置中，对 medcl 这个索引执行查询，允许的最大 qps 为 3，而对其它的索引执行查询的 qps 为 100。\n参数说明 #     名称 类型 说明     message string 设置达到限速条件的请求的返回消息   rules array 设置限速的策略，支持多种规则，按照配置的先后顺序处理，先匹配的先执行   rules.pattern string 使用正则表达式来对 URL 的 Path 进行规则匹配，必须提供一个 group 名称，用于作为限速的 bucket key   rules.group string 正则表达式里面定义的 group 名称，将用于请求次数的统计，相同的 group 值视为一类请求   rules.max_qps int 定义每组请求的最大的 qps 参数，超过该值将触发限速行为    "});index.add({'id':62,'href':'/docs/references/filters/request_user_filter/','title':"request_user_filter",'section':"在线过滤器",'content':"request_user_filter #  描述 #  当 Elasticsearch 是通过 Basic Auth 方式来进行身份认证的时候，request_user_filter 过滤器可用来按请求的用户名信息来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - request_user_filter: include: - \u0026quot;elastic\u0026quot; 上面的例子表示，只有来自 elastic 的请求才被允许通过。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的请求的用户名列表   include array 允许通过的请求的用户名列表   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':63,'href':'/docs/references/filters/request_user_limiter/','title':"request_user_limiter",'section':"在线过滤器",'content':"request_user_limiter #  描述 #  request_user_limiter 过滤器用来按照用户名来进行限速。\n配置示例 #  配置示例如下：\nflow: - name: rate_limit_flow filter: - request_user_limiter: user: - elastic - medcl max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: \u0026quot;you reached our limit\u0026quot; 上面的配置中，对 medcl 和 elastic 这两个用户进行限速，允许的最大 qps 为 256 每秒。\n参数说明 #     名称 类型 说明     user array 设置哪些用户会参与限速，不设置表示所有用户参与   interval string 评估限速的单位时间间隔，默认为 1s   max_requests int 单位间隔内最大的请求次数限额   max_bytes int 单位间隔内最大的请求流量限额   action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry   message string 设置达到限速条件的请求的拒绝返回消息   retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒   max_retry_times int 限速重试的最大重试次数，默认 1000    "});index.add({'id':64,'href':'/docs/references/filters/response_body_regex_replace/','title':"response_body_regex_replace",'section':"在线过滤器",'content':"response_body_regex_replace #  描述 #  response_body_regex_replace 过滤器使用正则表达式来替换请求响应内容的字符串。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - echo: message: \u0026quot;hello infini\\n\u0026quot; - response_body_regex_replace: pattern: infini to: world 上面的结果输出为 hello world。\n参数说明 #     名称 类型 说明     pattern string 用于匹配替换的正则表达式   to string 替换为目标的字符串内容    "});index.add({'id':65,'href':'/docs/references/filters/response_header_filter/','title':"response_header_filter",'section':"在线过滤器",'content':"response_header_filter #  描述 #  response_header_filter 过滤器用来按请求响应的 Header 信息来过滤流量。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: ... - response_header_filter: exclude: - INFINI-CACHE: CACHED 上面的例子表示，当 Header 信息里面出现 INFINI-CACHE: CACHED 的请求不允许通过。\n参数说明 #     名称 类型 说明     exclude array 拒绝通过的响应 Header 信息   include array 允许通过的响应 Header 信息   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':66,'href':'/docs/references/filters/response_header_format/','title':"response_header_format",'section':"在线过滤器",'content':"response_header_format #  描述 #  response_header_format 过滤器用来将请求响应的 Header 信息里面的 Key 都转换成小写。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - response_header_format: "});index.add({'id':67,'href':'/docs/references/filters/response_status_filter/','title':"response_status_filter",'section':"在线过滤器",'content':"response_status_filter #  描述 #  response_status_filter 过滤器用来按后端服务响应的状态码来进行过滤。\n配置示例 #  一个简单的示例如下：\nflow: - name: test filter: - response_status_filter: message: \u0026quot;Request filtered!\u0026quot; exclude: - 404 include: - 200 - 201 - 500 参数说明 #     名称 类型 说明     exclude array 拒绝通过的响应码   include array 允许通过的响应码   action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny   status int 自定义模式匹配之后返回的状态码   message string 自定义 deny 模式返回的消息文本   flow string 自定义 redirect_flow 模式执行的 flow ID    注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。  "});index.add({'id':68,'href':'/docs/references/filters/retry_limiter/','title':"retry_limiter",'section':"在线过滤器",'content':"retry_limiter #  描述 #  retry_limiter 过滤器用来判断一个请求是否达到最大重试次数，避免一个请求的无限重试。\n配置示例 #  一个简单的示例如下：\nflow: - name: retry_limiter filter: - retry_limiter: queue_name: \u0026quot;deadlock_messages\u0026quot; max_retry_times: 3 参数说明 #     名称 类型 说明     max_retry_times int 最大重试次数，默认为 3   queue_name string 达到重试最大次数后，输出消息到指定消息队列的名称    "});index.add({'id':69,'href':'/docs/references/filters/sample/','title':"sample",'section':"在线过滤器",'content':"sample #  描述 #  sample 过滤器用来将正常的流量按照比例采样，对于海量查询的场景，全流量收集日志需要耗费大量的资源，可以考虑进行抽样统计，对查询日志进行采样分析。\n配置示例 #  一个简单的示例如下：\nflow: - name: sample filter: - sample: ratio: 0.2 参数说明 #     名称 类型 说明     ratio float 采样比例    "});index.add({'id':70,'href':'/docs/references/filters/set_basic_auth/','title':"set_basic_auth",'section':"在线过滤器",'content':"set_basic_auth #  描述 #  set_basic_auth 过滤器用来设置请求的身份认证信息，可以用于重置请求的身份信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_basic_auth filter: - set_basic_auth: username: admin password: password 参数说明 #     名称 类型 说明     username string 用户名   password string 密码    "});index.add({'id':71,'href':'/docs/references/filters/set_hostname/','title':"set_hostname",'section':"在线过滤器",'content':"set_hostname #  描述 #  set_hostname 过滤器用来设置请求 Header 关于要访问的主机或域名信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_hostname filter: - set_hostname: hostname: api.infini.sh 为避免\n参数说明 #     名称 类型 说明     hostname string 主机信息    "});index.add({'id':72,'href':'/docs/references/filters/set_request_header/','title':"set_request_header",'section':"在线过滤器",'content':"set_request_header #  描述 #  set_request_header 过滤器用来设置请求的 Header 头信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_request_header filter: - set_request_header: headers: - Trial -\u0026gt; true - Department -\u0026gt; Engineering 为避免\n参数说明 #     名称 类型 说明     headers map 使用 -\u0026gt; 作为标识符的键值对，用于设置 Header 信息    "});index.add({'id':73,'href':'/docs/references/filters/set_request_query_args/','title':"set_request_query_args",'section':"在线过滤器",'content':"set_request_query_args #  描述 #  set_request_query_args 过滤器用来设置请求的 QueryString 参数信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_request_query_args filter: - set_request_query_args: args: - size -\u0026gt; 10 为避免\n参数说明 #     名称 类型 说明     args map 使用 -\u0026gt; 作为标识符的键值对，用于设置 QueryString 参数信息    "});index.add({'id':74,'href':'/docs/references/filters/set_response/','title':"set_response",'section':"在线过滤器",'content':"set_response #  描述 #  set_response 过滤器用来设置请求响应返回信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_response filter: - set_response: status: 200 content_type: application/json body: '{\u0026quot;message\u0026quot;:\u0026quot;hello world\u0026quot;}' 参数说明 #     名称 类型 说明     status int 请求状态码，默认 200   content_type string 设置请求返回的内容类型   body string 设置请求返回的结构体    "});index.add({'id':75,'href':'/docs/references/filters/set_response_header/','title':"set_response_header",'section':"在线过滤器",'content':"set_response_header #  描述 #  set_response_header 过滤器用来设置请求响应的 Header 头信息。\n配置示例 #  一个简单的示例如下：\nflow: - name: set_response_header filter: - set_response_header: headers: - Trial -\u0026gt; true - Department -\u0026gt; Engineering 为避免\n参数说明 #     名称 类型 说明     headers map 使用 -\u0026gt; 作为标识符的键值对，用于设置 Header 信息    "});index.add({'id':76,'href':'/docs/references/filters/sleep/','title':"sleep",'section':"在线过滤器",'content':"sleep #  描述 #  sleep 过滤器用来添加一个固定的延迟到请求，可以人为降速。\n配置示例 #  一个简单的示例如下：\nflow: - name: slow_query_logging_test filter: - sleep: sleep_in_million_seconds: 1024 参数说明 #     名称 类型 说明     sleep_in_million_seconds int64 需要添加的延迟长度，单位为毫秒    "});index.add({'id':77,'href':'/docs/references/filters/switch/','title':"switch",'section':"在线过滤器",'content':"switch #  描述 #  switch 过滤器用来将流量按照请求路径转发到另外的一个处理流程，可以方便的实现跨集群操作，且 Elasticsearch 集群不需要做任何修改，且各个集群内所有的 API 都可以访问，包括索引的读写和集群操作。\n配置示例 #  一个简单的示例如下：\nflow: - name: es1-flow filter: - elasticsearch: elasticsearch: es1 - name: es2-flow filter: - elasticsearch: elasticsearch: es2 - name: cross_cluste_search filter: - switch: path_rules: - prefix: \u0026quot;es1:\u0026quot; flow: es1-flow - prefix: \u0026quot;es2:\u0026quot; flow: es2-flow - elasticsearch: elasticsearch: dev #elasticsearch configure reference name 上面的例子中，以 es1: 开头的索引将转发给集群 es1 集群，以 es2: 开头的索引转发给 es2 集群，不匹配的转发给 dev 集群，在一个 Kibana 里面可以直接操作不同版本的集群了，如下：\n# GET es1:_cluster/health { \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;status\u0026quot; : \u0026quot;yellow\u0026quot;, \u0026quot;timed_out\u0026quot; : false, \u0026quot;number_of_nodes\u0026quot; : 1, \u0026quot;number_of_data_nodes\u0026quot; : 1, \u0026quot;active_primary_shards\u0026quot; : 37, \u0026quot;active_shards\u0026quot; : 37, \u0026quot;relocating_shards\u0026quot; : 0, \u0026quot;initializing_shards\u0026quot; : 0, \u0026quot;unassigned_shards\u0026quot; : 9, \u0026quot;delayed_unassigned_shards\u0026quot; : 0, \u0026quot;number_of_pending_tasks\u0026quot; : 0, \u0026quot;number_of_in_flight_fetch\u0026quot; : 0, \u0026quot;task_max_waiting_in_queue_millis\u0026quot; : 0, \u0026quot;active_shards_percent_as_number\u0026quot; : 80.43478260869566 } # GET es2:_cluster/health { \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;status\u0026quot; : \u0026quot;yellow\u0026quot;, \u0026quot;timed_out\u0026quot; : false, \u0026quot;number_of_nodes\u0026quot; : 1, \u0026quot;number_of_data_nodes\u0026quot; : 1, \u0026quot;active_primary_shards\u0026quot; : 6, \u0026quot;active_shards\u0026quot; : 6, \u0026quot;relocating_shards\u0026quot; : 0, \u0026quot;initializing_shards\u0026quot; : 0, \u0026quot;unassigned_shards\u0026quot; : 6, \u0026quot;delayed_unassigned_shards\u0026quot; : 0, \u0026quot;number_of_pending_tasks\u0026quot; : 0, \u0026quot;number_of_in_flight_fetch\u0026quot; : 0, \u0026quot;task_max_waiting_in_queue_millis\u0026quot; : 0, \u0026quot;active_shards_percent_as_number\u0026quot; : 50.0 } 通过命令行也同样可以：\nroot@infini:/opt/gateway# curl -v 192.168.3.4:8000/es1:_cat/nodes * Trying 192.168.3.4... * TCP_NODELAY set * Connected to 192.168.3.4 (192.168.3.4) port 8000 (#0) \u0026gt; GET /es1:_cat/nodes HTTP/1.1 \u0026gt; Host: 192.168.3.4:8000 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Thu, 14 Oct 2021 10:37:39 GMT \u0026lt; content-type: text/plain; charset=UTF-8 \u0026lt; Content-Length: 45 \u0026lt; X-Backend-Cluster: dev1 \u0026lt; X-Backend-Server: 192.168.3.188:9299 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; 192.168.3.188 48 38 5 cdhilmrstw * LENOVO * Connection #0 to host 192.168.3.4 left intact root@infini:/opt/gateway# curl -v 192.168.3.4:8000/es2:_cat/nodes * Trying 192.168.3.4... * TCP_NODELAY set * Connected to 192.168.3.4 (192.168.3.4) port 8000 (#0) \u0026gt; GET /es2:_cat/nodes HTTP/1.1 \u0026gt; Host: 192.168.3.4:8000 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: INFINI \u0026lt; Date: Thu, 14 Oct 2021 10:37:48 GMT \u0026lt; content-type: text/plain; charset=UTF-8 \u0026lt; Content-Length: 146 \u0026lt; X-elastic-product: Elasticsearch \u0026lt; Warning: 299 Elasticsearch-7.14.0-dd5a0a2acaa2045ff9624f3729fc8a6f40835aa1 \u0026quot;Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.14/security-minimal-setup.html to enable security.\u0026quot; \u0026lt; X-Backend-Cluster: dev \u0026lt; X-Backend-Server: 192.168.3.188:9216 \u0026lt; X-Filters: filters-\u0026gt;switch-\u0026gt;filters-\u0026gt;elasticsearch-\u0026gt;skipped \u0026lt; 192.168.3.188 26 38 3 cdfhilmrstw - node-714-1 192.168.3.188 45 38 3 cdfhilmrstw * LENOVO 192.168.3.188 43 38 4 cdfhilmrstw - node-714-2 * Connection #0 to host 192.168.3.4 left intact 参数说明 #     名称 类型 说明     path_rules array 根据 URL 路径的匹配规则   path_rules.prefix string 匹配的前缀字符串，建议以 : 结尾，匹配之后会移除该 URL 前缀转发给后面的 flow。   path_rules.flow string 匹配之后用于处理该请求的 flow 名称。   remove_prefix bool 转发请求之前，是否移除前缀匹配上的字符串，默认 true    "});index.add({'id':78,'href':'/docs/references/filters/translog/','title':"translog",'section':"在线过滤器",'content':"translog #  描述 #  translog 过滤器用来将收到的请求保存到本地文件，并压缩存放，可记录部分或完整的请求日志，用于归档和请求重放。\n配置示例 #  一个简单的示例如下：\nflow: - name: translog filter: - translog: max_file_age: 7 max_file_count: 10 参数说明 #     名称 类型 说明     path string 日志存放根目录，默认为网关数据目录下的 translog 子目录   category string 区分不同日志的二级分类子目录，默认为 default   filename string 设置日志的文件名，默认为 translog.log   compress bool 文件滚动之后是否压缩归档，默认为 true   max_file_age int 最多保留的归档文件天数，默认为 30 天   max_file_count int 最多保留的归档文件个数，默认为 100 天   max_file_size_in_mb int 单个归档文件的最大字节数，默认为 1024 MB    "});})();