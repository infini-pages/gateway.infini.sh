<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>动手教程 on INFINI Gateway</title><link>/zh/docs/tutorial/</link><description>Recent content in 动手教程 on INFINI Gateway</description><generator>Hugo -- gohugo.io</generator><atom:link href="/zh/docs/tutorial/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Log4j 漏洞处置</title><link>/zh/docs/tutorial/log4j2_filtering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/zh/docs/tutorial/log4j2_filtering/</guid><description>Apache Log4j 漏洞处置 # 【CVE 地址】
https://github.com/advisories/GHSA-jfh8-c2jp-5v3q
【漏洞描述】
Apache Log4j 是一款非常流行的开源的用于 Java 运行环境的日志记录工具包，大量的 Java 框架包括 Elasticsearch 的最新版本都使用了该组件，故影响范围非常之大。
近日, 随着 Apache Log4j 的远程代码执行最新漏洞细节被公开，攻击者可通过构造恶意请求利用该漏洞实现在目标服务器上执行任意代码。可导致服务器被黑客控制，从而进行页面篡改、数据窃取、挖矿、勒索等行为。建议使用该组件的用户第一时间启动应急响应进行修复。
简单总结一下就是，在使用 Log4j 打印输出的日志中，如果发现日志内容中包含关键词 ${，那么这个里面包含的内容会当做变量来进行替换和执行，导致攻击者可以通过恶意构造日志内容来让 Java 进程来执行任意命令，达到攻击的效果。
【漏洞等级】：非常紧急
此次漏洞是用于 Log4j2 提供的 lookup 功能造成的，该功能允许开发者通过一些协议去读取相应环境中的配置。但在实现的过程中，并未对输入进行严格的判断，从而造成漏洞的发生。
【影响范围】：Java 类产品：Apache Log4j 2.x &amp;lt; 2.15.0-rc2
【攻击检测】
可以通过检查日志中是否存在 jndi:ldap://、jndi:rmi 等字符来发现可能的攻击行为。
处理办法 # 如果 Elasticsearch 不能修改配置、或者替换 Log4j 的 jar 包和重启集群的，可以使用极限网关来进行拦截或者参数替换甚至是直接阻断请求。 通过在网关层对发往 Elasticsearch 的请求统一进行参数检测，将包含的敏感关键词 ${ 进行替换或者直接拒绝， 可以防止带攻击的请求到达 Elasticsearch 服务端而被 Log4j 打印相关日志的时候执行恶意攻击命令，从而避免被攻击。
参考配置 # 下载最新的 1.</description></item><item><title>在线查询修复的实现</title><link>/zh/docs/tutorial/online_query_rewrite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/zh/docs/tutorial/online_query_rewrite/</guid><description>在线查询修复的实现 # 在某些情况下，您可能会碰到业务代码生成的 QueryDSL 存在不合理的情况，一般做法是需要修改业务代码并发布上线， 如果上线新版本需要很长的时间，比如没有到投产窗口，或者封网，又或者需要和其他的代码提交一起上线，往往意味着需要大量的测试， 而生产环境的故障要立马解决，客户不能等啊，怎么办？
别着急，您可以使用极限网关来对查询进行动态修复。
举个例子 # 比如下面的这个查询：
GET _search { &amp;quot;size&amp;quot;: 1000000 , &amp;quot;explain&amp;quot;: true } 参数 size 设置的太大了，刚开始没有发现问题，随着数据越来越多，返回的数据太多势必会造成性能的急剧下降， 另外参数 explain 的开启也会造成不必要的性能开销，一般只在开发调试的时候才会用到这个功能。
通过在网关里面增加一个 request_body_json_set 过滤器，可以动态替换指定请求体 JSON PATH 的值，上面的例子对应的配置如下：
flow: - name: rewrite_query filter: - request_body_json_set: path: - explain -&amp;gt; false - size -&amp;gt; 10 - dump_request_body: - elasticsearch: elasticsearch: dev 通过重新设置 explain 和 size 参数，现在我们查询发给 Elasticsearch 前会被改写成如下格式：
{ &amp;quot;size&amp;quot;: 10, &amp;quot;explain&amp;quot;: false } 成功修复线上问题。</description></item><item><title>查询请求流量日志分析</title><link>/zh/docs/tutorial/request-logging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/zh/docs/tutorial/request-logging/</guid><description>查询请求流量日志分析 # 极限网关能够跟踪记录经过网关的所有请求，可用来分析发送给 Elasticsearch 的请求情况，用于分析请求性能和了解业务运行情况。
设置网关路由 # 如果需要开启极限网关的查询日志分析，需要在路由上面配置 tracing_flow 参数，设置一个流程来记录请求日志。
router: - name: default tracing_flow: request_logging default_flow: cache_first 上面的配置定义了一个名为 default 的路由，默认的请求流程为 cache_first，用于日志记录的流程为 request_logging。
定义日志流程 # 日志处理流程配置 request_logging 的定义如下：
flow: - name: request_logging filter: - request_path_filter: must_not: # any match will be filtered prefix: - /favicon.ico - request_header_filter: exclude: - app: kibana # in order to filter kibana's access log, config `elasticsearch.customHeaders: { &amp;quot;app&amp;quot;: &amp;quot;kibana&amp;quot; }` to your kibana's config `/config/kibana.</description></item><item><title>索引文档级别差异对比</title><link>/zh/docs/tutorial/index_diff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/zh/docs/tutorial/index_diff/</guid><description>索引差异对比 # 通过极限网关可以进行索引的文档差异对比，可以对同集群或者跨集群的两个不同的索引进行 diff 比较，对于使用应用双写、CCR 或者其他数据复制方案的场景，可以进行定期 diff 比较来确保数据是否真的一致。
功能演示 # 如何配置 # 设置目标集群 # 修改配置文件 gateway.yml，设置两个集群资源 source 和 target，增加如下配置：
elasticsearch: - name: source enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest - name: target enabled: true endpoint: http://localhost:9201 basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: test password: testtest 配置对比任务 # 增加一个服务管道配置，用来处理两个集群的索引文档拉取和对比，如下：
pipeline: - name: index_diff_service auto_start: true keep_running: true processor: - dag: parallel: - dump_hash: #dump es1's doc indices: &amp;quot;medcl-test&amp;quot; scroll_time: &amp;quot;10m&amp;quot; elasticsearch: &amp;quot;source&amp;quot; output_queue: &amp;quot;source_docs&amp;quot; batch_size: 10000 slice_size: 5 - dump_hash: #dump es2's doc indices: &amp;quot;medcl-test&amp;quot; scroll_time: &amp;quot;10m&amp;quot; batch_size: 10000 slice_size: 5 elasticsearch: &amp;quot;target&amp;quot; output_queue: &amp;quot;target_docs&amp;quot; end: - index_diff: diff_queue: &amp;quot;diff_result&amp;quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 上面的配置中，并行使用了 dump_hash 来拉取集群 source 的 medcl-a 索引和取集群 target 的 medcl-b 索引，并以文本结果的方式输出到终端。</description></item><item><title>与 Elasticsearch-Hadoop 集成</title><link>/zh/docs/tutorial/es-hadoop_integration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/zh/docs/tutorial/es-hadoop_integration/</guid><description>与 Elasticsearch-Hadoop 集成 # Elasticsearch-Hadoop 默认会通过某个种子节点拿到后端的所有 Elasticsearch 节点，可能存在热点和请求分配不合理的情况， 为了提高后端 Elasticsearch 节点的资源利用率，可以通过极限网关来实现后端 Elasticsearch 节点访问的精准路由。
写入加速 # 如果是通过 Elasticsearch-Hadoop 来进行数据导入，可以通过修改 Elasticsearch-Hadoop 程序的以下参数来访问极限网关来提升写入吞吐，如下：
名称 类型 说明 es.nodes string 设置访问网关的地址列表，如：localhost:8000,localhost:8001 es.nodes.discovery bool 设置为 false，不采用 sniff 模式，只访问配置的后端节点列表 es.nodes.wan.only bool 设置为 true，代理模式，强制走网关地址 es.batch.size.entries int 适当调大批次文档数，提升吞吐，如 5000 es.batch.size.bytes string 适当调大批次传输大小，提升吞吐，如 20mb es.batch.write.refresh bool 设置为 false，避免主动刷新，提升吞吐 相关链接 # Elasticsearch-Hadoop 配置参数文档</description></item><item><title>为 Kibana 添加代理和基础安全</title><link>/zh/docs/tutorial/proxy_kibana/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/zh/docs/tutorial/proxy_kibana/</guid><description>为 Kibana 添加代理和基础安全 # 如果你的 Kibana 版本比较多或者比较旧，或者没有设置 TLS 和身份信息，那么任何人都有可能直接访问 Kibana，而使用极限网关可以快速的进行修复。
使用 HTTP 过滤器来转发请求 # - http: schema: &amp;quot;http&amp;quot; #https or http host: &amp;quot;192.168.3.188:5602&amp;quot; 添加身份验证 # - basic_auth: valid_users: medcl: passwd 在路由里面可以替换静态资源 # - method: - GET pattern: - &amp;quot;/plugins/kibanaReact/assets/illustration_integrations_lightmode.svg&amp;quot; flow: - replace_logo_flow 开启 TLS # - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.0.0.0:8000 skip_occupied_port: true tls: enabled: true 完整配置如下 # entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 10000 network: binding: 0.</description></item><item><title>兼容不同版本的响应 Count 结构</title><link>/zh/docs/tutorial/fix_count_in_search_response/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/zh/docs/tutorial/fix_count_in_search_response/</guid><description>兼容不同版本的查询响应结果的 Count 结构 # Elasticsearch 在 7.0 之后的版本中，为了优化性能，搜索结果的命中数默认不进行精确的计数统计，同时对搜索结果的响应体进行了调整， 这样势必会造成已有代码的不兼容，如何快速修复呢？
结构对比 # 首先来对比下前后差异：
7 之前的搜索结构如下，total 显示的具体的数值：
{ &amp;quot;took&amp;quot;: 53, &amp;quot;timed_out&amp;quot;: false, &amp;quot;_shards&amp;quot;: { &amp;quot;total&amp;quot;: 1, &amp;quot;successful&amp;quot;: 1, &amp;quot;skipped&amp;quot;: 0, &amp;quot;failed&amp;quot;: 0 }, &amp;quot;hits&amp;quot;: { &amp;quot;total&amp;quot;: 0, &amp;quot;max_score&amp;quot;: null, &amp;quot;hits&amp;quot;: [] } } 7 之后的搜索结构如下，total 变成了一组描述范围的对象：
{ &amp;quot;took&amp;quot;: 3, &amp;quot;timed_out&amp;quot;: false, &amp;quot;_shards&amp;quot;: { &amp;quot;total&amp;quot;: 1, &amp;quot;successful&amp;quot;: 1, &amp;quot;skipped&amp;quot;: 0, &amp;quot;failed&amp;quot;: 0 }, &amp;quot;hits&amp;quot;: { &amp;quot;total&amp;quot;: { &amp;quot;value&amp;quot;: 10000, &amp;quot;relation&amp;quot;: &amp;quot;gte&amp;quot; }, &amp;quot;max_score&amp;quot;: 1, &amp;quot;hits&amp;quot;: [] } } Elasticsearch 提供的参数 # 不过在 7 里面，Elasticsearch 也提供了一个参数来控制是否进行精确计数，通过在查询请求的 url 参数里面加上 rest_total_hits_as_int=true 即可使用旧的行为方式，默认未开启。</description></item></channel></rss>