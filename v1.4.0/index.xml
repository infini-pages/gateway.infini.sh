<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>极限网关 on INFINI Gateway</title><link>/v1.4.0/</link><description>Recent content in 极限网关 on INFINI Gateway</description><generator>Hugo -- gohugo.io</generator><atom:link href="/v1.4.0/index.xml" rel="self" type="application/rss+xml"/><item><title>echo</title><link>/v1.4.0/docs/references/filters/echo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/echo/</guid><description>echo # 描述 # echo 过滤器是一个用于在返回结果里面输出指定字符信息的过滤器，常用于调试。
功能演示 # 配置示例 # 一个简单的示例如下：
flow: - name: hello_world filter: - echo: message: &amp;quot;hello infini\n&amp;quot; echo 过滤器可以设置重复输出相同的字符的次数，示例如下：
... - echo: message: &amp;quot;hello gateway\n&amp;quot; repeat: 3 ... 参数说明 # 名称 类型 说明 message string 需要输出的字符内容 repeat int 重复次数 stdout bool 是否在终端也打印输出，默认为 false</description></item><item><title>在线查询修复的实现</title><link>/v1.4.0/docs/tutorial/online_query_rewrite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/tutorial/online_query_rewrite/</guid><description>在线查询修复的实现 # 在某些情况下，您可能会碰到业务代码生成的 QueryDSL 存在不合理的情况，一般做法是需要修改业务代码并发布上线， 如果上线新版本需要很长的时间，比如没有到投产窗口，或者封网，又或者需要和其他的代码提交一起上线，往往意味着需要大量的测试， 而生产环境的故障要立马解决，客户不能等啊，怎么办？
别着急，您可以使用极限网关来对查询进行动态修复。
举个例子 # 比如下面的这个查询：
GET _search { &amp;quot;size&amp;quot;: 1000000 , &amp;quot;explain&amp;quot;: true } 参数 size 设置的太大了，刚开始没有发现问题，随着数据越来越多，返回的数据太多势必会造成性能的急剧下降， 另外参数 explain 的开启也会造成不必要的性能开销，一般只在开发调试的时候才会用到这个功能。
通过在网关里面增加一个 request_body_json_set 过滤器，可以动态替换指定请求体 JSON PATH 的值，上面的例子对应的配置如下：
flow: - name: rewrite_query filter: - request_body_json_set: path: - explain -&amp;gt; false - size -&amp;gt; 10 - dump_request_body: - elasticsearch: elasticsearch: dev 通过重新设置 explain 和 size 参数，现在我们查询发给 Elasticsearch 前会被改写成如下格式：
{ &amp;quot;size&amp;quot;: 10, &amp;quot;explain&amp;quot;: false } 成功修复线上问题。</description></item><item><title>同类对比</title><link>/v1.4.0/docs/overview/-comparison/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/overview/-comparison/</guid><description/></item><item><title>安装网关</title><link>/v1.4.0/docs/getting-started/install/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/getting-started/install/</guid><description>安装网关 # 极限网关支持主流的操作系统和平台，程序包很小，没有任何额外的外部依赖，安装起来应该是很快的 ：）
安装演示 # 下载安装 # 根据您所在的操作系统和平台选择下面相应的下载地址：
http://release.elasticsearch.cn/gateway/stable/
最新快照的下载地址访问：这里 容器部署 # 极限网关也支持 Docker 容器方式部署。
了解更多 验证安装 # 极限网关下载解压之后，我们可以执行这个命令来验证安装包是否有效，如下：
✗ ./bin/gateway -v gateway 1.0.0_SNAPSHOT 2021-01-03 22:45:28 6a54bb2 如果能够正常看到上面的版本信息，说明网关程序本身一切正常。
启动网关 # 以管理员身份直接运行网关程序即可启动极限网关了，如下：
➜ sudo ./bin/gateway ___ _ _____ __ __ __ _ / _ \ /_\ /__ \/__\/ / /\ \ \/_\ /\_/\ / /_\///_\\ / /\/_\ \ \/ \/ //_\\\_ _/ / /_\\/ _ \/ / //__ \ /\ / _ \/ \ \____/\_/ \_/\/ \__/ \/ \/\_/ \_/\_/ [GATEWAY] A light-weight, powerful and high-performance elasticsearch gateway.</description></item><item><title>服务入口</title><link>/v1.4.0/docs/references/entry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/entry/</guid><description>服务入口 # 定义入口 # 每一个网关都至少要对外暴露一个服务的入口，用来接收业务的操作请求，这个在极限网关里面叫做 entry，通过下面的参数即可定义：
entry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: false 通过参数 network.binding 可以指定服务监听的 IP 和地址，极限网关支持端口重用，也就是多个极限网关共享一个相同的 IP 和端口，这样可以充分利用服务器的资源， 也能做到不同网关进程的动态配置修改（通过开启多个进程，修改配置之后，依次重启各个进程）而不会中断客户端的正常请求。
每个发送到 entry 的请求都会通过 router 来进行流量的路由处理，router 在单独的地方定义规则，以方便在不同的 entry 间复用，entry 只需要通过 router 参数指定要使用的 router 规则即可，这里定义的是 default。
TLS 配置 # 极限网关支持无缝开启 TLS 传输加密，只需要将 tls.enabled 设置成 true，即可直接切换为 HTTPS 的通信模式，极限网关能自动生成自签证书。
极限网关也支持自定义证书路径，配置方式如下：
entry: - name: es_gateway enabled: true router: default network: binding: 0.0.0.0:8000 reuse_port: true tls: enabled: true cert_file: /etc/ssl.</description></item><item><title>查询请求流量日志分析</title><link>/v1.4.0/docs/tutorial/request-logging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/tutorial/request-logging/</guid><description>查询请求流量日志分析 # 极限网关能够跟踪记录经过网关的所有请求，可用来分析发送给 Elasticsearch 的请求情况，用于分析请求性能和了解业务运行情况。
设置网关路由 # 如果需要开启极限网关的查询日志分析，需要在路由上面配置 tracing_flow 参数，设置一个流程来记录请求日志。
router: - name: default tracing_flow: request_logging default_flow: cache_first 上面的配置定义了一个名为 default 的路由，默认的请求流程为 cache_first，用于日志记录的流程为 request_logging。
定义日志流程 # 日志处理流程配置 request_logging 的定义如下：
flow: - name: request_logging filter: - request_path_filter: must_not: # any match will be filtered prefix: - /favicon.ico - request_header_filter: exclude: - app: kibana # in order to filter kibana's access log, config `elasticsearch.customHeaders: { &amp;quot;app&amp;quot;: &amp;quot;kibana&amp;quot; }` to your kibana's config `/config/kibana.</description></item><item><title>浮动 IP</title><link>/v1.4.0/docs/references/modules/floating_ip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/modules/floating_ip/</guid><description>浮动 IP # 极限网关内置浮动 IP 功能，可以实现双机热备、故障转移的能力，极限网关天然提供四层网络流量的高可用，无需再额外考虑增加额外的软件和设备来保障因为停机、网络故障等造成的代理服务中断。
注意:
该特性目前仅支持 Mac OS、Linux 操作系统。且需要网关以 root 身份运行。 此特性依赖目标系统的 ping 和 ifconfig 命令，请确保相关包默认已安装。 一组启用浮动 IP 的网关所在网卡地址应该在一个子网，且内网广播互通（网关实际 IP 和浮动 IP 要求只最后一位地址不一样，如：192.168.3.x）。 功能演示 # Youtube Bilibili 什么是浮动 IP # 极限网关基于浮动 IP 来实现高可用，浮动 IP 也叫虚拟 IP 或者动态 IP，我们知道每台服务器之间都必须要有 IP 才能进行通信，一台服务器的 IP 一般是固定的并且一般要提前分配好， 如果这台服务器因为故障挂了的话，这个 IP 以及上面部署的业务也就不能访问了。 而一个浮动 IP 通常是一个公开的、可以路由到的 IP 地址，并且不会自动分配给实体设备。项目管理者临时分配这个动态IP到一个或者多个实体设备。 这个实体设备有自动分配的静态 IP 用于内部网间设备的通讯。这个内部网使用私有地址，这些私有地址不能被路由到。通过浮动 IP 内网实体的服务才能被外网识别和访问。
为什么需要浮动 IP # 在一个配置好浮动 IP 的典型切换场景是，当出现当前绑定浮动 IP 的机器出现故障的时候，浮动 IP 地址会飘到网络中的另一台设备。新设备无延迟的接替当掉的设备，并对外提供服务。 从而实现网络服务的高可用，对应业务的消费方来说，只需要指定浮动 IP 就可以了。 浮动 IP 非常有用，在某些特定的场景，比如客户端或者 SDK 只允许配置一个服务 IP 地址，所以这个 IP 一定要是高可用的，而极限网关正好解决了这个问题。 使用两个独立的极限网关服务器，最好部署在独立的物理服务器上，两台极限网关构成一组双机热备的状态，任意网关出现故障都能保障前端业务的正常访问。</description></item><item><title>服务路由</title><link>/v1.4.0/docs/references/router/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/router/</guid><description>服务路由 # 极限网关通过路由来判断流量的去向，一个典型的路由配置示例如下：
router: - name: my_router default_flow: default_flow tracing_flow: request_logging rules: - method: - PUT - POST pattern: - &amp;quot;/_bulk&amp;quot; - &amp;quot;/{index_name}/_bulk&amp;quot; flow: - bulk_process_flow 路由有几个非常重要的概念：
flow：请求的处理流程，一个路由里面有三个地方定义 flow default_flow: 默认的处理流，也就是业务处理的主流程，请求转发、过滤、缓存等操作都在这里面进行 tracing_flow：用于追踪请求状态的流，不受 default_flow 的影响，用于记录请求日志、统计等 rules：根据匹配规则将请求分发到特定的处理流中去，支持请求的 Method、Path 的正则匹配 参数说明 # 名称 类型 说明 name string 路由名称 default_flow string 默认的请求的处理流程名称 tracing_flow string 用于追踪请求的处理流程名称 rules array 路由规则列表，按照数组的先后顺序依次应用 rules.</description></item><item><title>某保险业务索引速度百倍提升</title><link>/v1.4.0/docs/user-cases/stories/indexing_speedup_for_big_index_rebuild/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/user-cases/stories/indexing_speedup_for_big_index_rebuild/</guid><description>某保险集团业务的索引速度百倍提升之旅 # 业务挑战 # 某大型保险集团的保单查询业务，通过将数据库的常用字段放到 Elasticsearch 里面，用来提升查询性能，集群部署在 14 台物理机上面，每个物理机上面部署了 4 个 Elasticsearch 实例， 整个集群约有 90 多亿条数据，索引主分片存储接近 5 TB，每天的增量更新数据大概在 6 亿条左右，由于业务上的特殊性，全国的所有的业务数据都存放在一个索引里面， 造成了单个索引达到了 210 个分片，批量重建的任务采用 Spark 任务来并行执行，平均的写入速度在 2000~3000 条/s 左右，一次增量重建时间可能需要 2~3 天， 业务数据的更新延迟较大，长时间的重建也会影响正常时间段的业务访问。该技术团队也尝试过直接对 Elasticsearch 层面和 Spark 写入端多轮的测试和调优，发现对整体的写入速度没有太大的提升。
应用场景 # 通过分析，集群性能应该没有问题，不过由于单个批次写入请求到达 Elasticsearch 之后需要重新再次按照主分片所在节点进行封装转发，而某保的业务索引分片个数太多，每个数据节点最终拿到的请求文档数太小， 客户端一次批次写入要拆分成几百次的小批次请求，并且由于短板原理，最慢的节点处理速度会拖慢整个批次写入的速度，从而造成集群总体吞吐的低下。
通过评估极限网关，发现极限网关具备提前拆分请求和合并请求的能力，通过提前拆分合并请求到以节点为单位的本地队列，然后通过队列消费程序写入到目标 Elasticsearch 集群，将随机的批次请求转换为顺序的精准投放，如下图：
极限网关在收到 Spark 请求之后先落地到本地磁盘确保数据不丢失，同时极限网关能够本地计算每个文档与目标数据节点的对应关系，新的数据写入架构如下图所示：
通过采用极限网关来接收 Spark 的写入请求，整个集群的写入吞吐显著提升，Spark 写数据只花了不到 15 分钟即任务运行结束，网关从收到请求到写完 Elasticsearch 也只花了 20 分钟，服务器的 CPU 资源也充分利用起来了， 各个节点的 CPU 利用率均达到 100%。
用户收益 # 索引速度提升 20000%</description></item><item><title>索引文档级别差异对比</title><link>/v1.4.0/docs/tutorial/index_diff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/tutorial/index_diff/</guid><description>索引差异对比 # 通过极限网关可以进行索引的文档差异对比，可以对同集群或者跨集群的两个不同的索引进行 diff 比较，对于使用应用双写、CCR 或者其他数据复制方案的场景，可以进行定期 diff 比较来确保数据是否真的一致。
功能演示 # 如何配置 # 设置目标集群 # 修改配置文件 gateway.yml，设置两个集群资源 source 和 target，增加如下配置：
elasticsearch: - name: source enabled: true endpoint: http://localhost:9200 basic_auth: username: test password: testtest - name: target enabled: true endpoint: http://localhost:9201 basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions username: test password: testtest 配置对比任务 # 增加一个服务管道配置，用来处理两个集群的索引文档拉取和对比，如下：
pipeline: - name: index_diff_service processor: - dag: parallel: - dump_hash: #dump es1's doc indices: &amp;quot;medcl-test&amp;quot; scroll_time: &amp;quot;10m&amp;quot; elasticsearch: &amp;quot;source&amp;quot; output_queue: &amp;quot;source_docs&amp;quot; batch_size: 10000 slice_size: 5 - dump_hash: #dump es2's doc indices: &amp;quot;medcl-test&amp;quot; scroll_time: &amp;quot;10m&amp;quot; batch_size: 10000 slice_size: 5 elasticsearch: &amp;quot;target&amp;quot; output_queue: &amp;quot;target_docs&amp;quot; end: - index_diff: diff_queue: &amp;quot;diff_result&amp;quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 上面的配置中，并行使用了 dump_hash 来拉取集群 source 的 medcl-a 索引和取集群 target 的 medcl-b 索引，并以文本结果的方式输出到终端。</description></item><item><title>索引段合并</title><link>/v1.4.0/docs/references/modules/force_merge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/modules/force_merge/</guid><description>主动合并索引分段 # 极限网关内置一个索引分段合并服务，可以主动对索引段文件进行合并，从而提升查询速度，段合并服务支持多个索引的依次顺序处理，并对合并任务状态进行了跟踪处理，避免大量段合并任务并行操作拖慢集群。
如何开启 # 修改配置文件 gateway.yml，增加如下配置：
force_merge: enabled: false elasticsearch: dev min_num_segments: 20 max_num_segments: 1 indices: - index_name 各参数说明如下：
名称 类型 说明 enabled bool 是否启用该模块，默认是 false elasticsearch string 操作的 Elasticsearch 集群 ID min_num_segments int 超过多少分片的索引才会执行主动分片合并，以索引为单位的统计数目 max_num_segments int 将分片下的段文件合并之后，最多生成的段文件个数 indices array 需要进行分片合并的索引列表 discovery object 自动发现索引的相关设置 discovery.min_idle_time string 满足段合并条件的最小时间跨度，默认 1d discovery.</description></item><item><title>跨云集群的就近本地访问</title><link>/v1.4.0/docs/user-cases/stories/a_cross_region_cluster_access_locality/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/user-cases/stories/a_cross_region_cluster_access_locality/</guid><description>跨云集群的就近本地访问 # 业务需求 # 作业帮为了确保某个业务 Elasticsearch 集群的高可用，在百度云和华为云上面采取了双云部署，即将单个 Elasticsearch 集群跨云进行部署，并且要求业务请求优先访问本地云。
Elasticsearch 单集群双云实现 # Elasticsearch 集群采用 Master 与 Data 节点分离的架构。 目前主力云放 2 个 Master，另外一个云放一个 Master。 主要考虑就是基础设施故障中，专线故障问题是大多数，某个云厂商整体挂的情况基本没有。 所以设置了主力云，当专线故障时，主力云的 Elasticsearch 是可以读写的，业务把流量切到主力云就行了。
具体配置方式如下。
首先，在 Master 节点上设置：
cluster.routing.allocation.awareness.attributes: zone_id cluster.routing.allocation.awareness.force.zone_id.values: zone_baidu,zone_huawei 然后分别在百度云上数据节点上设置：
node.attr.zone_id: zone_baidu 和华为云上数据节点上设置：
node.attr.zone_id: zone_huawei 创建索引采用 1 副本，可以保证百度云与华为云上都有一份相同的数据。
业务访问方式如下图：
百度云业务 -&amp;gt; 百度 lb -&amp;gt; INFINI Gateway (百度) -&amp;gt; Elasticsearch （百度云 data 节点） 华为云业务 -&amp;gt; 华为 lb -&amp;gt; INFINI Gateway (华为) -&amp;gt; Elasticsearch （华为云 data 节点） 极限网关配置 # Elasticsearch 支持一个 Preference 参数来设置请求的优先访问，通过在两个云内部的极限网关分别设置各自请求默认的 Preference 参数，让各个云内部的请求优先发往本云内的数据节点，即可实现请求的就近访问。</description></item><item><title>配置网关</title><link>/v1.4.0/docs/getting-started/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/getting-started/configuration/</guid><description>配置 # 极限网关支持多种方式来修改配置。
命令行参数 # 极限网关提供了命令行参数如下：
✗ ./bin/gateway --help Usage of ./bin/gateway: -config string the location of config file, default: gateway.yml (default &amp;quot;gateway.yml&amp;quot;) -cpu int the number of CPUs to use (default -1) -cpuprofile string write cpu profile to this file -daemon run in background as daemon -debug run in debug mode, gateway will quit with panic error -log string the log level,options:trace,debug,info,warn,error (default &amp;quot;info&amp;quot;) -memprofile string write memory profile to this file -pidfile string pidfile path (only for daemon mode) -pprof string enable and setup pprof/expvar service, eg: localhost:6060 , the endpoint will be: http://localhost:6060/debug/pprof/ and http://localhost:6060/debug/vars -v version 常用的说明如下：</description></item><item><title>容器部署</title><link>/v1.4.0/docs/getting-started/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/getting-started/docker/</guid><description>容器部署 # 极限网关支持容器方式部署，可以运行在 K8s 集群环境。
安装演示 # 下载镜像 # 极限网关的镜像发布在 Docker 的官方仓库，地址如下：
https://hub.docker.com/r/infinilabs/gateway
使用下面的命令即可获取最新的容器镜像：
docker pull infinilabs/gateway:latest 验证镜像 # 将镜像下载到本地之后，可以看到极限网关的容器镜像非常小，只有不到 25MB，所以下载的速度应该是非常快的。
✗ docker images REPOSITORY TAG IMAGE ID CREATED SIZE infinilabs/gateway latest fdae74b64e1a 47 minutes ago 23.5MB 创建配置 # 现在需要创建一个配置文件 gateway.yml，来进行基本的配置，如下：
path.data: data path.logs: log entry: - name: my_es_entry enabled: true router: my_router max_concurrency: 200000 network: binding: 0.0.0.0:8000 - name: my_es_entry1 enabled: true router: my_router max_concurrency: 200000 network: binding: 0.</description></item><item><title>硬件规格</title><link>/v1.4.0/docs/overview/hardware/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/overview/hardware/</guid><description/></item><item><title>系统调优</title><link>/v1.4.0/docs/getting-started/optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/getting-started/optimization/</guid><description>系统调优 # 要保证极限网关运行在最佳状态，其所在服务器的操作系统也需要进行相应的调优，以 Linux 为例。
系统参数 # vi /etc/security/limits.conf
* soft nofile 1024000 * hard nofile 1024000 * soft memlock unlimited * hard memlock unlimited root soft nofile 1024000 root hard nofile 1024000 root soft memlock unlimited 内核调优 # vi /etc/sysctl.conf
net.ipv4.ip_forward = 1 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.ip_nonlocal_bind=1 net.ipv4.tcp_tw_reuse=1 net.ipv4.tcp_timestamps=1 net.ipv4.tcp_syncookies=1 net.ipv4.tcp_max_syn_backlog=65535 net.ipv4.tcp_synack_retries=0 net.core.somaxconn=32768 net.core.netdev_max_backlog=65535 net.core.rmem_max=4194304 net.core.wmem_max=4194304 fs.file-max=10485760 vm.</description></item><item><title>处理流程</title><link>/v1.4.0/docs/references/flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/flow/</guid><description>处理流程 # 流程定义 # 每一个网关接收到的请求都会通过一系列的流程处理，最后才返回给客户端，流程的定义在极限网关里面叫做 flow，以下面的这个例子为例：
flow: - name: hello_world filter: - echo: str: &amp;quot;hello gateway\n&amp;quot; repeat: 1 - name: not_found filter: - echo: str: '404 not found\n' repeat: 1 上面的例子定义了两个 flow hello_world 和 not_found， 每个 flow 都使用了一个名为 echo 的过滤器，用来输出一段字符串，每个 flow 下面可以定义一系列 filter，他们按照定义的顺序依次执行。
语法说明 # 极限网关采用约定的格式来定义流程，并且支持灵活的条件参数来进行逻辑判断，具体的格式定义如下：
flow: - name: &amp;lt;flow_name&amp;gt; filter: - &amp;lt;filter_name&amp;gt;: when: &amp;lt;condition&amp;gt; &amp;lt;parameters&amp;gt; - &amp;lt;filter_name&amp;gt;: when: &amp;lt;condition&amp;gt; &amp;lt;parameters&amp;gt; ... 上面的 filter_name 代表具体的某个过滤器名称，用来执行特定的任务，when 下面的 condition 用来定义特定的满足执行该任务的条件参数，不满足条件的情况下会跳过该过滤器任务的执行，parameters 里面设置的该过滤器相关的参数，如果多个参数依次换行即可。</description></item><item><title>Elasticsearch</title><link>/v1.4.0/docs/references/elasticsearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/elasticsearch/</guid><description>Elasticsearch # 定义资源 # 极限网关支持多集群的访问，支持不同的版本，每个集群作为一个 Elasticsearch 后端资源，可以后续被极限网关的多个地方使用，以下面的这个例子为例：
elasticsearch: - name: local enabled: true endpoint: https://127.0.0.1:9200 - name: dev enabled: true endpoint: https://192.168.3.98:9200 basic_auth: username: elastic password: pass - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true interval: 10s basic_auth: username: elastic password: pass 上面的例子定义了一个名为 local 的本地开发测试集群，和一个名为 dev 的开发集群。开发集群开启了身份验证，这里也定义了相应的用户名和密码。 最后还定义了一个名为 prod 的生产集群，并且通过参数 discovery 开启了集群的节点拓扑自动发现和更新。
参数说明 # 名称 类型 说明 name string Elasticsearch 集群名称 enabled bool 是否启用 endpoint string Elasticsearch 访问地址，如: http://localhost:9200 endpoints array Elasticsearch 访问地址列表，支持多个入口地址，用于冗余 schema string 协议类型，http 或者 https host string Elasticsearch 主机，格式：localhost:9200，host 和 endpoint 任意选择一种配置方式即可 hosts array Elasticsearch 主机列表，支持多个入口地址，用于冗余 basic_auth object 身份认证信息 basic_auth.</description></item><item><title>请求上下文</title><link>/v1.4.0/docs/references/context/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/context/</guid><description>请求上下文 # 什么是上下文 # 上下文是极限网关用来访问当前运行环境下相关信息的入口，如请求的来源和配置信息等等，使用关键字 _ctx 即可访问相应的字段，如：_ctx.request.uri 表示请求的 URL 地址。
内置请求上下文 # HTTP 请求内置的 _ctx 上下文对象主要包括如下：
名称 类型 说明 id uint64 请求的唯一 ID tls bool 表示请求是否 TLS remote_addr string 客户端来源 IP local_addr string 网关本地 IP elapsed int64 请求已执行时间（毫秒） request.* object 描述请求信息 response.* object 描述响应信息 request # request 对象包含以下属性：</description></item><item><title>性能测试</title><link>/v1.4.0/docs/getting-started/benchmark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/getting-started/benchmark/</guid><description>性能测试 # 推荐使用 Elasticsearch 专属压测工具 Loadgen 来对网关进行性能压测。
Loadgen 的特点：
性能强劲 轻量级无依赖 支持模板化参数随机 支持高并发 支持压测端均衡流量控制 下载地址： http://release.elasticsearch.cn/loadgen/
Loadgen # Loadgen 使用非常简单，下载解压之后会得到两个文件，一个可执行程序和一个配置文件 loadgen.yml，配置文件样例如下：
variables: - name: ip type: file path: test/ip.txt - name: user type: file path: test/user.txt - name: id type: sequence - name: uuid type: uuid - name: now_local type: now_local - name: now_utc type: now_utc - name: now_unix type: now_unix requests: - request: has_variable: true method: GET basic_auth: username: elastic password: pass url: http://localhost:8000/medcl/_search body: '{ &amp;quot;query&amp;quot;: {&amp;quot;match&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;$[[user]]&amp;quot; }}}' 变量的使用 # 上面的配置中，variables 用来定义变量参数，根据 name 来设置变量标识，在构造请求的使用 $[[变量名]] 即可访问该变量的值，变量目前支持的类型有：</description></item><item><title>与 Elasticsearch-Hadoop 集成</title><link>/v1.4.0/docs/tutorial/es-hadoop_integration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/tutorial/es-hadoop_integration/</guid><description>与 Elasticsearch-Hadoop 集成 # Elasticsearch-Hadoop 默认会通过某个种子节点拿到后端的所有 Elasticsearch 节点，可能存在热点和请求分配不合理的情况， 为了提高后端 Elasticsearch 节点的资源利用率，可以通过极限网关来实现后端 Elasticsearch 节点访问的精准路由。
写入加速 # 如果是通过 Elasticsearch-Hadoop 来进行数据导入，可以通过修改 Elasticsearch-Hadoop 程序的以下参数来访问极限网关来提升写入吞吐，如下：
名称 类型 说明 es.nodes string 设置访问网关的地址列表，如：localhost:8000,localhost:8001 es.nodes.discovery bool 设置为 false，不采用 sniff 模式，只访问配置的后端节点列表 es.nodes.wan.only bool 设置为 true，代理模式，强制走网关地址 es.batch.size.entries int 适当调大批次文档数，提升吞吐，如 5000 es.batch.size.bytes string 适当调大批次传输大小，提升吞吐，如 20mb es.batch.write.refresh bool 设置为 false，避免主动刷新，提升吞吐 相关链接 # Elasticsearch-Hadoop 配置参数文档</description></item><item><title>其它配置</title><link>/v1.4.0/docs/references/config/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/config/</guid><description>其它配置 # 系统配置 # 系统配置主要用来设置极限网关的基础属性：
名称 类型 说明 path.data string 数据目录，默认为 data path.logs string 日志目录，默认为 log log.level string 日志级别，默认为 info log.debug bool 是否开启调试模式，当开启的时候，一旦出现异常程序直接退出，打印完整堆栈，仅用于调试定位故障点，默认为 false，生产环境不要开启，可能丢数据 log.disable_file_output bool 是否关闭本地文件的日志输出，默认为 false，容器环境不希望本地日志输出的可以开启本参数 allow_multi_instance bool 是否运行单个机器上面启动多个网关实例，默认为 true max_num_of_instances int 网关实例的最大个数，默认为 5</description></item><item><title>bulk_indexing</title><link>/v1.4.0/docs/references/processors/bulk_indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/processors/bulk_indexing/</guid><description>bulk_indexing # 描述 # bulk_indexing 处理器用来异步消费队列里面的 bulk 请求。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - bulk_indexing: elasticsearch: &amp;quot;dev&amp;quot; compress: true worker_size: 1 bulk_size_in_mb: 1 retry_delay_in_seconds: 5 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 1 max_connection_per_host int 目标主机允许的最大连接数，默认 5，单位秒 bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB elasticsearch string 保存到目标集群的名称 failure_queue string 故障请求的保存队列名称，默认为 %集群名%-failure invalid_queue string 不合法请求的保存队列名称，默认为 %集群名%-invalid dead_letter_queue string 超过最大重试次数的请求的保存队列名称，默认为 %集群名%-dead_letter process_failure_queue bool 是否主动不断重试处理故障队列里面的请求数据 queues array 手动指定的一组需要消费的队列名称 index array 设置一组索引名称，单独开启的索引分片级别的消费队列 shards array 设置分片级别允许请求通过的分片 ID，其余的丢弃 bulk.</description></item><item><title>bulk_reshuffle</title><link>/v1.4.0/docs/references/filters/bulk_reshuffle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/bulk_reshuffle/</guid><description>bulk_reshuffle # 描述 # 极限网关具有本地计算每个索引文档对应后端 Elasticsearch 集群的目标存放位置的能力，从而能够精准的进行请求定位，在一批 bulk 请求中，可能存在多个后端节点的数据，bulk_reshuffle 过滤器用来将正常的 bulk 请求打散，按照目标节点或者分片进行拆分重新组装，避免 Elasticsearch 节点收到请求之后再次进行请求分发， 从而降低 Elasticsearch 集群间的流量和负载，也能避免单个节点成为热点瓶颈，确保各个数据节点的处理均衡，从而提升集群总体的索引吞吐能力。
配置示例 # 一个简单的示例如下：
flow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: node mode: sync - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 以上配置表示会将 bulk 请求拆分，按照索引文档所对应的目标节点，重新拆组装，然后分别同步提交到目标 Elasticsearch 节点。
节点级别的异步提交 # 默认的同步提交方式可能受目标 Elasticsearch 服务的性能影响，极限网关支持异步的提交方式，将数据线落地到本地磁盘队列，然后通过单独的任务来消费提交。
当极限网关处于开启异步模式的情况下，就算后端 Elasticsearch 集群出现故障也不会影响索引操作的正常进行，因为请求都是存放在网关本地的磁盘队列，从而解耦了前端索引和后端集群的依赖。因此就算后端 Elasticsearch 集群出现故障、进行重启、或是版本升级都不会影响正常的索引操作。 配置流程 # 首先定义一个异步的请求处理流程。
flow: - name: online_indexing_merge filter: - bulk_reshuffle: elasticsearch: prod level: node mode: async - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 极限网关会以目标节点为单位来将请求存放到本地磁盘。</description></item><item><title>bulk_response_validate</title><link>/v1.4.0/docs/references/filters/bulk_response_validate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/bulk_response_validate/</guid><description>bulk_response_validate # 描述 # bulk_response_validate 过滤器用来验证 Elasticsearch 的 Bulk 请求是否正确执行完成。
配置示例 # 一个简单的示例如下：
flow: - name: bulk_response_validate filter: - bulk_response_validate: invalid_status: 500 参数说明 # 名称 类型 说明 invalid_status int 当 Bulk 请求不成功的时候，设置请求响应的状态码。</description></item><item><title>cache</title><link>/v1.4.0/docs/references/filters/cache/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/cache/</guid><description>cache # 描述 # cache 过滤器由 get_cache 和 set_cache 两组过滤器组成，一般需要组合使用，可用于缓存加速查询，抵挡重复请求，降低后端集群查询压力。
get_cache 过滤器 # 过滤器 get_cache 用来从缓存里面获取之前出现的消息，直接返回给客户端，避免访问后端 Elasticsearch，用于缓存热点数据。
配置示例如下：
flow: - name: get_cache filter: - get_cache: pass_patterns: [&amp;quot;_cat&amp;quot;,&amp;quot;scroll&amp;quot;, &amp;quot;scroll_id&amp;quot;,&amp;quot;_refresh&amp;quot;,&amp;quot;_cluster&amp;quot;,&amp;quot;_ccr&amp;quot;,&amp;quot;_count&amp;quot;,&amp;quot;_flush&amp;quot;,&amp;quot;_ilm&amp;quot;,&amp;quot;_ingest&amp;quot;,&amp;quot;_license&amp;quot;,&amp;quot;_migration&amp;quot;,&amp;quot;_ml&amp;quot;,&amp;quot;_rollup&amp;quot;,&amp;quot;_data_stream&amp;quot;,&amp;quot;_open&amp;quot;, &amp;quot;_close&amp;quot;] 参数说明 # 名称 类型 说明 pass_patterns string 设置忽略缓存的请求规则，URL 包含其中的任意关键字将跳过缓存 set_cache 过滤器 # 过滤器 set_cache 用来将后端查询拿到的返回结果存到缓存里面，可以设置过期时间。
配置示例如下：
flow: - name: get_cache filter: - set_cache: min_response_size: 100 max_response_size: 1024000 cache_ttl: 30s max_cache_items: 100000 参数说明 # 名称 类型 说明 cache_type string 缓存类型，支持 ristretto，ccache 和 redis，默认 ristretto cache_ttl string 缓存的过期时间，默认 10s async_search_cache_ttl string 异步请求结果的缓存过期时间，默认 10m min_response_size int 最小符合缓存要求的消息体大小，默认 -1 表示不限制 max_response_size int 最大符合缓存要求的消息体大小，默认为 int 的最大值 max_cached_item int 最大的缓存消息总数，默认 1000000，当类型为 ccache有效 max_cached_size int 最大的缓存内存开销，默认 1000000000 即 1GB，当类型为 ristretto 有效 validated_status_code array 允许被缓存的请求状态码，默认 200,201,404,403,413,400,301 其它参数 # 如果希望主动忽略缓存，可以在 URL 的参数里面传递一个 no_cache 来让网关忽略缓存。如：</description></item><item><title>clone</title><link>/v1.4.0/docs/references/filters/clone/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/clone/</guid><description>clone # 描述 # clone 过滤器用来将流量克隆转发到另外的一个处理流程，可以实现双写、多写、多数据中心同步、集群升级、版本切换等需求。
配置示例 # 一个简单的示例如下：
flow: - name: double_write filter: - clone: flows: - write_to_region_a - write_to_region_b #last one's response will be output to client - name: write_to_region_a filter: - elasticsearch: elasticsearch: es1 - name: write_to_region_b filter: - elasticsearch: elasticsearch: es2 上面的例子可以将 Elasticsearch 的请求复制到两个不同的异地集群。
参数说明 # 名称 类型 说明 flows array 指定多个流量处理的流程，依次同步执行，将最后一个流程处理的结果输出给客户端 continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。</description></item><item><title>dag</title><link>/v1.4.0/docs/references/processors/dag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/processors/dag/</guid><description>dag # 描述 # dag 处理器用来管理任务的并行调度。
配置示例 # 下面的这个例子，定义了一个名为 racing_example 的服务，auto_start 设置为自动启动，processor 设置依次执行的每个处理单元，其中 dag 处理器支持多个任务并行执行，支持 wait_all 和 first_win 两种聚合模式，如下：
pipeline: - name: racing_example auto_start: true processor: - echo: #ready, set, go message: read,set,go - dag: mode: wait_all #first_win, wait_all parallel: - echo: #player1 message: player1 - echo: #player2 message: player2 - echo: #player3 message: player3 end: - echo: #checking score message: checking score - echo: #announce champion message: 'announce champion' - echo: #done message: racing finished 上面的 echo 处理器非常简单，用来输出一个指定的消息，这个管道模拟的是一个赛跑的场景，palyer1、2、3 并行赛跑，全部跑完之后再进行算分和宣布比赛冠军，最后输出结束信息，程序运行输出如下：</description></item><item><title>date_range_precision_tuning</title><link>/v1.4.0/docs/references/filters/date_range_precision_tuning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/date_range_precision_tuning/</guid><description>date_range_precision_tuning # 描述 # date_range_precision_tuning 过滤器用来重设时间范围查询的时间精度，通过调整精度，可以让短时间内邻近的重复请求更容易被缓存，对于有一些对于时间精度不那么高但是数据量非常大的场景，比如使用 Kibana 来做报表分析，通过缩减精度来缓存重复的查询请求，从而降低后端服务器压力，前端报表展现的提速非常明显。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - date_range_precision_tuning: time_precision: 4 - get_cache: - elasticsearch: elasticsearch: dev - set_cache: 精度说明 # Kibana 默认发往 Elasticsearch 的查询，使用的是当前时间 Now，精度到毫秒，通过设置不同的精度来改写查询，以下面的查询为例：
{&amp;quot;range&amp;quot;:{&amp;quot;@timestamp&amp;quot;:{&amp;quot;gte&amp;quot;:&amp;quot;2019-09-26T08:21:12.152Z&amp;quot;,&amp;quot;lte&amp;quot;:&amp;quot;2020-09-26T08:21:12.152Z&amp;quot;,&amp;quot;format&amp;quot;:&amp;quot;strict_date_optional_time&amp;quot;} 分别设置不同的精度，改写之后的查询结果如下：
精度 新的查询 0 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T00:00:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T23:59:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 1 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T00:00:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T09:59:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 2 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:00:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T08:59:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 3 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:20:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T08:29:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 4 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:21:00.000Z&amp;rdquo;,&amp;ldquo;lte&amp;rdquo;:&amp;ldquo;2020-09-26T08:21:59.999Z&amp;rdquo;,&amp;ldquo;format&amp;rdquo;:&amp;ldquo;strict_date_optional_time&amp;rdquo;} 5 {&amp;ldquo;range&amp;rdquo;:{&amp;quot;@timestamp&amp;quot;:{&amp;ldquo;gte&amp;rdquo;:&amp;ldquo;2019-09-26T08:21:10.</description></item><item><title>drop</title><link>/v1.4.0/docs/references/filters/drop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/drop/</guid><description>drop # 描述 # drop 过滤器用来丢弃某个消息，提前结束请求的处理。
配置示例 # 一个简单的示例如下：
flow: - name: drop filter: - drop:</description></item><item><title>dump</title><link>/v1.4.0/docs/references/filters/dump/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/dump/</guid><description>dump # 描述 # dump 过滤器是一个用于在终端打印 Dump 输出相关请求信息的过滤器，主要用于调试。
配置示例 # 一个简单的示例如下：
flow: - name: hello_world filter: - dump: uri: true request_header: true request_body: true response_body: true status_code: true 参数说明 # dump 过滤器比较简单，在需要的流程处理阶段插入 dump 过滤器，即可在终端输出相应阶段的请求信息，方便调试。
名称 类型 说明 request bool 是否输出全部完整的请求信息 uri bool 是否输出请求的 URI 信息 query_args bool 是否输出请求的参数信息 user bool 是否输出请求的用户信息 api_key bool 是否输出请求的 APIKey 信息 request_header bool 是否输出请求的头信息 response_header bool 是否输出响应的头信息 status_code bool 是否输出响应的状态码 context array 输出自定义的上下文信息 输出上下文 # 可以使用 context 参数来调试请求上下文信息，示例配置文件：</description></item><item><title>dump_hash</title><link>/v1.4.0/docs/references/processors/dump_hash/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/processors/dump_hash/</guid><description>dump_hash # 描述 # dump_hash 处理器用来导出集群的索引文档并计算 Hash。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - dump_hash: #dump es1's doc indices: &amp;quot;medcl-dr3&amp;quot; scroll_time: &amp;quot;10m&amp;quot; elasticsearch: &amp;quot;source&amp;quot; query: &amp;quot;field1:elastic&amp;quot; fields: &amp;quot;doc_hash&amp;quot; output_queue: &amp;quot;source_docs&amp;quot; batch_size: 10000 slice_size: 5 参数说明 # 名称 类型 说明 elasticsearch string 目标集群的名称 scroll_time string Scroll 回话超时时间 batch_size int Scroll 批次大小，默认 5000 slice_size int Slice 大小，默认 1 sort_type string 文档排序类型，默认 asc sort_field string 文档排序字段 indices string 索引 query string 查询过滤条件 fields string 要返回的字段列表 output_queue string 输出结果的名称</description></item><item><title>elasticsearch</title><link>/v1.4.0/docs/references/filters/elasticsearch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/elasticsearch/</guid><description>elasticsearch # 描述 # elasticsearch 过滤器是一个用于请求转发给后端 Elasticsearch 集群的过滤器。
配置示例 # 使用 elasticsearch 过滤器之前，需要提前定义一个 Elasticsearch 的集群配置节点，如下：
elasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 流程的配置示例如下：
flow: - name: cache_first filter: - elasticsearch: elasticsearch: prod 上面的例子即将请求转发给 prod 集群。
自动更新 # 对于一个大规模的集群，可能存在很多的节点，不可能一一配置后端的所有节点，只需要先指定 Elasticsearch 模块允许自动发现后端节点，如下：
elasticsearch: - name: prod enabled: true endpoint: http://192.168.3.201:9200 discovery: enabled: true refresh: enabled: true basic_auth: username: elastic password: pass 然后过滤器这边的配置也开启刷新，即可访问后端所有节点，且节点上下线也会自动更新，示例如下：
flow: - name: cache_first filter: - elasticsearch: elasticsearch: prod refresh: enabled: true interval: 30s 设置权重 # 如果后端集群很多，极限网关支持对不同的节点设置不同的访问权重，配置示例如下：</description></item><item><title>elasticsearch_health_check</title><link>/v1.4.0/docs/references/filters/elasticsearch_health_check/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/elasticsearch_health_check/</guid><description>elasticsearch_health_check # 描述 # elasticsearch_health_check 过滤器用来以限速模式下主动探测 Elasticsearch 的健康情况， 当出现后端故障的情况下，可以触发一次主动的集群健康检查，而不用等待 Elasticsearch 默认的轮询检查结果，限速设置为最多每秒发送一次检查请求给后端 Elasticsearch。
配置示例 # 一个简单的示例如下：
flow: - name: elasticsearch_health_check filter: - elasticsearch_health_check: elasticsearch: dev 参数说明 # 名称 类型 说明 elasticsearch string 集群 ID interval int 设置最少执行请求的时间间隔，单位秒，默认 1</description></item><item><title>flow</title><link>/v1.4.0/docs/references/filters/flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/flow/</guid><description>flow # 描述 # flow 过滤器用来跳转或执行某个或一系列其他流程。
配置示例 # 一个简单的示例如下：
flow: - name: flow filter: - flow: flows: - request_logging 参数说明 # 名称 类型 说明 flows array 流程 ID，数组格式，可以指定多个，依次执行</description></item><item><title>flow_runner</title><link>/v1.4.0/docs/references/processors/flow_runner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/processors/flow_runner/</guid><description>flow_runner # 描述 # flow_runner 处理器用来异步消费队列里面的请求并使用异步用于在线请求的处理流程来进行消费处理。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - flow_runner: input_queue: &amp;quot;primary_deadletter_requests&amp;quot; flow: primary-flow-post-processing when: cluster_available: [ &amp;quot;primary&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue string 订阅的队列名称 flow string 以什么样的流程来消费队列里面的请求消息</description></item><item><title>index_diff</title><link>/v1.4.0/docs/references/processors/index_diff/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/processors/index_diff/</guid><description>index_diff # 描述 # index_diff 处理器用来对两个结果集进行差异对比。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - index_diff: diff_queue: &amp;quot;diff_result&amp;quot; buffer_size: 1 text_report: true #如果要存 es，这个开关关闭，开启 pipeline 的 diff_result_ingest 任务 source_queue: 'source_docs' target_queue: 'target_docs' 参数说明 # 名称 类型 说明 source_queue string 来源数据的名称 target_queue string 目标数据的名称 diff_queue string 存放 diff 结果的队列 buffer_size int 内存 buffer 大小 keep_source bool diff 结果里面是否包含文档 source 信息 text_report bool 是否输出文本格式的结果</description></item><item><title>json_indexing</title><link>/v1.4.0/docs/references/processors/json_indexing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/processors/json_indexing/</guid><description>json_indexing # 描述 # json_indexing 处理器用来消费队列里面的纯 JSON 文档，并保存到指定的 Elasticsearch 服务器里面。
配置示例 # 一个简单的示例如下：
pipeline: - name: request_logging_index auto_start: true keep_running: true processor: - json_indexing: index_name: &amp;quot;gateway_requests&amp;quot; elasticsearch: &amp;quot;dev&amp;quot; input_queue: &amp;quot;request_logging&amp;quot; idle_timeout_in_seconds: 1 worker_size: 1 bulk_size_in_mb: 10 参数说明 # 名称 类型 说明 input_queue int 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 5，单位秒 bulk_size_in_kb int 批次请求的单位大小，单位 KB bulk_size_in_mb int 批次请求的单位大小，单位 MB elasticsearch string 保存到目标集群的名称 index_name string 保存到目标集群的索引名称 type_name string 保存到目标集群的索引类型名称，默认根据集群版本来设置，v7 以前为 doc，之后为 _doc</description></item><item><title>ldap_auth</title><link>/v1.4.0/docs/references/filters/ldap_auth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/ldap_auth/</guid><description>ldap_auth # 描述 # ldap_auth 过滤器用来设置基于 LDAP 的身份认证。
配置示例 # 一个简单的示例如下：
flow: - name: ldap_auth filter: - ldap_auth: host: &amp;quot;ldap.forumsys.com&amp;quot; port: 389 bind_dn: &amp;quot;cn=read-only-admin,dc=example,dc=com&amp;quot; bind_password: &amp;quot;password&amp;quot; base_dn: &amp;quot;dc=example,dc=com&amp;quot; user_filter: &amp;quot;(uid=%s)&amp;quot; 上面的配置使用的是在线的免费 LDAP 测试服务器，测试用户 tesla，密码 password。
➜ curl http://127.0.0.1:8000/ -u tesla:password { &amp;quot;name&amp;quot; : &amp;quot;192.168.3.7&amp;quot;, &amp;quot;cluster_name&amp;quot; : &amp;quot;elasticsearch&amp;quot;, &amp;quot;cluster_uuid&amp;quot; : &amp;quot;ZGTwWtBfSLWRpsS1VKQDiQ&amp;quot;, &amp;quot;version&amp;quot; : { &amp;quot;number&amp;quot; : &amp;quot;7.8.0&amp;quot;, &amp;quot;build_flavor&amp;quot; : &amp;quot;default&amp;quot;, &amp;quot;build_type&amp;quot; : &amp;quot;tar&amp;quot;, &amp;quot;build_hash&amp;quot; : &amp;quot;757314695644ea9a1dc2fecd26d1a43856725e65&amp;quot;, &amp;quot;build_date&amp;quot; : &amp;quot;2020-06-14T19:35:50.</description></item><item><title>logging</title><link>/v1.4.0/docs/references/filters/logging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/logging/</guid><description>logging # 描述 # logging 过滤器用来按请求记录下来，通过异步记录到本地磁盘的方式，尽可能降低对请求的延迟影响，对于流量很大的场景，建议配合其它请求过滤器来降低日志的总量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - logging: queue_name: request_logging 记录的请求日志样例如下：
{ &amp;quot;_index&amp;quot; : &amp;quot;gateway_requests&amp;quot;, &amp;quot;_type&amp;quot; : &amp;quot;doc&amp;quot;, &amp;quot;_id&amp;quot; : &amp;quot;EH5bG3gBsbC2s3iWFzCF&amp;quot;, &amp;quot;_score&amp;quot; : 1.0, &amp;quot;_source&amp;quot; : { &amp;quot;tls&amp;quot; : false, &amp;quot;@timestamp&amp;quot; : &amp;quot;2021-03-10T08:57:30.645Z&amp;quot;, &amp;quot;conn_time&amp;quot; : &amp;quot;2021-03-10T08:57:30.635Z&amp;quot;, &amp;quot;flow&amp;quot; : { &amp;quot;from&amp;quot; : &amp;quot;127.0.0.1&amp;quot;, &amp;quot;process&amp;quot; : [ &amp;quot;request_body_regex_replace&amp;quot;, &amp;quot;get_cache&amp;quot;, &amp;quot;date_range_precision_tuning&amp;quot;, &amp;quot;get_cache&amp;quot;, &amp;quot;elasticsearch&amp;quot;, &amp;quot;set_cache&amp;quot;, &amp;quot;||&amp;quot;, &amp;quot;request_logging&amp;quot; ], &amp;quot;relay&amp;quot; : &amp;quot;192.168.43.101-Quartz&amp;quot;, &amp;quot;to&amp;quot; : [ &amp;quot;localhost:9200&amp;quot; ] }, &amp;quot;id&amp;quot; : 3, &amp;quot;local_ip&amp;quot; : &amp;quot;127.</description></item><item><title>queue</title><link>/v1.4.0/docs/references/filters/queue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/queue/</guid><description>queue # 描述 # queue 过滤器用来保存请求到消息队列。
配置示例 # 一个简单的示例如下：
flow: - name: queue filter: - queue: queue_name: queue_name 参数说明 # 名称 类型 说明 depth_threshold int 大于队列指定深度才能存入队列，默认为 0 queue_name string 消息队列名称</description></item><item><title>queue_consumer</title><link>/v1.4.0/docs/references/processors/queue_consumer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/processors/queue_consumer/</guid><description>queue_consumer # 描述 # queue_consumer 处理器用来异步消费队列里面的请求到 Elasticsearch。
配置示例 # 一个简单的示例如下：
pipeline: - name: bulk_request_ingest auto_start: true keep_running: true processor: - queue_consumer: input_queue: &amp;quot;backup&amp;quot; elasticsearch: &amp;quot;backup&amp;quot; waiting_after: [ &amp;quot;backup_failure_requests&amp;quot;] worker_size: 20 when: cluster_available: [ &amp;quot;backup&amp;quot; ] 参数说明 # 名称 类型 说明 input_queue int 订阅的队列名称 worker_size int 并行执行消费任务的线程数，默认 1 idle_timeout_in_seconds int 消费队列的超时时间，默认 1 elasticsearch string 保存到目标集群的名称 waiting_after array 需要先等将这些指定队列消费完才能开始消费主队列里面的数据 failure_queue string 因为后端故障执行失败的情况，默认为 %input_queue%-failure invalid_queue string 状态码返回为 4xx 的请求，默认为 %input_queue%-invalid compress bool 是否压缩请求，默认 false</description></item><item><title>ratio</title><link>/v1.4.0/docs/references/filters/ratio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/ratio/</guid><description>ratio # 描述 # ratio 过滤器用来将正常的流量按照比例迁移转发到另外的一个处理流程，可以实现灰度发布、流量迁移导出，或者将部分流量切换到不同版本集群用于测试的能力。
配置示例 # 一个简单的示例如下：
flow: - name: ratio_traffic_forward filter: - ratio: ratio: 0.1 flow: hello_world continue: true 参数说明 # 名称 类型 说明 ratio float 需要迁移的流量比例 flow string 指定新的流量处理流程 continue bool 流量迁移出去之后，是否还继续执行之前的既定流程，设置成 false 则立即返回，默认 false。</description></item><item><title>redis_pubsub</title><link>/v1.4.0/docs/references/filters/redis_pubsub/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/redis_pubsub/</guid><description>redis_pubsub # 描述 # reids 过滤器用来将收到的请求和响应结果保存到 Redis 消息队列中。
配置示例 # 一个简单的示例如下：
flow: - name: redis_pubsub filter: - redis_pubsub: host: 127.0.0.1 port: 6379 channel: gateway response: true 参数说明 # 名称 类型 说明 host string Reids 主机名，默认 localhost port int Reids 端口号，默认为 6379 password string Redis 密码 db int Redis 默认选择的数据库，默认为 0 channel string Redis 消息队列名称，必填，没有默认值 response bool 是否包含响应结果，默认为 true</description></item><item><title>request_api_key_filter</title><link>/v1.4.0/docs/references/filters/request_api_key_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_api_key_filter/</guid><description>request_api_key_filter # 描述 # 当 Elasticsearch 是通过 API Key 方式来进行身份认证的时候，request_api_key_filter 过滤器可用来按请求的 API ID 来进行过滤。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_api_key_filter: message: &amp;quot;Request filtered!&amp;quot; exclude: - VuaCfGcBCdbkQm-e5aOx 上面的例子表示，来自 VuaCfGcBCdbkQm-e5aOx 的请求会被拒绝，如下。
➜ ~ curl localhost:8000 -H &amp;quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==&amp;quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.0.0.1) port 8000 (#0) &amp;gt; GET / HTTP/1.1 &amp;gt; Host: localhost:8000 &amp;gt; User-Agent: curl/7.</description></item><item><title>request_api_key_limiter</title><link>/v1.4.0/docs/references/filters/request_api_key_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_api_key_limiter/</guid><description>request_api_key_limiter # 描述 # request_api_key_limiter 过滤器用来按照 API Key 来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_api_key_limiter: id: - VuaCfGcBCdbkQm-e5aOx max_requests: 1 action: drop # retry or drop message: &amp;quot;your api_key reached our limit&amp;quot; 上面的配置中，对 VuaCfGcBCdbkQm-e5aOx 这个 API ID 进行限速，允许的最大 qps 为 1 每秒。
➜ ~ curl localhost:8000 -H &amp;quot;Authorization: ApiKey VnVhQ2ZHY0JDZGJrUW0tZTVhT3g6dWkybHAyYXhUTm1zeWFrdzl0dk5udw==&amp;quot; -v * Rebuilt URL to: localhost:8000/ * Trying 127.0.0.1... * TCP_NODELAY set * Connected to localhost (127.</description></item><item><title>request_body_json_del</title><link>/v1.4.0/docs/references/filters/request_body_json_del/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_body_json_del/</guid><description>request_body_json_del # 描述 # request_body_json_del 过滤器用来删除 JSON 格式的请求体里面的部分字段。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_body_json_del: path: - query.bool.should.[0] - query.bool.must 参数说明 # 名称 类型 说明 path array 需要删除的 JSON PATH 键值 ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false</description></item><item><title>request_body_json_set</title><link>/v1.4.0/docs/references/filters/request_body_json_set/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_body_json_set/</guid><description>request_body_json_set # 描述 # request_body_json_set 过滤器用来修改 JSON 格式的请求体。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_body_json_set: path: - aggs.total_num.terms.field -&amp;gt; &amp;quot;name&amp;quot; - aggs.total_num.terms.size -&amp;gt; 3 - size -&amp;gt; 0 参数说明 # 名称 类型 说明 path map 使用 -&amp;gt; 作为标识符的键值对， JSON PATH 和需要替换的值 ignore_missing bool 如果这个 JSON Path 不存在，是否忽略处理，默认 false</description></item><item><title>request_body_regex_replace</title><link>/v1.4.0/docs/references/filters/request_body_regex_replace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_body_regex_replace/</guid><description>request_body_regex_replace # 描述 # request_body_regex_replace 过滤器使用正则表达式来替换请求体正文的字符串内容。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_body_regex_replace: pattern: '&amp;quot;size&amp;quot;: 10000' to: '&amp;quot;size&amp;quot;: 100' - elasticsearch: elasticsearch: prod - dump: request_body: true 上面的示例将会替换发送给 Elasticsearch 请求体里面，size 设置为 10000 的部分修改为 100，可以用来动态修复错误或者不合理的查询。
测试如下：
curl -XPOST &amp;quot;http://localhost:8000/myindex/_search&amp;quot; -H 'Content-Type: application/json' -d' { &amp;quot;query&amp;quot;: { &amp;quot;match_all&amp;quot;: {} },&amp;quot;size&amp;quot;: 10000 }' 实际发生的查询：
{ &amp;quot;_index&amp;quot; : &amp;quot;gateway_requests&amp;quot;, &amp;quot;_type&amp;quot; : &amp;quot;doc&amp;quot;, &amp;quot;_id&amp;quot; : &amp;quot;EH5bG3gBsbC2s3iWFzCF&amp;quot;, &amp;quot;_score&amp;quot; : 1.</description></item><item><title>request_client_ip_filter</title><link>/v1.4.0/docs/references/filters/request_client_ip_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_client_ip_filter/</guid><description>request_client_ip_filter # 描述 # request_client_ip_filter 过滤器用来按请求的来源用户 IP 信息来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_client_ip_filter: exclude: - 192.168.3.67 上面的例子表示，来自 192.168.3.67 的请求不允许通过。
路由跳转的例子:
flow: - name: echo filter: - echo: message: hello stanger - name: default_flow filter: - request_client_ip_filter: action: redirect_flow flow: echo exclude: - 192.168.3.67 来自 192.168.3.67 会跳转到另外的 echo 流程。
参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求 IP 数组列表 include array 允许通过的请求 IP 数组列表 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_client_ip_limiter</title><link>/v1.4.0/docs/references/filters/request_client_ip_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_client_ip_limiter/</guid><description>request_client_ip_limiter # 描述 # request_client_ip_limiter 过滤器用来按照请求客户端 IP 来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_client_ip_limiter: ip: #only limit for specify ips - 127.0.0.1 max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: &amp;quot;your ip reached our limit&amp;quot; 上面的配置中，对 127.0.0.1 这个 IP 进行限速，允许的最大 qps 为 256。
参数说明 # 名称 类型 说明 ip array 设置哪些客户端 IP 会参与限速，不设置表示所有 IP 参与 interval string 评估限速的单位时间间隔，默认为 1s max_requests int 单位间隔内最大的请求次数限额 max_bytes int 单位间隔内最大的请求流量限额 action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry status string 设置达到限速条件的返回状态码，默认 429 message string 设置达到限速条件的请求的拒绝返回消息 retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒 max_retry_times int 限速重试的最大重试次数，默认 1000 failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息</description></item><item><title>request_header_filter</title><link>/v1.4.0/docs/references/filters/request_header_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_header_filter/</guid><description>request_header_filter # 描述 # request_header_filter 过滤器用来按请求的 Header 信息来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_header_filter: include: - TRACE: true 上面的例子表示，当 Header 里面包含 TRACE: true 的请求才被允许通过。
curl 192.168.3.4:8000 -v -H 'TRACE: true' 参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求 Header 信息 include array 允许通过的请求 Header 信息 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_host_filter</title><link>/v1.4.0/docs/references/filters/request_host_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_host_filter/</guid><description>request_host_filter # 描述 # request_host_filter 过滤器主要用来按照指定的域名或者主机名来进行请求过滤，适合只有一个 IP 多个域名需要进行域名访问控制的场景。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_host_filter: include: - domain-test2.com:8000 上面的例子表示，只有访问的是这个域名 domain-test2.com:8000 的请求才被允许通过。
示例如下： # ✗ curl -k -u medcl:backsoon http://domain-test4.com:8000/ -v * Trying 192.168.3.67... * TCP_NODELAY set * Connected to domain-test4.com (192.168.3.67) port 8000 (#0) * Server auth using Basic with user 'medcl' &amp;gt; GET / HTTP/1.1 &amp;gt; Host: domain-test4.com:8000 &amp;gt; Authorization: Basic bWVkY2w6YmFja3Nvb24= &amp;gt; User-Agent: curl/7.</description></item><item><title>request_host_limiter</title><link>/v1.4.0/docs/references/filters/request_host_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_host_limiter/</guid><description>request_host_limiter # 描述 # request_host_limiter 过滤器用来按照请求主机（域名）来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_host_limiter: host: - api.elasticsearch.cn - logging.elasticsearch.cn max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: &amp;quot;you reached our limit&amp;quot; 上面的配置中，对 api.elasticsearch.cn 和 logging.elasticsearch.cn 这两个访问域名进行限速，允许的最大 qps 为 256 每秒。
参数说明 # 名称 类型 说明 host array 设置哪些主机域名会参与限速，不设置表示都参与 interval string 评估限速的单位时间间隔，默认为 1s max_requests int 单位间隔内最大的请求次数限额 max_bytes int 单位间隔内最大的请求流量限额 action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry status string 设置达到限速条件的返回状态码，默认 429 message string 设置达到限速条件的请求的拒绝返回消息 retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒 max_retry_times int 限速重试的最大重试次数，默认 1000 failed_retry_message string 设置达到最大重试次数的请求的拒绝返回消息</description></item><item><title>request_method_filter</title><link>/v1.4.0/docs/references/filters/request_method_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_method_filter/</guid><description>request_method_filter # 描述 # request_method_filter 过滤器用来按请求 Method 来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_method_filter: exclude: - PUT - POST include: - GET - HEAD - DELETE 参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求 Method include array 允许通过的请求 Method action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_path_filter</title><link>/v1.4.0/docs/references/filters/request_path_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_path_filter/</guid><description>request_path_filter # 描述 # request_path_filter 过滤器用来按请求的 Path 路径来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_path_filter: must: #must match all rules to continue prefix: - /medcl contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\w]+dcl must_not: # any match will be filtered prefix: - /.kibana - /_security - /_security - /gateway_requests* - /.reporting - /_monitoring/bulk contain: - _search suffix: - _count - _refresh wildcard: - /*/_refresh regex: - ^/m[\w]+dcl should: prefix: - /medcl contain: - _search - _async_search suffix: - _refresh wildcard: - /*/_refresh regex: - ^/m[\w]+dcl 参数说明 # 名称 类型 说明 must.</description></item><item><title>request_path_limiter</title><link>/v1.4.0/docs/references/filters/request_path_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_path_limiter/</guid><description>request_path_limiter # 描述 # request_path_limiter 过滤器用来定义请求的限速规则，可以实现索引级别的限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_path_limiter: message: &amp;quot;Hey, You just reached our request limit!&amp;quot; rules: - pattern: &amp;quot;/(?P&amp;lt;index_name&amp;gt;medcl)/_search&amp;quot; max_qps: 3 group: index_name - pattern: &amp;quot;/(?P&amp;lt;index_name&amp;gt;.*?)/_search&amp;quot; max_qps: 100 group: index_name 上面的配置中，对 medcl 这个索引执行查询，允许的最大 qps 为 3，而对其它的索引执行查询的 qps 为 100。
参数说明 # 名称 类型 说明 message string 设置达到限速条件的请求的返回消息 rules array 设置限速的策略，支持多种规则，按照配置的先后顺序处理，先匹配的先执行 rules.</description></item><item><title>request_user_filter</title><link>/v1.4.0/docs/references/filters/request_user_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_user_filter/</guid><description>request_user_filter # 描述 # 当 Elasticsearch 是通过 Basic Auth 方式来进行身份认证的时候，request_user_filter 过滤器可用来按请求的用户名信息来进行过滤。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - request_user_filter: include: - &amp;quot;elastic&amp;quot; 上面的例子表示，只有来自 elastic 的请求才被允许通过。
参数说明 # 名称 类型 说明 exclude array 拒绝通过的请求的用户名列表 include array 允许通过的请求的用户名列表 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>request_user_limiter</title><link>/v1.4.0/docs/references/filters/request_user_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/request_user_limiter/</guid><description>request_user_limiter # 描述 # request_user_limiter 过滤器用来按照用户名来进行限速。
配置示例 # 配置示例如下：
flow: - name: rate_limit_flow filter: - request_user_limiter: user: - elastic - medcl max_requests: 256 # max_bytes: 102400 #100k action: retry # retry or drop # max_retry_times: 1000 # retry_interval: 500 #100ms message: &amp;quot;you reached our limit&amp;quot; 上面的配置中，对 medcl 和 elastic 这两个用户进行限速，允许的最大 qps 为 256 每秒。
参数说明 # 名称 类型 说明 user array 设置哪些用户会参与限速，不设置表示所有用户参与 interval string 评估限速的单位时间间隔，默认为 1s max_requests int 单位间隔内最大的请求次数限额 max_bytes int 单位间隔内最大的请求流量限额 action string 触发限速之后的处理动作，分为 retry 和 drop 两种，默认为 retry message string 设置达到限速条件的请求的拒绝返回消息 retry_interval int 限速重试的时间间隔，单位毫秒，默认 10，即 10 毫秒 max_retry_times int 限速重试的最大重试次数，默认 1000</description></item><item><title>response_body_regex_replace</title><link>/v1.4.0/docs/references/filters/response_body_regex_replace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/response_body_regex_replace/</guid><description>response_body_regex_replace # 描述 # response_body_regex_replace 过滤器使用正则表达式来替换请求响应内容的字符串。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - echo: message: &amp;quot;hello infini\n&amp;quot; - response_body_regex_replace: pattern: infini to: world 上面的结果输出为 hello world。
参数说明 # 名称 类型 说明 pattern string 用于匹配替换的正则表达式 to string 替换为目标的字符串内容</description></item><item><title>response_header_filter</title><link>/v1.4.0/docs/references/filters/response_header_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/response_header_filter/</guid><description>response_header_filter # 描述 # response_header_filter 过滤器用来按请求响应的 Header 信息来过滤流量。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: ... - response_header_filter: exclude: - INFINI-CACHE: CACHED 上面的例子表示，当 Header 信息里面出现 INFINI-CACHE: CACHED 的请求不允许通过。
参数说明 # 名称 类型 说明 exclude array 拒绝通过的响应 Header 信息 include array 允许通过的响应 Header 信息 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>response_header_format</title><link>/v1.4.0/docs/references/filters/response_header_format/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/response_header_format/</guid><description>response_header_format # 描述 # response_header_format 过滤器用来将请求响应的 Header 信息里面的 Key 都转换成小写。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - response_header_format:</description></item><item><title>response_status_filter</title><link>/v1.4.0/docs/references/filters/response_status_filter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/response_status_filter/</guid><description>response_status_filter # 描述 # response_status_filter 过滤器用来按后端服务响应的状态码来进行过滤。
配置示例 # 一个简单的示例如下：
flow: - name: test filter: - response_status_filter: message: &amp;quot;Request filtered!&amp;quot; exclude: - 404 include: - 200 - 201 - 500 参数说明 # 名称 类型 说明 exclude array 拒绝通过的响应码 include array 允许通过的响应码 action string 符合过滤条件之后的处理动作，可以是 deny 和 redirect_flow，默认为 deny status int 自定义模式匹配之后返回的状态码 message string 自定义 deny 模式返回的消息文本 flow string 自定义 redirect_flow 模式执行的 flow ID 注意: 当设置了 include 条件的情况下，必须至少满足 include 设置的其中一种响应码才能被允许通过。 当仅设置了 exclude 条件的情况下，不符合 exclude 的任意请求都允许通过。</description></item><item><title>retry_limiter</title><link>/v1.4.0/docs/references/filters/retry_limiter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/retry_limiter/</guid><description>retry_limiter # 描述 # retry_limiter 过滤器用来判断一个请求是否达到最大重试次数，避免一个请求的无限重试。
配置示例 # 一个简单的示例如下：
flow: - name: retry_limiter filter: - retry_limiter: queue_name: &amp;quot;deadlock_messages&amp;quot; max_retry_times: 3 参数说明 # 名称 类型 说明 max_retry_times int 最大重试次数，默认为 3 queue_name string 达到重试最大次数后，输出消息到指定消息队列的名称</description></item><item><title>sample</title><link>/v1.4.0/docs/references/filters/sample/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/sample/</guid><description>sample # 描述 # sample 过滤器用来将正常的流量按照比例采样，对于海量查询的场景，全流量收集日志需要耗费大量的资源，可以考虑进行抽样统计，对查询日志进行采样分析。
配置示例 # 一个简单的示例如下：
flow: - name: sample filter: - sample: ratio: 0.2 参数说明 # 名称 类型 说明 ratio float 采样比例</description></item><item><title>set_basic_auth</title><link>/v1.4.0/docs/references/filters/set_basic_auth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/set_basic_auth/</guid><description>set_basic_auth # 描述 # set_basic_auth 过滤器用来设置请求的身份认证信息，可以用于重置请求的身份信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_basic_auth filter: - set_basic_auth: username: admin password: password 参数说明 # 名称 类型 说明 username string 用户名 password string 密码</description></item><item><title>set_hostname</title><link>/v1.4.0/docs/references/filters/set_hostname/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/set_hostname/</guid><description>set_hostname # 描述 # set_hostname 过滤器用来设置请求 Header 关于要访问的主机或域名信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_hostname filter: - set_hostname: hostname: api.infini.sh 为避免
参数说明 # 名称 类型 说明 hostname string 主机信息</description></item><item><title>set_request_header</title><link>/v1.4.0/docs/references/filters/set_request_header/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/set_request_header/</guid><description>set_request_header # 描述 # set_request_header 过滤器用来设置请求的 Header 头信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_request_header filter: - set_request_header: headers: - Trial -&amp;gt; true - Department -&amp;gt; Engineering 为避免
参数说明 # 名称 类型 说明 headers map 使用 -&amp;gt; 作为标识符的键值对，用于设置 Header 信息</description></item><item><title>set_request_query_args</title><link>/v1.4.0/docs/references/filters/set_request_query_args/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/set_request_query_args/</guid><description>set_request_query_args # 描述 # set_request_query_args 过滤器用来设置请求的 QueryString 参数信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_request_query_args filter: - set_request_query_args: args: - size -&amp;gt; 10 为避免
参数说明 # 名称 类型 说明 args map 使用 -&amp;gt; 作为标识符的键值对，用于设置 QueryString 参数信息</description></item><item><title>set_response</title><link>/v1.4.0/docs/references/filters/set_response/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/set_response/</guid><description>set_response # 描述 # set_response 过滤器用来设置请求响应返回信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_response filter: - set_response: status: 200 content_type: application/json body: '{&amp;quot;message&amp;quot;:&amp;quot;hello world&amp;quot;}' 参数说明 # 名称 类型 说明 status int 请求状态码，默认 200 content_type string 设置请求返回的内容类型 body string 设置请求返回的结构体</description></item><item><title>set_response_header</title><link>/v1.4.0/docs/references/filters/set_response_header/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/set_response_header/</guid><description>set_response_header # 描述 # set_response_header 过滤器用来设置请求响应的 Header 头信息。
配置示例 # 一个简单的示例如下：
flow: - name: set_response_header filter: - set_response_header: headers: - Trial -&amp;gt; true - Department -&amp;gt; Engineering 为避免
参数说明 # 名称 类型 说明 headers map 使用 -&amp;gt; 作为标识符的键值对，用于设置 Header 信息</description></item><item><title>sleep</title><link>/v1.4.0/docs/references/filters/sleep/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/sleep/</guid><description>sleep # 描述 # sleep 过滤器用来添加一个固定的延迟到请求，可以人为降速。
配置示例 # 一个简单的示例如下：
flow: - name: slow_query_logging_test filter: - sleep: sleep_in_million_seconds: 1024 参数说明 # 名称 类型 说明 sleep_in_million_seconds int64 需要添加的延迟长度，单位为毫秒</description></item><item><title>switch</title><link>/v1.4.0/docs/references/filters/switch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/switch/</guid><description>switch # 描述 # switch 过滤器用来将流量按照请求路径转发到另外的一个处理流程，可以方便的实现跨集群操作，且 Elasticsearch 集群不需要做任何修改，且各个集群内所有的 API 都可以访问，包括索引的读写和集群操作。
配置示例 # 一个简单的示例如下：
flow: - name: es1-flow filter: - elasticsearch: elasticsearch: es1 - name: es2-flow filter: - elasticsearch: elasticsearch: es2 - name: cross_cluste_search filter: - switch: path_rules: - prefix: &amp;quot;es1:&amp;quot; flow: es1-flow - prefix: &amp;quot;es2:&amp;quot; flow: es2-flow - elasticsearch: elasticsearch: dev #elasticsearch configure reference name 上面的例子中，以 es1: 开头的索引将转发给集群 es1 集群，以 es2: 开头的索引转发给 es2 集群，不匹配的转发给 dev 集群，在一个 Kibana 里面可以直接操作不同版本的集群了，如下：</description></item><item><title>translog</title><link>/v1.4.0/docs/references/filters/translog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/v1.4.0/docs/references/filters/translog/</guid><description>translog # 描述 # translog 过滤器用来将收到的请求保存到本地文件，并压缩存放，可记录部分或完整的请求日志，用于归档和请求重放。
配置示例 # 一个简单的示例如下：
flow: - name: translog filter: - translog: max_file_age: 7 max_file_count: 10 参数说明 # 名称 类型 说明 path string 日志存放根目录，默认为网关数据目录下的 translog 子目录 category string 区分不同日志的二级分类子目录，默认为 default filename string 设置日志的文件名，默认为 translog.log compress bool 文件滚动之后是否压缩归档，默认为 true max_file_age int 最多保留的归档文件天数，默认为 30 天 max_file_count int 最多保留的归档文件个数，默认为 100 天 max_file_size_in_mb int 单个归档文件的最大字节数，默认为 1024 MB</description></item></channel></rss>